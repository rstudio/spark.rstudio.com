---
title: "Option 1 - Connecting to Databricks remotely"
output:
  html_document:
    toc: true
    toc_depth: 2
    toc_float:
      collapsed: false
params:
  width: 600
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<div id="overview" class="section level2">
<h2>Overview</h2>
<p>With this configuration, RStudio Server Pro is installed outside of the Spark
cluster and allows users to connect to Spark remotely using <code>sparklyr</code> with
<a href="https://docs.databricks.com/dev-tools/databricks-connect.html">Databricks Connect</a>.</p>
<p><img src="/images/deployment/databricks/rstudio-databricks-remote.png" width='800px' align='center'/></p>
<p>This is the recommended configuration because it targets separate environments,
involves a typical configuration process, avoids resource contention, and allows
RStudio Server Pro to connect to Databricks as well as other remote storage and
compute resources.</p>
</div>
<div id="advantages-and-limitations" class="section level2">
<h2>Advantages and limitations</h2>
<p>Advantages:</p>
<ul>
<li>RStudio Server Pro will remain functional if Databricks clusters are
terminated</li>
<li>Provides the ability to communicate with one or more Databricks clusters as a
remote compute resource</li>
<li>Avoids resource contention between RStudio Server Pro and Databricks</li>
</ul>
<p>Limitations:</p>
<ul>
<li>Databricks Connect does not currently support the following APIs from
<code>sparklyr</code>: Broom APIs, Streaming APIs, Broadcast APIs, Most MLlib APIs,
<code>csv_file</code> serialization mode, and the <code>spark_submit</code> API</li>
<li>Databricks Connect does not support structured streaming</li>
<li>Databricks Connect does not support running arbitrary code that is not a part
of a Spark job on the remote cluster</li>
<li>Databricks Connect does not support Scala, Python, and R APIs for Delta table
operations</li>
<li>Databricks Connect does not support most utilities in Databricks Utilities.
However, <code>dbutils.fs</code> and <code>dbutils.secrets</code> are supported</li>
</ul>
<p>For more information on the limitations of Databricks Connect, refer to the
<a href="https://docs.databricks.com/dev-tools/databricks-connect.html#limitations">Limitation section of the Databricks Connect documentation</a>.</p>
</div>
<div id="requirements" class="section level2">
<h2>Requirements</h2>
<ul>
<li>RStudio Server Pro installed outside of the Databricks cluster</li>
<li>Java 8 installed on the machine with RStudio Server Pro</li>
<li>A running Databricks cluster with a runtime version 5.5 or above</li>
</ul>
</div>
<div id="install-python" class="section level2">
<h2>Install Python</h2>
<p>The Databricks Connect client is provided as a Python library. The minor version
of your Python installation must be the same as the minor Python version of your
Databricks cluster.</p>
<p>Refer to the steps in the
<a href="https://docs.rstudio.com/resources/install-python/">install Python section of the RStudio Documentation</a>
to install Python on the same server where RStudio Server Pro is installed.</p>
<p>Note that you can either install Python for all users in a global location (as
an administrator) or in a home directory (as an end user).</p>
</div>
<div id="install-databricks-connect" class="section level2">
<h2>Install Databricks Connect</h2>
<p>Run the following command to install Databricks Connect on the server with
RStudio Server Pro:</p>
<pre><code>pip install -U databricks-connect==6.3.*  # or a different version to match your Databricks cluster</code></pre>
<p>Note that you can either install this library for all users in a global Python
environment (as an administrator) or for an individual user in their Python
environment (e.g., using the <code>pip --user</code> option or installing into a conda
environment or virtual environment).</p>
</div>
<div id="configure-databricks-connect" class="section level2">
<h2>Configure Databricks Connect</h2>
<p>To configure the Databricks Connect client, you can run the following command in
a terminal when logged in as a user in RStudio Server Pro:</p>
<pre><code>databricks-connect configure</code></pre>
<p>In the prompts that follow, enter the following information:</p>
<table style="width:100%;">
<colgroup>
<col width="27%" />
<col width="33%" />
<col width="39%" />
</colgroup>
<thead>
<tr class="header">
<th>Parameter</th>
<th>Description</th>
<th>Example Value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Databricks Host</td>
<td>Base address of your Databricks console URL</td>
<td><code>https://dbc-01234567-89ab.cloud.databricks.com</code></td>
</tr>
<tr class="even">
<td>Databricks Token</td>
<td>User token generated from the Databricks Console under your “User Settings”</td>
<td><code>dapi24g06bdd96f2700b09dd336d5444c1yz</code></td>
</tr>
<tr class="odd">
<td>Cluster ID</td>
<td>Cluster ID in the Databricks console under Advanced Options &gt; Tags &gt; <code>ClusterId</code></td>
<td><code>0308-033548-colt989</code></td>
</tr>
<tr class="even">
<td>Org ID</td>
<td>Found in the <code>?o=orgId</code> portion of your Databricks Console URL</td>
<td><code>8498623428173033</code></td>
</tr>
<tr class="odd">
<td>Port</td>
<td>The port that Databricks Connect connects to</td>
<td><code>15001</code></td>
</tr>
</tbody>
</table>
<p>After you’ve completed the configuration process for Databricks Connect, you can
run the following command in a terminal to test the connectivity of Databricks
Connect to your Databricks cluster:</p>
<pre><code>databricks-connect test</code></pre>
</div>
<div id="install-sparklyr" class="section level2">
<h2>Install <code>sparklyr</code></h2>
<p>The integration of <code>sparklyr</code> with Databricks Connect is currently being added
to the development version of <code>sparklyr</code>. To use this functionality now, you’ll
need to install the development version of <code>sparklyr</code> by running the following
command in an R console:</p>
<pre><code>devtools::install_github(&quot;sparklyr/sparklyr&quot;)</code></pre>
</div>
<div id="install-spark" class="section level2">
<h2>Install Spark</h2>
<p>To work with a remote Databricks cluster, you need to have a local installation
of Spark that matches the version of Spark on the Databricks Cluster.</p>
<p>You can install Spark by running the following command in an R console:</p>
<pre><code>library(sparklyr)
sparklyr::spark_install()</code></pre>
<p>You can specify the version of Spark to install along with other options. Refer
to the
<a href="https://spark.rstudio.com/reference/spark_install/"><code>spark_install()</code> options in the <code>sparklyr</code> reference documentation</a>
for more information.</p>
</div>
<div id="use-sparklyr" class="section level2">
<h2>Use <code>sparklyr</code></h2>
<p>In order to connect to Databricks using <code>sparklyr</code> and <code>databricks-connect</code>,
<code>SPARK_HOME</code> must be set to the output of the <code>databricks-connect get-spark-home</code> command.</p>
<p>You can set <code>SPARK_HOME</code> as an environment variable or directly within
<code>spark_connect()</code>. The following R code demonstrates connecting to Databricks,
copying some data into the cluster, summarizing that data using <code>sparklyr</code>, and
disconnecting:</p>
<pre><code>library(sparklyr)
library(dplyr)

databricks_connect_spark_home &lt;- system(&quot;databricks-connect get-spark-home&quot;, intern = TRUE)
sc &lt;- spark_connect(method = &quot;databricks&quot;, spark_home = databricks_connect_spark_home)

cars_tbl &lt;- copy_to(sc, mtcars, overwrite = TRUE)

cars_tbl %&gt;% 
  group_by(cyl) %&gt;% 
  summarise(mean_mpg = mean(mpg, na.rm = TRUE),
            mean_hp  = mean(hp, na.rm = TRUE))

spark_disconnect(sc)</code></pre>
</div>
<div id="additional-information" class="section level2">
<h2>Additional information</h2>
<p>For more information on the setup, configuration, troubleshooting, and
limitations of Databricks Connect, refer to the
<a href="https://docs.databricks.com/dev-tools/databricks-connect.html">Databricks Connect section of the Databricks documentation</a>.</p>
</div>
