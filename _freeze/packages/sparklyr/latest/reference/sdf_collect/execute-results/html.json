{
  "hash": "d81f1401228f4cc7be0bfecf928736e9",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Collect a Spark DataFrame into R.\"\nexecute:\n  freeze: true\n---\n\n\n\n*R/sdf_wrapper.R*\n\n## sdf_collect\n\n## Description\n Collects a Spark dataframe into R. \n\n\n## Usage\n```r\n \nsdf_collect(object, impl = c(\"row-wise\", \"row-wise-iter\", \"column-wise\"), ...) \n```\n\n## Arguments\n|Arguments|Description|\n|---|---|\n| object | Spark dataframe to collect |\n| impl | Which implementation to use while collecting Spark dataframe - row-wise: fetch the entire dataframe into memory and then process it row-by-row - row-wise-iter: iterate through the dataframe using RDD local iterator, processing one row at                  a time (hence reducing memory footprint) - column-wise: fetch the entire dataframe into memory and then process it column-by-column NOTE: (1) this will not apply to streaming or arrow use cases (2) this parameter will only affect implementation detail, and will not affect result of `sdf_collect`, and should only be set if performance profiling indicates any particular choice will be significantly better than the default choice (\"row-wise\") |\n| ... | Additional options. |\n\n\n\n\n\n\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}