---
title: "Default Compilation Specification for Spark Extensions"
aliases:
  - reference/sparklyr/latest/spark_default_compilation_spec.html
---

    <div>

    <div>
    <ul data-gumshoe>
    <li><a href="#arguments">Arguments</a></li>
    </ul>
    </div>

    <div>

    <p>This is the default compilation specification used for
Spark extensions, when used with <code><a href='compile_package_jars.html'>compile_package_jars</a></code>.</p>

    <div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class='fu'>spark_default_compilation_spec</span>(
  <span class='kw'>pkg</span> <span class='kw'>=</span> <span class='fu'>infer_active_package_name</span>(),
  <span class='kw'>locations</span> <span class='kw'>=</span> <span class='kw'>NULL</span>
)</code></pre></div>

    <h2 id="arguments">Arguments</h2>
    <table class="ref-arguments">

    <colgroup>
      <col class="name" />
      <col class="desc" />
    </colgroup>

    <tr>
      <td>pkg</td>
      <td><p>The package containing Spark extensions to be compiled.</p></td>
    </tr>
    <tr>
      <td>locations</td>
      <td><p>Additional locations to scan. By default, the
directories <code>/opt/scala</code> and <code>/usr/local/scala</code> will
be scanned.</p></td>
    </tr>
    </table>



    </div>

    </div>




