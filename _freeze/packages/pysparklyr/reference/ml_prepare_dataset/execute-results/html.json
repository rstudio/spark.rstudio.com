{
  "hash": "2df8e28cc37d987bbf00c061f457b6b7",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Creates the 'label' and 'features' columns\"\nexecute:\n  freeze: true\n---\n\n\n\n*R/ml-prepare-dataset.R*\n\n## ml_prepare_dataset\n\n## Description\n Creates the 'label' and 'features' columns \n\n\n## Usage\n```r\n \nml_prepare_dataset( \n  x, \n  formula = NULL, \n  label = NULL, \n  features = NULL, \n  label_col = \"label\", \n  features_col = \"features\", \n  keep_original = TRUE, \n  ... \n) \n```\n\n## Arguments\n|Arguments|Description|\n|---|---|\n| x | A `tbl_pyspark` object |\n| formula | Used when `x` is a `tbl_spark`. R formula. |\n| label | The name of the label column. |\n| features | The name(s) of the feature columns as a character vector. |\n| label_col | Label column name, as a length-one character vector. |\n| features_col | Features column name, as a length-one character vector. |\n| keep_original | Boolean flag that indicates if the output will contain, or not, the original columns from `x`. Defaults to `TRUE`. |\n| ... | Added for backwards compatibility. Not in use today. |\n\n## Details\n At this time, 'Spark ML Connect', does not include a Vector Assembler transformer. The main thing that this function does, is create a 'Pyspark' array column. Pipelines require a 'label' and 'features' columns. Even though it is is single column in the dataset, the 'features' column will contain all of the predictors insde an array. This function also creates a new 'label' column that copies the outcome variable. This makes it a lot easier to remove the 'label', and 'outcome' columns. \n\n\n## Value\n A `tbl_pyspark`, with either the original columns from `x`, plus the 'label' and 'features' column, or, the 'label' and 'features' columns only. \n\n\n\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}