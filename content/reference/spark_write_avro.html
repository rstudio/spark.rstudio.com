---
title: "Serialize a Spark DataFrame into Apache Avro format"
aliases:
  - reference/sparklyr/latest/spark_write_avro.html
---

    <div>

    <div>
    <ul data-gumshoe>
    <li><a href="#arguments">Arguments</a></li>
    <li><a href="#see-also">See also</a></li>
    </ul>
    </div>

    <div>

    <p>Serialize a Spark DataFrame into Apache Avro format.
Notice this functionality requires the Spark connection <code>sc</code> to be instantiated with either
an explicitly specified Spark version (i.e.,
<code>spark_connect(..., version = &lt;version&gt;, packages = c("avro", &lt;other package(s)&gt;), ...)</code>)
or a specific version of Spark avro package to use (e.g.,
<code>spark_connect(..., packages = c("org.apache.spark:spark-avro_2.12:3.0.0", &lt;other package(s)&gt;), ...)</code>).</p>

    <div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class='fu'>spark_write_avro</span>(
  <span class='no'>x</span>,
  <span class='no'>path</span>,
  <span class='kw'>avro_schema</span> <span class='kw'>=</span> <span class='kw'>NULL</span>,
  <span class='kw'>record_name</span> <span class='kw'>=</span> <span class='st'>"topLevelRecord"</span>,
  <span class='kw'>record_namespace</span> <span class='kw'>=</span> <span class='st'>""</span>,
  <span class='kw'>compression</span> <span class='kw'>=</span> <span class='st'>"snappy"</span>,
  <span class='kw'>partition_by</span> <span class='kw'>=</span> <span class='kw'>NULL</span>
)</code></pre></div>

    <h2 id="arguments">Arguments</h2>
    <table class="ref-arguments">

    <colgroup>
      <col class="name" />
      <col class="desc" />
    </colgroup>

    <tr>
      <td>x</td>
      <td><p>A Spark DataFrame or dplyr operation</p></td>
    </tr>
    <tr>
      <td>path</td>
      <td><p>The path to the file. Needs to be accessible from the cluster.
Supports the <samp>"hdfs://"</samp>, <samp>"s3a://"</samp> and <samp>"file://"</samp> protocols.</p></td>
    </tr>
    <tr>
      <td>avro_schema</td>
      <td><p>Optional Avro schema in JSON format</p></td>
    </tr>
    <tr>
      <td>record_name</td>
      <td><p>Optional top level record name in write result (default: "topLevelRecord")</p></td>
    </tr>
    <tr>
      <td>record_namespace</td>
      <td><p>Record namespace in write result (default: "")</p></td>
    </tr>
    <tr>
      <td>compression</td>
      <td><p>Compression codec to use (default: "snappy")</p></td>
    </tr>
    <tr>
      <td>partition_by</td>
      <td><p>A <code>character</code> vector. Partitions the output by the given columns on the file system.</p></td>
    </tr>
    </table>

    <h2 id="see-also">See also</h2>

    <div class='dont-index'><p>Other Spark serialization routines: 
<code><a href='spark_load_table.html'>spark_load_table</a>()</code>,
<code><a href='spark_read_avro.html'>spark_read_avro</a>()</code>,
<code><a href='spark_read_csv.html'>spark_read_csv</a>()</code>,
<code><a href='spark_read_delta.html'>spark_read_delta</a>()</code>,
<code><a href='spark_read_jdbc.html'>spark_read_jdbc</a>()</code>,
<code><a href='spark_read_json.html'>spark_read_json</a>()</code>,
<code><a href='spark_read_libsvm.html'>spark_read_libsvm</a>()</code>,
<code><a href='spark_read_orc.html'>spark_read_orc</a>()</code>,
<code><a href='spark_read_parquet.html'>spark_read_parquet</a>()</code>,
<code><a href='spark_read_source.html'>spark_read_source</a>()</code>,
<code><a href='spark_read_table.html'>spark_read_table</a>()</code>,
<code><a href='spark_read_text.html'>spark_read_text</a>()</code>,
<code><a href='spark_read.html'>spark_read</a>()</code>,
<code><a href='spark_save_table.html'>spark_save_table</a>()</code>,
<code><a href='spark_write_csv.html'>spark_write_csv</a>()</code>,
<code><a href='spark_write_delta.html'>spark_write_delta</a>()</code>,
<code><a href='spark_write_jdbc.html'>spark_write_jdbc</a>()</code>,
<code><a href='spark_write_json.html'>spark_write_json</a>()</code>,
<code><a href='spark_write_orc.html'>spark_write_orc</a>()</code>,
<code><a href='spark_write_parquet.html'>spark_write_parquet</a>()</code>,
<code><a href='spark_write_source.html'>spark_write_source</a>()</code>,
<code><a href='spark_write_table.html'>spark_write_table</a>()</code>,
<code><a href='spark_write_text.html'>spark_write_text</a>()</code></p></div>


    </div>

    </div>




