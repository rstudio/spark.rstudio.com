---
title: "Export a Spark pipeline for serving"
execute:
  freeze: true
---

```{r, eval=ecodown::examples_not_run()}
#| include: false
options("pillar.width" = 60)
library(sparklyr) 
library(dplyr)
```

*R/write-bundle.R*

## ml_write_to_bundle_transformed

## Description
 This functions serializes a Spark pipeline model into an MLeap bundle. 


## Usage
```r
 
ml_write_to_bundle_transformed(x, transformed_dataset, path, overwrite = FALSE) 
```

## Arguments
|Arguments|Description|
|---|---|
| x | A Spark ML Pipeline Model object. |
| transformed_dataset | A Spark data frame created by the ML Pipeline Model (`x`) |
| path | Where to save the bundle. |
| overwrite | Whether to overwrite an existing file, defaults to `FALSE`. |





## Examples
```{r, eval=ecodown::examples_not_run()}
library(mleap)
 
library(sparklyr) 
 
sc <- spark_connect(master = "local") 
 
mtcars_tbl <- copy_to(sc, mtcars, overwrite = TRUE) 
 
pipeline <- ml_pipeline(sc) %>% 
  ft_binarizer("hp", "big_hp", threshold = 100) %>% 
  ft_vector_assembler(c("big_hp", "wt", "qsec"), "features") %>% 
  ml_gbt_regressor(label_col = "mpg") 
 
pipeline_model <- ml_fit(pipeline, mtcars_tbl) 
 
preds <- ml_transform(pipeline_model, mtcars_tbl) 
 
model_path <- file.path(tempdir(), "mtcars_model.zip") 
 
ml_write_bundle( 
  x = pipeline_model, 
  transformed_dataset = preds, 
  path = model_path, 
  overwrite = TRUE 
) 
 
 
```



```{r, eval=ecodown::examples_not_run()}
#| include: false
spark_disconnect_all()
```
