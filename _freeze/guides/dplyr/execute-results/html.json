{
  "hash": "f9751107b93c429b4456885e462dcc3b",
  "result": {
    "markdown": "---\ntitle: \"Manipulating Data with `dplyr`\"\nformat:\n  html:\n    theme: default\n    toc: true\nexecute:\n    eval: true\n    freeze: true\n---\n\n\n## Overview\n\n[**`dplyr`**](https://cran.r-project.org/web/packages/dplyr/index.html) is\nan R package for working with structured data both in and outside of R.\ndplyr makes data manipulation for R users easy, consistent, and\nperformant. With `dplyr` as an interface to manipulating Spark DataFrames,\nyou can:\n\n  - Select, filter, and aggregate data\n  - Use window functions (e.g. for sampling)\n  - Perform joins on `DataFrames`\n  - Collect data from Spark into R\n\nStatements in dplyr can be chained together using pipes defined by the\n[magrittr](https://cran.r-project.org/web/packages/magrittr/vignettes/magrittr.html)\nR package. dplyr also supports [non-standard\nevalution](https://cran.r-project.org/web/packages/dplyr/vignettes/nse.html)\nof its arguments. For more information on dplyr, see the\n[introduction](https://cran.r-project.org/web/packages/dplyr/vignettes/introduction.html),\na guide for connecting to\n[databases](https://cran.r-project.org/web/packages/dplyr/vignettes/databases.html),\nand a variety of\n[vignettes](https://cran.r-project.org/web/packages/dplyr/index.html).\n\n\n### Flights Data\n\nThis guide will demonstrate some of the basic data manipulation verbs of\ndplyr by using data from the `nycflights13` R package. This package\ncontains data for all 336,776 flights departing New York City in 2013.\nIt also includes useful metadata on airlines, airports, weather, and\nplanes. The data comes from the US [Bureau of Transportation\nStatistics](http://www.transtats.bts.gov/DatabaseInfo.asp?DB_ID=120&Link=0),\nand is documented in `?nycflights13`\n\nConnect to the cluster and copy the flights data using the `copy_to()`\nfunction. Caveat: The flight data in `nycflights13` is convenient for\ndplyr demonstrations because it is small, but in practice large data\nshould rarely be copied directly from R objects.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(sparklyr)\nlibrary(dplyr)\nlibrary(ggplot2)\n\nsc <- spark_connect(master=\"local\")\n\nflights_tbl <- copy_to(sc, nycflights13::flights, \"flights\")\n\nairlines_tbl <- copy_to(sc, nycflights13::airlines, \"airlines\")\n```\n:::\n\n\n## dplyr Verbs\n\nVerbs are `dplyr` commands for manipulating data. When connected to a\nSpark DataFrame, `dplyr` translates the commands into **Spark SQL**\nstatements. Remote data sources use exactly the same five verbs as local\ndata sources. Here are the five verbs with their corresponding SQL\ncommands:\n\n  - `select()` ~ `SELECT`\n  - `filter()` ~ `WHERE`\n  - `arrange()` ~ `ORDER`\n  - `summarise()` ~ `aggregators: sum, min, sd, etc.`\n  - `mutate()` ~ `operators: +, *, log, etc.`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nselect(flights_tbl, year:day, arr_delay, dep_delay)\n```\n\n::: {.cell-output-stdout}\n```\n# Source: spark<?> [?? x 5]\n    year month   day arr_delay dep_delay\n   <int> <int> <int>     <dbl>     <dbl>\n 1  2013     1     1        11         2\n 2  2013     1     1        20         4\n 3  2013     1     1        33         2\n 4  2013     1     1       -18        -1\n 5  2013     1     1       -25        -6\n 6  2013     1     1        12        -4\n 7  2013     1     1        19        -5\n 8  2013     1     1       -14        -3\n 9  2013     1     1        -8        -3\n10  2013     1     1         8        -2\n# … with more rows\n```\n:::\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfilter(flights_tbl, dep_delay > 1000)\n```\n\n::: {.cell-output-stdout}\n```\n# Source: spark<?> [?? x 19]\n   year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n  <int> <int> <int>    <int>          <int>     <dbl>    <int>          <int>\n1  2013     1     9      641            900      1301     1242           1530\n2  2013     1    10     1121           1635      1126     1239           1810\n3  2013     6    15     1432           1935      1137     1607           2120\n4  2013     7    22      845           1600      1005     1044           1815\n5  2013     9    20     1139           1845      1014     1457           2210\n# … with 11 more variables: arr_delay <dbl>, carrier <chr>, flight <int>,\n#   tailnum <chr>, origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>,\n#   hour <dbl>, minute <dbl>, time_hour <dttm>\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\narrange(flights_tbl, desc(dep_delay))\n```\n\n::: {.cell-output-stdout}\n```\n# Source:     spark<?> [?? x 19]\n# Ordered by: desc(dep_delay)\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   <int> <int> <int>    <int>          <int>     <dbl>    <int>          <int>\n 1  2013     1     9      641            900      1301     1242           1530\n 2  2013     6    15     1432           1935      1137     1607           2120\n 3  2013     1    10     1121           1635      1126     1239           1810\n 4  2013     9    20     1139           1845      1014     1457           2210\n 5  2013     7    22      845           1600      1005     1044           1815\n 6  2013     4    10     1100           1900       960     1342           2211\n 7  2013     3    17     2321            810       911      135           1020\n 8  2013     6    27      959           1900       899     1236           2226\n 9  2013     7    22     2257            759       898      121           1026\n10  2013    12     5      756           1700       896     1058           2020\n# … with more rows, and 11 more variables: arr_delay <dbl>, carrier <chr>,\n#   flight <int>, tailnum <chr>, origin <chr>, dest <chr>, air_time <dbl>,\n#   distance <dbl>, hour <dbl>, minute <dbl>, time_hour <dttm>\n```\n:::\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummarise(\n  flights_tbl, \n  mean_dep_delay = mean(dep_delay, na.rm = TRUE)\n  )\n```\n\n::: {.cell-output-stdout}\n```\n# Source: spark<?> [?? x 1]\n  mean_dep_delay\n           <dbl>\n1           12.6\n```\n:::\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmutate(flights_tbl, speed = distance / air_time * 60)\n```\n\n::: {.cell-output-stdout}\n```\n# Source: spark<?> [?? x 20]\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   <int> <int> <int>    <int>          <int>     <dbl>    <int>          <int>\n 1  2013     1     1      517            515         2      830            819\n 2  2013     1     1      533            529         4      850            830\n 3  2013     1     1      542            540         2      923            850\n 4  2013     1     1      544            545        -1     1004           1022\n 5  2013     1     1      554            600        -6      812            837\n 6  2013     1     1      554            558        -4      740            728\n 7  2013     1     1      555            600        -5      913            854\n 8  2013     1     1      557            600        -3      709            723\n 9  2013     1     1      557            600        -3      838            846\n10  2013     1     1      558            600        -2      753            745\n# … with more rows, and 12 more variables: arr_delay <dbl>, carrier <chr>,\n#   flight <int>, tailnum <chr>, origin <chr>, dest <chr>, air_time <dbl>,\n#   distance <dbl>, hour <dbl>, minute <dbl>, time_hour <dttm>, speed <dbl>\n```\n:::\n:::\n\n\n## Laziness\n\nWhen working with databases, `dplyr` tries to be as lazy as possible:\n\n  - It never pulls data into R unless you explicitly ask for it.\n\n  - It delays doing any work until the last possible moment: it collects\n    together everything you want to do and then sends it to the database\n    in one step.\n\nFor example, take the following\ncode:\n\n::: {.cell}\n\n```{.r .cell-code}\nc1 <- filter(\n  flights_tbl, \n  day == 17, month == 5, carrier %in% c('UA', 'WN', 'AA', 'DL')\n  )\n\nc2 <- select(c1, year, month, day, carrier, dep_delay, air_time, distance)\n\nc3 <- mutate(c2, air_time_hours = air_time / 60)\n\nc4 <- arrange(c3, year, month, day, carrier)\n```\n:::\n\nThis sequence of operations never actually touches the database. It’s\nnot until you ask for the data (e.g. by printing `c4`) that dplyr\nrequests the results from the database.\n\n::: {.cell}\n\n```{.r .cell-code}\nc4\n```\n\n::: {.cell-output-stdout}\n```\n# Source:     spark<?> [?? x 8]\n# Ordered by: year, month, day, carrier\n    year month   day carrier dep_delay air_time distance air_time_hours\n   <int> <int> <int> <chr>       <dbl>    <dbl>    <dbl>          <dbl>\n 1  2013     5    17 AA             -7      142     1089           2.37\n 2  2013     5    17 AA             -9      186     1389           3.1 \n 3  2013     5    17 AA             -6      143     1096           2.38\n 4  2013     5    17 AA             -7      119      733           1.98\n 5  2013     5    17 AA             -4      114      733           1.9 \n 6  2013     5    17 AA             -2      146     1085           2.43\n 7  2013     5    17 AA             -2      185     1372           3.08\n 8  2013     5    17 AA             -3      193     1598           3.22\n 9  2013     5    17 AA             -7      137      944           2.28\n10  2013     5    17 AA             -1      195     1389           3.25\n# … with more rows\n```\n:::\n:::\n\n## Piping\n\nYou can use\n[magrittr](https://cran.r-project.org/web/packages/magrittr/vignettes/magrittr.html)\npipes to write cleaner syntax. Using the same example from above, you\ncan write a much cleaner version like this:\n\n::: {.cell}\n\n```{.r .cell-code}\nc4 <- flights_tbl %>%\n  filter(month == 5, day == 17, carrier %in% c('UA', 'WN', 'AA', 'DL')) %>%\n  select(carrier, dep_delay, air_time, distance) %>%\n  mutate(air_time_hours = air_time / 60) %>% \n  arrange(carrier) \n```\n:::\n\n\n## Grouping\n\nThe `group_by()` function corresponds to the `GROUP BY` statement in SQL.\n\n::: {.cell}\n\n```{.r .cell-code}\nflights_tbl %>% \n  group_by(carrier) %>%\n  summarize(\n    count = n(), \n    mean_dep_delay = mean(dep_delay, na.rm = FALSE)\n    )\n```\n\n::: {.cell-output-stderr}\n```\nWarning: Missing values are always removed in SQL.\nUse `mean(x, na.rm = TRUE)` to silence this warning\nThis warning is displayed only once per session.\n```\n:::\n\n::: {.cell-output-stdout}\n```\n# Source: spark<?> [?? x 3]\n   carrier count mean_dep_delay\n   <chr>   <dbl>          <dbl>\n 1 WN      12275          17.7 \n 2 VX       5162          12.9 \n 3 YV        601          19.0 \n 4 DL      48110           9.26\n 5 OO         32          12.6 \n 6 B6      54635          13.0 \n 7 F9        685          20.2 \n 8 EV      54173          20.0 \n 9 US      20536           3.78\n10 UA      58665          12.1 \n# … with more rows\n```\n:::\n:::\n\n\n## Collecting to R\n\nYou can copy data from Spark into R’s memory by using `collect()`.\n\n::: {.cell}\n\n```{.r .cell-code}\ncarrierhours <- collect(c4)\n```\n:::\n\n`collect()` executes the Spark query and returns the results to R for\nfurther analysis and visualization.\n\n::: {.cell}\n\n```{.r .cell-code}\n# Test the significance of pairwise differences and plot the results\n\nwith(carrierhours, pairwise.t.test(air_time, carrier))\n```\n\n::: {.cell-output-stdout}\n```\n\n\tPairwise comparisons using t tests with pooled SD \n\ndata:  air_time and carrier \n\n   AA      DL      UA     \nDL 0.25057 -       -      \nUA 0.07957 0.00044 -      \nWN 0.07957 0.23488 0.00041\n\nP value adjustment method: holm \n```\n:::\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncarrierhours %>% \n  ggplot() + \n  geom_boxplot(aes(carrier, air_time_hours))\n```\n\n::: {.cell-output-display}\n![](dplyr_files/figure-html/unnamed-chunk-28-1.png){width=672}\n:::\n:::\n\n\n## SQL Translation\n\nIt’s relatively straightforward to translate R code to SQL (or indeed to\nany programming language) when doing simple mathematical operations of\nthe form you normally use when *filtering*, *mutating* and *summarizing.*\n`dplyr` knows how to convert the following R functions to Spark SQL:\n\n``` r\n# Basic math operators\n+, -, *, /, %%, ^\n  \n# Math functions\nabs, acos, asin, asinh, atan, atan2, ceiling, cos, cosh, exp, floor, log, \nlog10, round, sign, sin, sinh, sqrt, tan, tanh\n\n# Logical comparisons\n<, <=, !=, >=, >, ==, %in%\n\n# Boolean operations\n&, &&, |, ||, !\n\n# Character functions\npaste, tolower, toupper, nchar\n\n# Casting\nas.double, as.integer, as.logical, as.character, as.date\n\n# Basic aggregations\nmean, sum, min, max, sd, var, cor, cov, n\n```\n\n`dplyr` supports Spark SQL window functions. Window functions are used in\nconjunction with mutate and filter to solve a wide range of problems.\nYou can compare the `dplyr` syntax to the query it has generated by using\n`dplyr::show_query()`.\n\n::: {.cell}\n\n```{.r .cell-code}\n# Rank each flight within a daily\nranked <- flights_tbl %>%\n  group_by(year, month, day) %>%\n  select(dep_delay) %>% \n  mutate(rank = rank(desc(dep_delay)))\n\ndplyr::show_query(ranked)\n```\n\n::: {.cell-output-stdout}\n```\n<SQL>\nSELECT `year`, `month`, `day`, `dep_delay`, RANK() OVER (PARTITION BY `year`, `month`, `day` ORDER BY `dep_delay` DESC) AS `rank`\nFROM `flights`\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nranked \n```\n\n::: {.cell-output-stdout}\n```\n# Source: spark<?> [?? x 5]\n# Groups: year, month, day\n    year month   day dep_delay  rank\n   <int> <int> <int>     <dbl> <int>\n 1  2013     1     1       853     1\n 2  2013     1     1       379     2\n 3  2013     1     1       290     3\n 4  2013     1     1       285     4\n 5  2013     1     1       260     5\n 6  2013     1     1       255     6\n 7  2013     1     1       216     7\n 8  2013     1     1       192     8\n 9  2013     1     1       157     9\n10  2013     1     1       155    10\n# … with more rows\n```\n:::\n:::\n\n\n## Peforming Joins\n\nIt’s rare that a data analysis involves only a single table of data. In\npractice, you’ll normally have many tables that contribute to an\nanalysis, and you need flexible tools to combine them. In `dplyr`, there\nare three families of verbs that work with two tables at a time:\n\n  - Mutating joins, which add new variables to one table from matching\n    rows in another.\n\n  - Filtering joins, which filter observations from one table based on\n    whether or not they match an observation in the other table.\n\n  - Set operations, which combine the observations in the data sets as\n    if they were set elements.\n\nAll two-table verbs work similarly. The first two arguments are `x` and\n`y`, and provide the tables to combine. The output is always a new table\nwith the same type as `x`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflights_tbl %>% \n  left_join(airlines_tbl, by = \"carrier\") %>% \n  select(name, flight, dep_time)\n```\n\n::: {.cell-output-stdout}\n```\n# Source: spark<?> [?? x 3]\n   name                     flight dep_time\n   <chr>                     <int>    <int>\n 1 Delta Air Lines Inc.        461      554\n 2 JetBlue Airways             725      544\n 3 JetBlue Airways             507      555\n 4 JetBlue Airways              79      557\n 5 JetBlue Airways              49      558\n 6 ExpressJet Airlines Inc.   5708      557\n 7 United Air Lines Inc.      1545      517\n 8 United Air Lines Inc.      1714      533\n 9 United Air Lines Inc.      1696      554\n10 American Airlines Inc.     1141      542\n# … with more rows\n```\n:::\n:::\n\n\n## Sampling\n\nYou can use `sample_n()` and `sample_frac()` to take a random sample of\nrows: use `sample_n()` for a fixed number and `sample_frac()` for a\nfixed fraction.\n\n::: {.cell}\n\n```{.r .cell-code}\nsample_n(flights_tbl, 10) %>% \n  select(1:4)\n```\n\n::: {.cell-output-stdout}\n```\n# Source: spark<?> [?? x 4]\n    year month   day dep_time\n   <int> <int> <int>    <int>\n 1  2013    11    24     1039\n 2  2013     4    18     2026\n 3  2013     9    10     1643\n 4  2013     2     1     1625\n 5  2013     4    19      536\n 6  2013     3     8     1905\n 7  2013     9     3     1349\n 8  2013     3     5     1603\n 9  2013     1    14     1753\n10  2013     9    16      904\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsample_frac(flights_tbl, 0.01) %>% \n  count()\n```\n\n::: {.cell-output-stdout}\n```\n# Source: spark<?> [?? x 1]\n      n\n  <dbl>\n1  3368\n```\n:::\n:::\n\n## Hive Functions\n\nMany of Hive’s built-in functions (UDF) and built-in aggregate functions\n(UDAF) can be called inside dplyr’s mutate and summarize. The [Languange\nReference\nUDF](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF)\npage provides the list of available functions.\n\nThe following example uses the **datediff** and **current\\_date** Hive\nUDFs to figure the difference between the flight\\_date and the current\nsystem date:\n\n::: {.cell}\n\n```{.r .cell-code}\nflights_tbl %>% \n  mutate(\n    flight_date = paste(year,month,day,sep=\"-\"),\n    days_since = datediff(current_date(), flight_date)\n    ) %>%\n  group_by(flight_date,days_since) %>%\n  count() %>%\n  arrange(-days_since)\n```\n\n::: {.cell-output-stdout}\n```\n# Source:     spark<?> [?? x 3]\n# Groups:     flight_date\n# Ordered by: -days_since\n   flight_date days_since     n\n   <chr>            <int> <dbl>\n 1 2013-1-1          3311   842\n 2 2013-1-2          3310   943\n 3 2013-1-3          3309   914\n 4 2013-1-4          3308   915\n 5 2013-1-5          3307   720\n 6 2013-1-6          3306   832\n 7 2013-1-7          3305   933\n 8 2013-1-8          3304   899\n 9 2013-1-9          3303   902\n10 2013-1-10         3302   932\n# … with more rows\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nspark_disconnect(sc)\n```\n:::\n\n",
    "supporting": [
      "dplyr_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": [],
    "engineDependencies": {},
    "preserve": {},
    "postProcess": null
  }
}