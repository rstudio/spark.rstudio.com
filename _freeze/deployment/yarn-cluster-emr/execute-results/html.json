{
  "hash": "bc0a191bc9ad23c62184975d6bed57f8",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Using sparklyr with an Apache Spark cluster\"\nformat:\n  html:\n    theme: default\n    toc: true\nexecute:\n    eval: false\n    freeze: true\naliases:\n  - /examples/yarn-cluster-emr\n---\n\nThis document demonstrates how to use `sparklyr` with an Apache Spark cluster. Data are downloaded from the web and stored in Hive tables on HDFS across multiple worker nodes. RStudio Server is installed on the master node and orchestrates the analysis in spark. Here is the basic workflow.\n\n![](/images/deployment/amazon-emr/workflowShare.png)\n\n# Data preparation\n\n## Set up the cluster\n\nThis demonstration uses Amazon Web Services (AWS), but it could just as easily use Microsoft, Google, or any other provider. \nWe will use Elastic Map Reduce (EMR) to easily set up a cluster with two core nodes and one master node. Nodes use virtual servers from the Elastic Compute Cloud (EC2). *Note: There is no free tier for EMR, charges will apply.*\n\nBefore beginning this setup we assume you have:\n\n-   Familiarity with and access to an AWS account\n-   Familiarity with basic linux commands\n-   Sudo privileges in order to install software from the command line\n\n![](/images/deployment/amazon-emr/emrArchitecture.png){width=\"334\"}\n\n### Build an EMR cluster\n\nBefore beginning the EMR wizard setup, make sure you create the following in AWS:\n\n-   An AWS key pair (.pem key) so you can SSH into the EC2 master node\n-   A security group that gives you access to port 22 on your IP and port 8787 from anywhere\n\n![](/images/deployment/amazon-emr/awsNewSecurityGroup.png)\n\n------------------------------------------------------------------------\n\n#### Step 1: Select software\n\nMake sure to select Hive and Spark as part of the install. Note that by choosing Spark, R will also be installed on the master node as part of the distribution.\n\n![](/images/deployment/amazon-emr/emrConfigStep1.png)\n\n------------------------------------------------------------------------\n\n#### Step 2: Select hardware\n\nInstall 2 core nodes and one master node with m3.xlarge 80 GiB storage per node. You can easily increase the number of nodes later.\n\n![](/images/deployment/amazon-emr/emrConfigStep2.png)\n\n------------------------------------------------------------------------\n\n#### Step 3: Select general cluster settings\n\nClick next on the general cluster settings.\n\n![](/images/deployment/amazon-emr/emrConfigStep3.png)\n\n------------------------------------------------------------------------\n\n#### Step 4: Select security\n\nEnter your EC2 key pair and security group. Make sure the security group has ports 22 and 8787 open.\n\n![](/images/deployment/amazon-emr/emrConfigStep4.png)\n\n------------------------------------------------------------------------\n\n### Connect to EMR\n\nThe cluster page will give you details about your EMR cluster and instructions on connecting.\n\n![](/images/deployment/amazon-emr/awsClusterConnect.png)\n\nConnect to the master node via SSH using your key pair. Once you connect you will see the EMR welcome.\n\n\n::: {.cell}\n\n```{.bash .cell-code}\n# Log in to master node\nssh -i ~/spark-demo.pem hadoop@ec2-52-10-102-11.us-west-2.compute.amazonaws.com\n```\n:::\n\n\n![](/images/deployment/amazon-emr/emrLogin.png)\n\n### Install RStudio Server\n\nEMR uses Amazon Linux which is based on Centos. Update your master node and install dependencies that will be used by R packages.\n\n\n::: {.cell}\n\n```{.bash .cell-code}\n# Update\nsudo yum update\nsudo yum install libcurl-devel openssl-devel # used for devtools\n```\n:::\n\n\nThe installation of RStudio Server is easy. Download the [preview version](https://www.rstudio.com/products/rstudio/download/preview/) of RStudio and install on the master node.\n\n\n::: {.cell}\n\n```{.bash .cell-code}\n# Install RStudio Server\nwget -P /tmp https://s3.amazonaws.com/rstudio-dailybuilds/rstudio-server-rhel-0.99.1266-x86_64.rpm\nsudo yum install --nogpgcheck /tmp/rstudio-server-rhel-0.99.1266-x86_64.rpm\n```\n:::\n\n\n### Create a User\n\nCreate a user called `rstudio-user` that will perform the data analysis. Create a user directory for `rstudio-user` on HDFS with the `hadoop fs` command.\n\n\n::: {.cell}\n\n```{.bash .cell-code}\n# Make User\nsudo useradd -m rstudio-user\nsudo passwd rstudio-user\n\n# Create new directory in hdfs\nhadoop fs -mkdir /user/rstudio-user\nhadoop fs -chmod 777 /user/rstudio-user\n```\n:::\n\n\n## Download flights data\n\nThe [flights](http://stat-computing.org/dataexpo/2009/the-data.html) data is a well known data source representing 123 million flights over 22 years. It consumes roughly 12 GiB of storage in uncompressed CSV format in yearly files.\n\n#### Switch User\n\nFor data loading and analysis, make sure you are logged in as regular user.\n\n\n::: {.cell}\n\n```{.bash .cell-code}\n# create directories on hdfs for new user\nhadoop fs -mkdir /user/rstudio-user\nhadoop fs -chmod 777 /user/rstudio-user\n\n# switch user\nsu rstudio-user\n```\n:::\n\n\n### Download data\n\nRun the following script to download data from the web onto your master node. Download the yearly flight data and the airlines lookup table.\n\n\n::: {.cell}\n\n```{.bash .cell-code}\n# Make download directory\nmkdir /tmp/flights\n\n# Download flight data by year\nfor i in {1987..2008}\n  do\n  \techo \"$(date) $i Download\"\n    fnam=$i.csv.bz2\n    wget -O /tmp/flights/$fnam http://stat-computing.org/dataexpo/2009/$fnam\n  \techo \"$(date) $i Unzip\"\n    bunzip2 /tmp/flights/$fnam\n  done\n\n# Download airline carrier data\nwget -O /tmp/airlines.csv http://www.transtats.bts.gov/Download_Lookup.asp?Lookup=L_UNIQUE_CARRIERS\n\n# Download airports data\nwget -O /tmp/airports.csv https://raw.githubusercontent.com/jpatokal/openflights/master/data/airports.dat\n```\n:::\n\n\n### Distribute into HDFS\n\nCopy data into HDFS using the `hadoop fs` command.\n\n\n::: {.cell}\n\n```{.bash .cell-code}\n# Copy flight data to HDFS\nhadoop fs -mkdir /user/rstudio-user/flights/\nhadoop fs -put /tmp/flights /user/rstudio-user/\n\n# Copy airline data to HDFS\nhadoop fs -mkdir /user/rstudio-user/airlines/\nhadoop fs -put /tmp/airlines.csv /user/rstudio-user/airlines\n\n# Copy airport data to HDFS\nhadoop fs -mkdir /user/rstudio-user/airports/\nhadoop fs -put /tmp/airports.csv /user/rstudio-user/airports\n```\n:::\n\n\n## Create Hive tables\n\nLaunch Hive from the command line.\n\n\n::: {.cell}\n\n```{.bash .cell-code}\n# Open Hive prompt\nhive\n```\n:::\n\n\nCreate the metadata that will structure the flights table. Load data into the Hive table.\n\n``` sql\n# Create metadata for flights\nCREATE EXTERNAL TABLE IF NOT EXISTS flights\n(\nyear int,\nmonth int,\ndayofmonth int,\ndayofweek int,\ndeptime int,\ncrsdeptime int,\narrtime int, \ncrsarrtime int,\nuniquecarrier string,\nflightnum int,\ntailnum string, \nactualelapsedtime int,\ncrselapsedtime int,\nairtime string,\narrdelay int,\ndepdelay int, \norigin string,\ndest string,\ndistance int,\ntaxiin string,\ntaxiout string,\ncancelled int,\ncancellationcode string,\ndiverted int,\ncarrierdelay string,\nweatherdelay string,\nnasdelay string,\nsecuritydelay string,\nlateaircraftdelay string\n)\nROW FORMAT DELIMITED\nFIELDS TERMINATED BY ','\nLINES TERMINATED BY '\\n'\nTBLPROPERTIES(\"skip.header.line.count\"=\"1\");\n\n# Load data into table\nLOAD DATA INPATH '/user/rstudio-user/flights' INTO TABLE flights;\n```\n\nCreate the metadata that will structure the airlines table. Load data into the Hive table.\n\n``` sql\n# Create metadata for airlines\nCREATE EXTERNAL TABLE IF NOT EXISTS airlines\n(\nCode string,\nDescription string\n)\nROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde'\nWITH SERDEPROPERTIES\n(\n\"separatorChar\" = '\\,',\n\"quoteChar\"     = '\\\"'\n)\nSTORED AS TEXTFILE\ntblproperties(\"skip.header.line.count\"=\"1\");\n\n# Load data into table\nLOAD DATA INPATH '/user/rstudio-user/airlines' INTO TABLE airlines;\n```\n\nCreate the metadata that will structure the airports table. Load data into the Hive table.\n\n``` sql\n# Create metadata for airports\nCREATE EXTERNAL TABLE IF NOT EXISTS airports\n(\nid string,\nname string,\ncity string,\ncountry string,\nfaa string,\nicao string,\nlat double,\nlon double,\nalt int,\ntz_offset double,\ndst string,\ntz_name string\n)\nROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde'\nWITH SERDEPROPERTIES\n(\n\"separatorChar\" = '\\,',\n\"quoteChar\"     = '\\\"'\n)\nSTORED AS TEXTFILE;\n\n# Load data into table\nLOAD DATA INPATH '/user/rstudio-user/airports' INTO TABLE airports;\n```\n\n## Connect to Spark\n\nLog in to RStudio Server by pointing a browser at your master node IP:8787.\n\n![](/images/deployment/amazon-emr/rstudioLogin.png){width=\"296\"}\n\nSet the environment variable `SPARK_HOME` and then run `spark_connect`. After connecting you will be able to browse the Hive metadata in the RStudio Server Spark pane.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Connect to Spark\nlibrary(sparklyr)\nlibrary(dplyr)\nlibrary(ggplot2)\nSys.setenv(SPARK_HOME=\"/usr/lib/spark\")\nconfig <- spark_config()\nsc <- spark_connect(master = \"yarn-client\", config = config, version = '1.6.2')\n```\n:::\n\n\nOnce you are connected, you will see the Spark pane appear along with your hive tables.\n\n![](/images/deployment/amazon-emr/rstudioSparkPane.png){width=\"367\"}\n\nYou can inspect your tables by clicking on the data icon.\n\n![](/images/deployment/amazon-emr/rstudioData.png){width=\"549\"}\n\n# Data analysis\n\nIs there evidence to suggest that some airline carriers make up time in flight? This analysis predicts time gained in flight by airline carrier.\n\n![](/images/deployment/amazon-emr/rstudio.png)\n\n## Cache the tables into memory\n\nUse `tbl_cache` to load the flights table into memory. Caching tables will make analysis much faster. Create a dplyr reference to the Spark DataFrame.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Cache flights Hive table into Spark\ntbl_cache(sc, 'flights')\nflights_tbl <- tbl(sc, 'flights')\n\n# Cache airlines Hive table into Spark\ntbl_cache(sc, 'airlines')\nairlines_tbl <- tbl(sc, 'airlines')\n\n# Cache airports Hive table into Spark\ntbl_cache(sc, 'airports')\nairports_tbl <- tbl(sc, 'airports')\n```\n:::\n\n\n## Create a model data set\n\nFilter the data to contain only the records to be used in the fitted model. Join carrier descriptions for reference. Create a new variable called `gain` which represents the amount of time gained (or lost) in flight.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Filter records and create target variable 'gain'\nmodel_data <- flights_tbl %>%\n  filter(!is.na(arrdelay) & !is.na(depdelay) & !is.na(distance)) %>%\n  filter(depdelay > 15 & depdelay < 240) %>%\n  filter(arrdelay > -60 & arrdelay < 360) %>%\n  filter(year >= 2003 & year <= 2007) %>%\n  left_join(airlines_tbl, by = c(\"uniquecarrier\" = \"code\")) %>%\n  mutate(gain = depdelay - arrdelay) %>%\n  select(year, month, arrdelay, depdelay, distance, uniquecarrier, description, gain)\n\n# Summarize data by carrier\nmodel_data %>%\n  group_by(uniquecarrier) %>%\n  summarize(description = min(description), gain=mean(gain), \n            distance=mean(distance), depdelay=mean(depdelay)) %>%\n  select(description, gain, distance, depdelay) %>%\n  arrange(gain)\n```\n:::\n\n\n    Source:   query [?? x 4]\n    Database: spark connection master=yarn-client app=sparklyr local=FALSE\n\n                        description       gain  distance depdelay\n                              <chr>      <dbl>     <dbl>    <dbl>\n    1        ATA Airlines d/b/a ATA -3.3480120 1134.7084 56.06583\n    2  ExpressJet Airlines Inc. (1) -3.0326180  519.7125 59.41659\n    3                     Envoy Air -2.5434415  416.3716 53.12529\n    4       Northwest Airlines Inc. -2.2030586  779.2342 48.52828\n    5          Delta Air Lines Inc. -1.8248026  868.3997 50.77174\n    6   AirTran Airways Corporation -1.4331555  641.8318 54.96702\n    7    Continental Air Lines Inc. -0.9617003 1116.6668 57.00553\n    8        American Airlines Inc. -0.8860262 1074.4388 55.45045\n    9             Endeavor Air Inc. -0.6392733  467.1951 58.47395\n    10              JetBlue Airways -0.3262134 1139.0443 54.06156\n    # ... with more rows\n\n## Train a linear model\n\nPredict time gained or lost in flight as a function of distance, departure delay, and airline carrier.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Partition the data into training and validation sets\nmodel_partition <- model_data %>% \n  sdf_partition(train = 0.8, valid = 0.2, seed = 5555)\n\n# Fit a linear model\nml1 <- model_partition$train %>%\n  ml_linear_regression(gain ~ distance + depdelay + uniquecarrier)\n\n# Summarize the linear model\nsummary(ml1)\n```\n:::\n\n\n    Deviance Residuals: (approximate):\n         Min       1Q   Median       3Q      Max \n    -305.422   -5.593    2.699    9.750  147.871 \n\n    Coefficients:\n                        Estimate  Std. Error  t value  Pr(>|t|)    \n    (Intercept)      -1.24342576  0.10248281 -12.1330 < 2.2e-16 ***\n    distance          0.00326600  0.00001670 195.5709 < 2.2e-16 ***\n    depdelay         -0.01466233  0.00020337 -72.0977 < 2.2e-16 ***\n    uniquecarrier_AA -2.32650517  0.10522524 -22.1098 < 2.2e-16 ***\n    uniquecarrier_AQ  2.98773637  0.28798507  10.3746 < 2.2e-16 ***\n    uniquecarrier_AS  0.92054894  0.11298561   8.1475 4.441e-16 ***\n    uniquecarrier_B6 -1.95784698  0.11728289 -16.6934 < 2.2e-16 ***\n    uniquecarrier_CO -2.52618081  0.11006631 -22.9514 < 2.2e-16 ***\n    uniquecarrier_DH  2.23287189  0.11608798  19.2343 < 2.2e-16 ***\n    uniquecarrier_DL -2.68848119  0.10621977 -25.3106 < 2.2e-16 ***\n    uniquecarrier_EV  1.93484736  0.10724290  18.0417 < 2.2e-16 ***\n    uniquecarrier_F9 -0.89788137  0.14422281  -6.2257 4.796e-10 ***\n    uniquecarrier_FL -1.46706706  0.11085354 -13.2343 < 2.2e-16 ***\n    uniquecarrier_HA -0.14506644  0.25031456  -0.5795    0.5622    \n    uniquecarrier_HP  2.09354855  0.12337515  16.9690 < 2.2e-16 ***\n    uniquecarrier_MQ -1.88297535  0.10550507 -17.8473 < 2.2e-16 ***\n    uniquecarrier_NW -2.79538927  0.10752182 -25.9983 < 2.2e-16 ***\n    uniquecarrier_OH  0.83520117  0.11032997   7.5700 3.730e-14 ***\n    uniquecarrier_OO  0.61993842  0.10679884   5.8047 6.447e-09 ***\n    uniquecarrier_TZ -4.99830389  0.15912629 -31.4109 < 2.2e-16 ***\n    uniquecarrier_UA -0.68294396  0.10638099  -6.4198 1.365e-10 ***\n    uniquecarrier_US -0.61589284  0.10669583  -5.7724 7.815e-09 ***\n    uniquecarrier_WN  3.86386059  0.10362275  37.2878 < 2.2e-16 ***\n    uniquecarrier_XE -2.59658123  0.10775736 -24.0966 < 2.2e-16 ***\n    uniquecarrier_YV  3.11113140  0.11659679  26.6828 < 2.2e-16 ***\n    ---\n    Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\n    R-Squared: 0.02385\n    Root Mean Squared Error: 17.74\n\n## Assess model performance\n\nCompare the model performance using the validation data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate average gains by predicted decile\nmodel_deciles <- lapply(model_partition, function(x) {\n  sdf_predict(ml1, x) %>%\n    mutate(decile = ntile(desc(prediction), 10)) %>%\n    group_by(decile) %>%\n    summarize(gain = mean(gain)) %>%\n    select(decile, gain) %>%\n    collect()\n})\n\n# Create a summary dataset for plotting\ndeciles <- rbind(\n  data.frame(data = 'train', model_deciles$train),\n  data.frame(data = 'valid', model_deciles$valid),\n  make.row.names = FALSE\n)\n\n# Plot average gains by predicted decile\ndeciles %>%\n  ggplot(aes(factor(decile), gain, fill = data)) +\n  geom_bar(stat = 'identity', position = 'dodge') +\n  labs(title = 'Average gain by predicted decile', x = 'Decile', y = 'Minutes')\n```\n:::\n\n\n![](/images/deployment/amazon-emr/performance-1.png)\n\n## Visualize predictions\n\nCompare actual gains to predicted gains for an out of time sample.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Select data from an out of time sample\ndata_2008 <- flights_tbl %>%\n  filter(!is.na(arrdelay) & !is.na(depdelay) & !is.na(distance)) %>%\n  filter(depdelay > 15 & depdelay < 240) %>%\n  filter(arrdelay > -60 & arrdelay < 360) %>%\n  filter(year == 2008) %>%\n  left_join(airlines_tbl, by = c(\"uniquecarrier\" = \"code\")) %>%\n  mutate(gain = depdelay - arrdelay) %>%\n  select(year, month, arrdelay, depdelay, distance, uniquecarrier, description, gain, origin,dest)\n\n# Summarize data by carrier\ncarrier <- sdf_predict(ml1, data_2008) %>%\n  group_by(description) %>%\n  summarize(gain = mean(gain), prediction = mean(prediction), freq = n()) %>%\n  filter(freq > 10000) %>%\n  collect\n\n# Plot actual gains and predicted gains by airline carrier\nggplot(carrier, aes(gain, prediction)) + \n  geom_point(alpha = 0.75, color = 'red', shape = 3) +\n  geom_abline(intercept = 0, slope = 1, alpha = 0.15, color = 'blue') +\n  geom_text(aes(label = substr(description, 1, 20)), size = 3, alpha = 0.75, vjust = -1) +\n  labs(title='Average Gains Forecast', x = 'Actual', y = 'Predicted')\n```\n:::\n\n\n![](/images/deployment/amazon-emr/forecast-1.png)\n\nSome carriers make up more time than others in flight, but the differences are relatively small. The average time gains between the best and worst airlines is only six minutes. The best predictor of time gained is not carrier but flight distance. The biggest gains were associated with the longest flights.\n\n# Share Insights\n\nThis simple linear model contains a wealth of detailed information about carriers, distances traveled, and flight delays. These detailed insights can be conveyed to a non-technical audiance via an interactive [flexdashboard](http://rmarkdown.rstudio.com/flexdashboard/index.html).\n\n## Build dashboard\n\nAggregate the scored data by origin, destination, and airline. Save the aggregated data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Summarize by origin, destination, and carrier\nsummary_2008 <- sdf_predict(ml1, data_2008) %>%\n  rename(carrier = uniquecarrier, airline = description) %>%\n  group_by(origin, dest, carrier, airline) %>%\n  summarize(\n    flights = n(),\n    distance = mean(distance),\n    avg_dep_delay = mean(depdelay),\n    avg_arr_delay = mean(arrdelay),\n    avg_gain = mean(gain),\n    pred_gain = mean(prediction)\n    )\n\n# Collect and save objects\npred_data <- collect(summary_2008)\nairports <- collect(select(airports_tbl, name, faa, lat, lon))\nml1_summary <- capture.output(summary(ml1))\nsave(pred_data, airports, ml1_summary, file = 'flights_pred_2008.RData')\n```\n:::\n\n\n## Publish dashboard\n\nUse the saved data to build an R Markdown [flexdashboard](http://rmarkdown.rstudio.com/flexdashboard/index.html). Publish the flexdashboard to [Shiny Server](https://www.rstudio.com/products/shiny-server-pro/), [Shinyapps.io](https://www.rstudio.com/products/shinyapps/) or [RStudio Connect](https://www.rstudio.com/products/connect/).\n\n![](/images/deployment/amazon-emr/flightsDashboard.png)\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}