---
title: "Export a Spark pipeline for serving"
execute:
  freeze: true
---

```{r, eval=ecodown::examples_not_run()}
#| include: false
options("pillar.width" = 60)
library(sparklyr) 
library(dplyr)
```

*R/mleap.R*

## ml_write_bundle

## Description
 This functions serializes a Spark pipeline model into an MLeap bundle. 


## Usage
```r
 
ml_write_bundle(x, sample_input, path, overwrite = FALSE) 
```

## Arguments
|Arguments|Description|
|---|---|
| x | A Spark pipeline model object. |
| sample_input | A sample input Spark DataFrame with the expected schema. |
| path | Where to save the bundle. |
| overwrite | Whether to overwrite an existing file, defaults to `FALSE`. |





## Examples
```{r, eval=ecodown::examples_run()}
library(mleap)
 
```
```{r, eval=ecodown::examples_not_run()}
library(mleap)
 
library(sparklyr) 
sc <- spark_connect(master = "local") 
mtcars_tbl <- sdf_copy_to(sc, mtcars, overwrite = TRUE) 
pipeline <- ml_pipeline(sc) %>% 
  ft_binarizer("hp", "big_hp", threshold = 100) %>% 
  ft_vector_assembler(c("big_hp", "wt", "qsec"), "features") %>% 
  ml_gbt_regressor(label_col = "mpg") 
pipeline_model <- ml_fit(pipeline, mtcars_tbl) 
model_path <- file.path(tempdir(), "mtcars_model.zip") 
ml_write_bundle(pipeline_model,  
                mtcars_tbl, 
                model_path, 
                overwrite = TRUE) 
 
 
```



```{r, eval=ecodown::examples_not_run()}
#| include: false
spark_disconnect_all()
```
