---
title: "Tune `tidymodels` remotely in Spark Connect"
execute:
  eval: true
  freeze: true
---

```{r}
#| include: false

run_r <- FALSE

```


```{r}
#| include: false

library(sparklyr)
library(tidymodels)
library(readmission)

if(FALSE) { # if (!interactive()) {
  pysparklyr::install_pyspark("4.1.0", python_version = "3.12")  
  reticulate::py_install("rpy2", envname = "r-sparklyr-pyspark-4.1")
}

# TODO: Remove before publishing
# readmission <- readmission[1:1000, ]
```

## Intro

Use the `tidymodels` objects created locally in R, to run the hyper-parameter
tuning in Spark.  With one call, `sparklyr` will upload 
the `tidymodels` objects,  execute the parallel jobs run remotely, and return
the finalized tuned object to the local R session.

::: {#fig-cluster}
```{mermaid}
%%| fig-width: 6
flowchart RL
  subgraph sc [Spark Connect]
   p[Parallel processes]
  end
  r[local R]  -- Re-samples --> sc
  sc -.- rs[Results] -.-> r
  r -- Model --> sc
  r -- Pre-processor --> sc
  style sc fill:#F0B675,stroke:#666,color:#000;
  style p fill:#F8DDBF,stroke:#666,color:#000;
  style r fill:#75C7F0,stroke:#666,color:#000;
  style rs fill:#333,stroke:#333,color:#fff;
  linkStyle default stroke:#666,color:#000
```

Model tuning in a Spark cluster
:::

To do this use `tune_grid_spark()` instead of calling `tune`'s `tune_grid()`
function.  The function accepts the exact same arguments as `tune_grid()`. The 
only required added argument is the Spark session.

**It is important to note that we are not speaking of "big data", but rather of 
something more like  "big processing"**. 
Processing numerous tuning combinations is what makes the process take
a long time. Each combination has to be individually fitted, the resulting model
is then used run predictions, and lastly the results of the predictions to
estimate metrics. The more of these individual combinations that can run in 
parallel the more time is saved, and Spark is particularly good at this sort
of processing. Additionally, Spark is a more widely available distributed 
computing infrastructure, as opposed to something such a grid computer This 
opens a new avenue for us to take advantage of vast resources, and without
having to change existing code, or having to learn a new API.

## Installation

The latest versions of `sparklyr`, `pysparklyr` and `tune` are needed:

```{r}
#| eval: false

# TODO: Replace with actual installation instructions at release time

remotes::install_github("sparklyr/sparklyr", ref = "grid2")
remotes::install_github("tidymodels/tune", ref = "grid2")
remotes::install_github("mlverse/pysparklyr", ref = "grid2")
```


## Prepare locally

The standard framework for Machine Learning in R is  [Tidymodels](https://www.tidymodels.org/). 
It is a collection of packages that are designed to work together to provide 
everything from re-sampling, to pre-processing, to model tuning, to performance 
measurement. 

In this article, we will follow an example of tuning a model of hospital 
readmission data. The following code prepares the re-sampling, pre-processing
and model specification. All of these steps are processed locally in R. 


```{r}
#| eval: !expr 'run_r'

library(tidymodels)
library(readmission)

set.seed(1)

# Data set resampling 
readmission_splits <- initial_split(readmission, strata = readmitted)

readmission_folds <- vfold_cv(
  data = training(readmission_splits),
  strata = readmitted
  )

# Data pre-processing
recipe_basic <- recipe(readmitted ~ ., data = readmission) |>
  step_mutate(
    race = factor(case_when(
      !(race %in% c("Caucasian", "African American")) ~ "Other",
      .default = race
    ))
  ) |>
  step_unknown(all_nominal_predictors()) |>
  step_YeoJohnson(all_numeric_predictors()) |>
  step_normalize(all_numeric_predictors()) |>
  step_dummy(all_nominal_predictors())

# Model specification
spec_bt <- boost_tree(
  mode = "classification",
  mtry = tune(), # Part of the hyper-parameters to tune
  learn_rate = tune(), # Part of the hyper-parameters to tune
  trees = 10
  )
```

Typically, the next step is calling `tune_grid()` to run the hyper-parameter
tuning. This is where we will diverge in order to use Spark, instead of our 
laptop, to tune the model.

## Tune in Spark Connect

Remote model tuning is only available for Spark Connect connections,
and its vendor variants such as [Databricks Connect](../deployment/databricks-connect.qmd). 

### Spark requirements

In all of its nodes, the Spark cluster will need an R run-time, and recent 
installations of some R packages. There is also a Python package requirement:

**R**

- `tidymodels`

- `reticulate`

**Python**

- `rpy2`

If tuning on a model not available in base R, then the package containing that
model will need to be installed. In the example on this article, the default
for `boost_tree()` is XGboost. This means that the `xbgoost` package should be
available in the cluster.

### Connect to Spark

To show a full example in this article, we have included the steps to
start a *local* Spark Connect service. Keep in mind that it is not necessary
to create anything local if you already have a Spark Connect service available
somewhere else, such as a vendor provided cluster. 

1. Install Spark locally if the version you wish to use is not available locally 
yet:

```{r}
#| eval: false
#| 
library(sparklyr)

spark_install("4.1.0")
```

2. Start the Spark Connect service locally. Make sure to match the Spark version
you recently installed:

```{r}
#| eval: !expr 'run_r'
pysparklyr::spark_connect_service_start("4.1.0", python_version = "3.12")
```

3. Connect to Spark:

```{r}
#| eval: !expr 'run_r'
sc <- spark_connect(
  "sc://localhost",
  method = "spark_connect",
  version = "4.1.0"
  )
```

### Tune the model

Once connected to Spark, to execute the tuning run: 

```{r}
#| eval: !expr 'run_r'
spark_results <- tune_grid_spark(
  sc = sc, # Spark connection
  object = spec_bt, # Model specification (`parsnip`)
  preprocessor = recipe_basic, 
  resamples = readmission_folds 
  )
```

As part of adding this feature, `sparklyr` ported a lot of the functionality
directly from the `tidymodels` packages in order to offer an equivalent 
experience, as well as to perform the same checks. The resulting object will 
look indistinguishable from that created directly by `tidymodels` locally in R:

```{r}
#| eval: !expr 'run_r'
spark_results
```

The object can now be used to inspect and used to finalize the model 
selection.

```{r}
#| eval: !expr 'run_r'
autoplot(spark_results)
```


## Comparing results

The steps in this section should not be part of an every day workflow. It is
included here for comparison purposes. We are comparing the results from 
Spark versus local R. 

```{r}
#| eval: !expr 'run_r'
results <- tune_grid(spec_bt, recipe_basic, readmission_folds)

# Use show_best() to compare the recommendations
show_best(results)

show_best(spark_results)
```

The results are identical because Spark is running locally. It should not be
surprising if the results are different if using Spark remotely. Differences in
Operating System, R, and packages can affect the results. Reproducibility is not
impacted because the remote job will always return the same results.  `sparklyr`
replicates how `tidymodels` sets the seed for each run. 

## Parallel processing in Spark

In Spark, the term **job** differs from the term **task**. A single job
contains multiple tasks that can run in parallel. Spark will run as many 
*concurrent tasks* as there are CPU cores that the cluster makes available to
that particular job. In the example on @fig-job-task, a single job is running
4 tasks in parallel thanks to each running in a separate core.

::: {#fig-job-task}
```{mermaid}
%%| fig-width: 6
flowchart RL
  subgraph j [<b>Job</b>]
   t1[<b>Task 1</b> <br/> Core 1]
   t2[<b>Task 2</b> <br/> Core 2]
   t3[<b>Task 3</b> <br/> Core 3]
   t4[<b>Task 4</b> <br/> Core 4]
  end
  style j fill:#F8DDBF,stroke:#666,color:#000;
  style t1 fill:#F7EADC,stroke:#666,color:#444;
  style t2 fill:#F7EADC,stroke:#666,color:#444;
  style t3 fill:#F7EADC,stroke:#666,color:#444;
  style t4 fill:#F7EADC,stroke:#666,color:#444;
  linkStyle default stroke:#666,color:#000
```

Job vs. Task in Spark example
:::

How this relates to `tune_grid_spark()` depends on how the parallel processing
flag is set. As with `tune_grid()`, that is driven by setting a value for
`parallel_over` in the control grid: 

```{r}
#| eval: false

cntrl <- control_grid(parallel_over = "resamples")

spark_results <- tune_grid_spark(sc, spec_bt, recipe_basic, readmission_folds, control = cntrl)
```

There are two possible values to use in `parallel_over`: 

1. **resamples** *(default)* - The tuning is performed in parallel over the 
resamples alone. In the example, `readmission_folds` has 10 folds/resamples. If 
we had 4 tasks available from Spark, then the 10 folds would be distributed
across that number of tasks. This means that some two tasks will run 2 folds, 
the the other two will run 3 folds, see @fig-resamples. Inside the tasks, the
2 or 3 folds will run sequentially, but the 4 tasks will start processing
folds at the same time. 

::: {#fig-resamples}
```{mermaid}
%%| fig-width: 6
flowchart RL
  subgraph j [<b>Job</b>]
   t1[<b>Task 1</b> <br/> Fold 1 <br/> Fold 2 <br/> Fold 3]
   t2[<b>Task 2</b> <br/> Fold 4 <br/> Fold 5 <br/> Fold 6]
   t3[<b>Task 3</b> <br/> Fold 7 <br/> Fold 8]
   t4[<b>Task 4</b> <br/> Fold 9 <br/> Fold 10]
  end
  style j fill:#F8DDBF,stroke:#666,color:#000;
  style t1 fill:#F7EADC,stroke:#666,color:#444;
  style t2 fill:#F7EADC,stroke:#666,color:#444;
  style t3 fill:#F7EADC,stroke:#666,color:#444;
  style t4 fill:#F7EADC,stroke:#666,color:#444;
  linkStyle default stroke:#666,color:#000
```

How "resamples" works in Spark
:::

1. **everything** - The tuning will be performed in parallel for each 
individual permutation of resamples and tuning combinations.  In the example,
there are 10 tune combinations, which are then combined with the 10 
folds/resamples, giving us 100 total combinations.  If we had 4 tasks available from
Spark, then each would run 25 combinations.

::: {#fig-everything}
```{mermaid}
%%| fig-width: 6
flowchart RL
  subgraph j [<b>Job</b>]
   t1[<b>Task 1</b> <br/> Fold 1 - Combo 1 <br/> ... <br/> ...  <br/> Fold 3 - Combo 5]
   t2[<b>Task 2</b> <br/> Fold 3 - Combo 6 <br/> ... <br/> ...  <br/> Fold 5 - Combo 10]
   t3[<b>Task 3</b> <br/> Fold 6 - Combo 1 <br/> ... <br/> ...  <br/> Fold 8 - Combo 5]
   t4[<b>Task 4</b> <br/> Fold 8 - Combo 6 <br/> ... <br/> ...  <br/> Fold 10 - Combo 10]
  end
  style j fill:#F8DDBF,stroke:#666,color:#000;
  style t1 fill:#F7EADC,stroke:#666,color:#444;
  style t2 fill:#F7EADC,stroke:#666,color:#444;
  style t3 fill:#F7EADC,stroke:#666,color:#444;
  style t4 fill:#F7EADC,stroke:#666,color:#444;
  linkStyle default stroke:#666,color:#000
```

How "everything" works in Spark
:::

In either case, despite the number of re-samples, or number of tuning +
re-samples combinations, the limit of how many processes run in parallel is set
by how many tasks are created for the job.  The more nodes and cores there are 
available in the Spark cluster, the more possible parallel tasks could be 
schedule to run for the job. 


```{r}
#| eval: !expr 'run_r'
#| include: false
pysparklyr::spark_connect_service_stop()
```


## Retrieving predictions a.k.a `save_pred = TRUE`

`sparklyr` supports getting the out-of-sample predictions if they are saved. That
is done by using `control_grid()` when calling `tune_grid()`.

```{r}
#| eval: !expr 'run_r'
cntrl <- control_grid(save_pred = TRUE)

spark_results <- tune_grid_spark(sc, spec_bt, recipe_basic, readmission_folds, control = cntrl)
```

There will be a second Spark job that executes. The job only reads the files 
containing the predictions created during the tuning job, and return the
data back to the local R session.

The predictions are added to the resulting tuning object the same way `tune`
would have done that locally in R.

```{r}
#| eval: !expr 'run_r'
collect_predictions(spark_results)
```
