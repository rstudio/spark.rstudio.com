---
title: "Option 2 - Working inside of Databricks"
output:
  html_document:
    toc: true
    toc_depth: 2
    toc_float:
      collapsed: false
params:
  width: 600
---



<div id="overview" class="section level2">
<h2>Overview</h2>
<p>If the recommended path of connecting to Spark remotely with Databricks Connect
does not apply to your use case, then you can install RStudio Server Pro
directly within a Databricks cluster as described in the sections below.</p>
<p>With this configuration, RStudio Server Pro is installed on the Spark driver
node and allows users to work locally with Spark.</p>
<p><img src="/images/deployment/databricks/rstudio-databricks-local.png" width='800px' align='center'/></p>
<p>This configuration can result in increased complexity, limited connectivity to
other storage and compute sources, resource contention between RStudio Server
Pro and Databricks, and maintenance concerns due to the ephemeral nature of
Databricks clusters.</p>
<p>For additional details, refer to the
<a href="https://docs.databricks.com/spark/latest/sparkr/rstudio.html#frequently-asked-questions-faq">FAQ for RStudio in the Databricks Documentation</a>.</p>
</div>
<div id="advantages-and-limitations" class="section level2">
<h2>Advantages and limitations</h2>
<p>Advantages:</p>
<ul>
<li>Ability for users to connect <code>sparklyr</code> to Spark without configuring remote
connectivity</li>
<li>Provides a high-bandwidth connection between R and the Spark JVM processes
because they are running on the same machine</li>
<li>Can load data from the cluster directly into an R session since RStudio Server
Pro is installed within the Databricks cluster</li>
</ul>
<p>Limitations:</p>
<ul>
<li>If the Databricks cluster is restarted or terminated, then the instance of
RStudio Server Pro will be terminated and its configuration will be lost</li>
<li>If users do not persist their code through version control or the Databricks
File System, then you risk losing user’s work if the cluster is restarted or
terminated</li>
<li>RStudio Server Pro (and other RStudio products) installed within a Databricks
cluster will be limited to the resources and lifecycle of that particular
Spark cluster</li>
<li>Non-Spark jobs will use CPU and RAM resources within the Databricks cluster</li>
<li>Need to install one instance of RStudio Server Pro per Spark cluster that you
want to run jobs on</li>
</ul>
</div>
<div id="requirements" class="section level2">
<h2>Requirements</h2>
<ul>
<li>A running Databricks cluster with a runtime version 4.1 or above</li>
<li>The cluster must not have “table access control” or “automatic termination” enabled</li>
<li>You must have “Can Attach To” permission for the Databricks cluster</li>
</ul>
</div>
<div id="preparation" class="section level2">
<h2>Preparation</h2>
<p>The following steps walk through the process to install RStudio Server Pro
on the Spark driver node within your Databricks cluster.</p>
<p>The recommended method for installing RStudio Server Pro to the Spark driver
node is via SSH. However, an alternative method is available if you are not able
to access the Spark driver node via SSH.</p>
</div>
<div id="configure-ssh-access-to-the-spark-driver-node" class="section level2">
<h2>Configure SSH access to the Spark driver node</h2>
<p>Configure SSH access to the Spark driver node in Databricks by following the
steps in the <a href="https://docs.databricks.com/clusters/configure.html#ssh-access-to-clusters">SSH access to clusters section of the Databricks Cluster
configurations
documentation</a>.</p>
<p><strong>Note:</strong> If you are unable to configure SSH access or connect to the Spark
driver node via SSH, then you can follow the steps in the <a href="https://docs.databricks.com/spark/latest/sparkr/rstudio.html#get-started-with-rstudio-server-pro">Get started with
RStudio Server Pro section of the RStudio on Databricks
documentation</a>
to install RStudio Server Pro from a Databricks notebook, then skip to the
section on <a href="#access-rstudio-server-pro">Access RStudio Server Pro</a> in this
documentation.</p>
</div>
<div id="connect-to-the-spark-driver-node-via-ssh" class="section level2">
<h2>Connect to the Spark driver node via SSH</h2>
<p>Connect to the Spark driver node via SSH on port 2200 by using the following
command on your local machine:</p>
<pre><code>ssh ubuntu@&lt;spark-driver-node-address&gt; -p 2200 -i &lt;path-to-private-SSH-key&gt;</code></pre>
<p>Replace <code>&lt;spark-driver-node-address&gt;</code> with the DNS name or IP address of the
Spark driver node, and <code>&lt;path-to-private-SSH-key&gt;</code> with the path to your private
SSH key on your local machine.</p>
</div>
<div id="install-rstudio-server-pro-on-the-spark-driver-node" class="section level2">
<h2>Install RStudio Server Pro on the Spark driver node</h2>
<p>After you SSH into the Spark driver node, then you can follow the steps to
<a href="https://docs.rstudio.com/rsp/installation/">install RStudio Server Pro in the RStudio documentation</a>.
In the installation steps, you can select Ubuntu as the target Linux
distribution.</p>
</div>
<div id="configure-rstudio-server-pro" class="section level2">
<h2>Configure RStudio Server Pro</h2>
<p>The following configuration steps are required to be able to use RStudio Server
Pro with Databricks.</p>
<p>Add the following configuration lines to <code>/etc/rstudio/rserver.conf</code> to use
proxied authentication with Databricks and enable the administrator dashboard:</p>
<pre><code>auth-proxy=1
auth-proxy-user-header-rewrite=^(.*)$ $1
auth-proxy-sign-in-url=&lt;domain&gt;/login.html
admin-enabled=1</code></pre>
<p>Add the following configuration line to <code>/etc/rstudio/rsession-profile</code> to set
the <code>PATH</code> to be used with RStudio Server Pro:</p>
<pre><code>export PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:$PATH</code></pre>
<p>Add the following configuration lines to <code>/etc/rstudio/rsession.conf</code> to
configure sessions in RStudio Server Pro to work with Databricks:</p>
<pre><code>session-rprofile-on-resume-default=1
allow-terminal-websockets=0</code></pre>
<p>Restart RStudio Server Pro:</p>
<pre><code>sudo rstudio-server restart</code></pre>
</div>
<div id="access-rstudio-server-pro" class="section level2">
<h2>Access RStudio Server Pro</h2>
<p>From the Databricks console, click on the Databricks cluster that you want to
work with:</p>
<p><img src="/images/deployment/databricks/rstudio-databricks-local-1.png" width='800px' align='center'/></p>
<p>From within the Databricks cluster, click on the <code>Apps</code> tab:</p>
<p><img src="/images/deployment/databricks/rstudio-databricks-local-2.png" width='800px' align='center'/></p>
<p>Click on the <code>Set up RStudio</code> button:</p>
<p><img src="/images/deployment/databricks/rstudio-databricks-local-3.png" width='800px' align='center'/></p>
<p>To access RStudio Server Pro, click on the link to <code>Open RStudio</code>:</p>
<p><img src="/images/deployment/databricks/rstudio-databricks-local-4.png" width='800px' align='center'/></p>
<p>If you configured proxied authentication in RStudio Server Pro as described in
the previous section, then you do not need to use the username or password that
is displayed. Instead, RStudio Server Pro will automatically login and start a
new RStudio session as your logged-in Databricks user:</p>
<p><img src="/images/deployment/databricks/rstudio-databricks-local-5.png" width='800px' align='center'/></p>
<p>Other users can access RStudio Server Pro from the Databricks console by
following the same steps described above. You do not need to create those users
in RStudio Server Pro or their home directory beforehand.</p>
</div>
<div id="configure-sparklyr" class="section level2">
<h2>Configure <code>sparklyr</code></h2>
<p>Use the following R code to establish a connection from <code>sparklyr</code> to the
Databricks cluster:</p>
<pre><code>SparkR::sparkR.session()
library(sparklyr)
sc &lt;- spark_connect(method = &quot;databricks&quot;)</code></pre>
</div>
<div id="additional-information" class="section level2">
<h2>Additional information</h2>
<p>For more information on using RStudio Server Pro inside of Databricks, refer to
the sections on
<a href="https://docs.databricks.com/spark/latest/sparkr/rstudio.html">RStudio on Databricks (AWS)</a>
or
<a href="https://docs.microsoft.com/en-us/azure/databricks/spark/latest/sparkr/rstudio">RStudio on Databricks (Azure)</a>
in the Databricks documentation.</p>
</div>
