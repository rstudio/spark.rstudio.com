---
title: Package index
toc: false
---

[checkpoint_directory()](checkpoint_directory.qmd) [spark_set_checkpoint_dir()](checkpoint_directory.qmd) [spark_get_checkpoint_dir()](checkpoint_directory.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Set/Get Spark checkpoint directory

[collect_from_rds()](collect_from_rds.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Collect Spark data serialized in RDS format into R

[compile_package_jars()](compile_package_jars.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Compile Scala sources into a Java Archive (jar)

[connection_config()](connection_config.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Read configuration values for a connection

[copy_to.spark_connection()](copy_to.spark_connection.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Copy an R Data Frame to Spark

[distinct()](distinct.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Distinct

[download_scalac()](download_scalac.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Downloads default Scala Compilers

[dplyr_hof()](dplyr_hof.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dplyr wrappers for Apache Spark higher order functions

[ensure()](ensure.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Enforce Specific Structure for R Objects

[fill()](fill.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Fill

[filter()](filter.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Filter

[find_scalac()](find_scalac.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Discover the Scala Compiler

[ft_binarizer()](ft_binarizer.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Feature Transformation - Binarizer (Transformer)

[ft_bucketizer()](ft_bucketizer.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Feature Transformation - Bucketizer (Transformer)

[ft_chisq_selector()](ft_chisq_selector.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Feature Transformation - ChiSqSelector (Estimator)

[ft_count_vectorizer()](ft_count_vectorizer.qmd) [ml_vocabulary()](ft_count_vectorizer.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Feature Transformation - CountVectorizer (Estimator)

[ft_dct()](ft_dct.qmd) [ft_discrete_cosine_transform()](ft_dct.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Feature Transformation - Discrete Cosine Transform (DCT) (Transformer)

[ft_elementwise_product()](ft_elementwise_product.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Feature Transformation - ElementwiseProduct (Transformer)

[ft_feature_hasher()](ft_feature_hasher.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Feature Transformation - FeatureHasher (Transformer)

[ft_hashing_tf()](ft_hashing_tf.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Feature Transformation - HashingTF (Transformer)

[ft_idf()](ft_idf.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Feature Transformation - IDF (Estimator)

[ft_imputer()](ft_imputer.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Feature Transformation - Imputer (Estimator)

[ft_index_to_string()](ft_index_to_string.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Feature Transformation - IndexToString (Transformer)

[ft_interaction()](ft_interaction.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Feature Transformation - Interaction (Transformer)

[ft_lsh()](ft_lsh.qmd) [ft_bucketed_random_projection_lsh()](ft_lsh.qmd) [ft_minhash_lsh()](ft_lsh.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Feature Transformation - LSH (Estimator)

[ft_lsh_utils()](ft_lsh_utils.qmd) [ml_approx_nearest_neighbors()](ft_lsh_utils.qmd) [ml_approx_similarity_join()](ft_lsh_utils.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Utility functions for LSH models

[ft_max_abs_scaler()](ft_max_abs_scaler.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Feature Transformation - MaxAbsScaler (Estimator)

[ft_min_max_scaler()](ft_min_max_scaler.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Feature Transformation - MinMaxScaler (Estimator)

[ft_ngram()](ft_ngram.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Feature Transformation - NGram (Transformer)

[ft_normalizer()](ft_normalizer.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Feature Transformation - Normalizer (Transformer)

[ft_one_hot_encoder()](ft_one_hot_encoder.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Feature Transformation - OneHotEncoder (Transformer)

[ft_one_hot_encoder_estimator()](ft_one_hot_encoder_estimator.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Feature Transformation - OneHotEncoderEstimator (Estimator)

[ft_pca()](ft_pca.qmd) [ml_pca()](ft_pca.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Feature Transformation - PCA (Estimator)

[ft_polynomial_expansion()](ft_polynomial_expansion.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Feature Transformation - PolynomialExpansion (Transformer)

[ft_quantile_discretizer()](ft_quantile_discretizer.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Feature Transformation - QuantileDiscretizer (Estimator)

[ft_r_formula()](ft_r_formula.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Feature Transformation - RFormula (Estimator)

[ft_regex_tokenizer()](ft_regex_tokenizer.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Feature Transformation - RegexTokenizer (Transformer)

[ft_robust_scaler()](ft_robust_scaler.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Feature Transformation - RobustScaler (Estimator)

[ft_standard_scaler()](ft_standard_scaler.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Feature Transformation - StandardScaler (Estimator)

[ft_stop_words_remover()](ft_stop_words_remover.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Feature Transformation - StopWordsRemover (Transformer)

[ft_string_indexer()](ft_string_indexer.qmd) [ml_labels()](ft_string_indexer.qmd) [ft_string_indexer_model()](ft_string_indexer.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Feature Transformation - StringIndexer (Estimator)

[ft_tokenizer()](ft_tokenizer.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Feature Transformation - Tokenizer (Transformer)

[ft_vector_assembler()](ft_vector_assembler.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Feature Transformation - VectorAssembler (Transformer)

[ft_vector_indexer()](ft_vector_indexer.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Feature Transformation - VectorIndexer (Estimator)

[ft_vector_slicer()](ft_vector_slicer.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Feature Transformation - VectorSlicer (Transformer)

[ft_word2vec()](ft_word2vec.qmd) [ml_find_synonyms()](ft_word2vec.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Feature Transformation - Word2Vec (Estimator)

[full_join()](full_join.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Full join

[generic_call_interface()](generic_call_interface.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Generic Call Interface

[get_spark_sql_catalog_implementation()](get_spark_sql_catalog_implementation.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Retrieve the Spark connection's SQL catalog implementation property

[()](grapes-greater-than-grapes.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Infix operator for composing a lambda expression

[hive_context_config()](hive_context_config.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Runtime configuration interface for Hive

[hof_aggregate()](hof_aggregate.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Apply Aggregate Function to Array Column

[hof_array_sort()](hof_array_sort.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Sorts array using a custom comparator

[hof_exists()](hof_exists.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Determine Whether Some Element Exists in an Array Column

[hof_filter()](hof_filter.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Filter Array Column

[hof_forall()](hof_forall.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Checks whether all elements in an array satisfy a predicate

[hof_map_filter()](hof_map_filter.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Filters a map

[hof_map_zip_with()](hof_map_zip_with.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Merges two maps into one

[hof_transform()](hof_transform.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Transform Array Column

[hof_transform_keys()](hof_transform_keys.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Transforms keys of a map

[hof_transform_values()](hof_transform_values.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Transforms values of a map

[hof_zip_with()](hof_zip_with.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Combines 2 Array Columns

[inner_join()](inner_join.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Inner join

[invoke()](invoke.qmd) [invoke_static()](invoke.qmd) [invoke_new()](invoke.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Invoke a Method on a JVM Object

[j_invoke()](j_invoke.qmd) [j_invoke_static()](j_invoke.qmd) [j_invoke_new()](j_invoke.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Invoke a Java function.

[jarray()](jarray.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Instantiate a Java array with a specific element type.

[jfloat()](jfloat.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Instantiate a Java float type.

[jfloat_array()](jfloat_array.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Instantiate an Array[Float].

[join.tbl_spark()](join.tbl_spark.qmd) [inner_join.tbl_spark()](join.tbl_spark.qmd) [left_join.tbl_spark()](join.tbl_spark.qmd) [right_join.tbl_spark()](join.tbl_spark.qmd) [full_join.tbl_spark()](join.tbl_spark.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Join Spark tbls.

[left_join()](left_join.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Left join

[list_sparklyr_jars()](list_sparklyr_jars.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;list all sparklyr-*.jar files that have been built

[livy_config()](livy_config.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Create a Spark Configuration for Livy

[livy_service_start()](livy_service.qmd) [livy_service_stop()](livy_service.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Start Livy

[ml-params()](ml-params.qmd) [ml_is_set()](ml-params.qmd) [ml_param_map()](ml-params.qmd) [ml_param()](ml-params.qmd) [ml_params()](ml-params.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Spark ML - ML Params

[ml-persistence()](ml-persistence.qmd) [ml_save()](ml-persistence.qmd) [ml_save.ml_model()](ml-persistence.qmd) [ml_load()](ml-persistence.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Spark ML - Model Persistence

[ml-transform-methods()](ml-transform-methods.qmd) [is_ml_transformer()](ml-transform-methods.qmd) [is_ml_estimator()](ml-transform-methods.qmd) [ml_fit()](ml-transform-methods.qmd) [ml_fit.default()](ml-transform-methods.qmd) [ml_transform()](ml-transform-methods.qmd) [ml_fit_and_transform()](ml-transform-methods.qmd) [ml_predict()](ml-transform-methods.qmd) [ml_predict.ml_model_classification()](ml-transform-methods.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Spark ML - Transform, fit, and predict methods (ml_ interface)

[ml-tuning()](ml-tuning.qmd) [ml_sub_models()](ml-tuning.qmd) [ml_validation_metrics()](ml-tuning.qmd) [ml_cross_validator()](ml-tuning.qmd) [ml_train_validation_split()](ml-tuning.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Spark ML - Tuning

[ml_aft_survival_regression()](ml_aft_survival_regression.qmd) [ml_survival_regression()](ml_aft_survival_regression.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Spark ML - Survival Regression

[ml_als()](ml_als.qmd) [ml_recommend()](ml_als.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Spark ML - ALS

[ml_als_tidiers()](ml_als_tidiers.qmd) [tidy.ml_model_als()](ml_als_tidiers.qmd) [augment.ml_model_als()](ml_als_tidiers.qmd) [glance.ml_model_als()](ml_als_tidiers.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Tidying methods for Spark ML ALS

[ml_bisecting_kmeans()](ml_bisecting_kmeans.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Spark ML - Bisecting K-Means Clustering

[ml_chisquare_test()](ml_chisquare_test.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Chi-square hypothesis testing for categorical data.

[ml_clustering_evaluator()](ml_clustering_evaluator.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Spark ML - Clustering Evaluator

[ml_corr()](ml_corr.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Compute correlation matrix

[ml_decision_tree_classifier()](ml_decision_tree.qmd) [ml_decision_tree()](ml_decision_tree.qmd) [ml_decision_tree_regressor()](ml_decision_tree.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Spark ML - Decision Trees

[ml_default_stop_words()](ml_default_stop_words.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default stop words

[ml_evaluate()](ml_evaluate.qmd) [ml_evaluate.ml_model_logistic_regression()](ml_evaluate.qmd) [ml_evaluate.ml_logistic_regression_model()](ml_evaluate.qmd) [ml_evaluate.ml_model_linear_regression()](ml_evaluate.qmd) [ml_evaluate.ml_linear_regression_model()](ml_evaluate.qmd) [ml_evaluate.ml_model_generalized_linear_regression()](ml_evaluate.qmd) [ml_evaluate.ml_generalized_linear_regression_model()](ml_evaluate.qmd) [ml_evaluate.ml_model_clustering()](ml_evaluate.qmd) [ml_evaluate.ml_model_classification()](ml_evaluate.qmd) [ml_evaluate.ml_evaluator()](ml_evaluate.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Evaluate the Model on a Validation Set

[ml_evaluator()](ml_evaluator.qmd) [ml_binary_classification_evaluator()](ml_evaluator.qmd) [ml_binary_classification_eval()](ml_evaluator.qmd) [ml_multiclass_classification_evaluator()](ml_evaluator.qmd) [ml_classification_eval()](ml_evaluator.qmd) [ml_regression_evaluator()](ml_evaluator.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Spark ML - Evaluators

[ml_feature_importances()](ml_feature_importances.qmd) [ml_tree_feature_importance()](ml_feature_importances.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Spark ML - Feature Importance for Tree Models

[ml_fpgrowth()](ml_fpgrowth.qmd) [ml_association_rules()](ml_fpgrowth.qmd) [ml_freq_itemsets()](ml_fpgrowth.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Frequent Pattern Mining - FPGrowth

[ml_gaussian_mixture()](ml_gaussian_mixture.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Spark ML - Gaussian Mixture clustering.

[ml_generalized_linear_regression()](ml_generalized_linear_regression.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Spark ML - Generalized Linear Regression

[ml_glm_tidiers()](ml_glm_tidiers.qmd) [tidy.ml_model_generalized_linear_regression()](ml_glm_tidiers.qmd) [tidy.ml_model_linear_regression()](ml_glm_tidiers.qmd) [augment.ml_model_generalized_linear_regression()](ml_glm_tidiers.qmd) [augment._ml_model_linear_regression()](ml_glm_tidiers.qmd) [augment.ml_model_linear_regression()](ml_glm_tidiers.qmd) [glance.ml_model_generalized_linear_regression()](ml_glm_tidiers.qmd) [glance.ml_model_linear_regression()](ml_glm_tidiers.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Tidying methods for Spark ML linear models

[ml_gbt_classifier()](ml_gradient_boosted_trees.qmd) [ml_gradient_boosted_trees()](ml_gradient_boosted_trees.qmd) [ml_gbt_regressor()](ml_gradient_boosted_trees.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Spark ML - Gradient Boosted Trees

[ml_isotonic_regression()](ml_isotonic_regression.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Spark ML - Isotonic Regression

[ml_isotonic_regression_tidiers()](ml_isotonic_regression_tidiers.qmd) [tidy.ml_model_isotonic_regression()](ml_isotonic_regression_tidiers.qmd) [augment.ml_model_isotonic_regression()](ml_isotonic_regression_tidiers.qmd) [glance.ml_model_isotonic_regression()](ml_isotonic_regression_tidiers.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Tidying methods for Spark ML Isotonic Regression

[ml_kmeans()](ml_kmeans.qmd) [ml_compute_cost()](ml_kmeans.qmd) [ml_compute_silhouette_measure()](ml_kmeans.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Spark ML - K-Means Clustering

[ml_kmeans_cluster_eval()](ml_kmeans_cluster_eval.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Evaluate a K-mean clustering

[ml_lda()](ml_lda.qmd) [ml_describe_topics()](ml_lda.qmd) [ml_log_likelihood()](ml_lda.qmd) [ml_log_perplexity()](ml_lda.qmd) [ml_topics_matrix()](ml_lda.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Spark ML - Latent Dirichlet Allocation

[ml_lda_tidiers()](ml_lda_tidiers.qmd) [tidy.ml_model_lda()](ml_lda_tidiers.qmd) [augment.ml_model_lda()](ml_lda_tidiers.qmd) [glance.ml_model_lda()](ml_lda_tidiers.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Tidying methods for Spark ML LDA models

[ml_linear_regression()](ml_linear_regression.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Spark ML - Linear Regression

[ml_linear_svc()](ml_linear_svc.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Spark ML - LinearSVC

[ml_linear_svc_tidiers()](ml_linear_svc_tidiers.qmd) [tidy.ml_model_linear_svc()](ml_linear_svc_tidiers.qmd) [augment.ml_model_linear_svc()](ml_linear_svc_tidiers.qmd) [glance.ml_model_linear_svc()](ml_linear_svc_tidiers.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Tidying methods for Spark ML linear svc

[ml_logistic_regression()](ml_logistic_regression.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Spark ML - Logistic Regression

[ml_logistic_regression_tidiers()](ml_logistic_regression_tidiers.qmd) [tidy.ml_model_logistic_regression()](ml_logistic_regression_tidiers.qmd) [augment.ml_model_logistic_regression()](ml_logistic_regression_tidiers.qmd) [augment._ml_model_logistic_regression()](ml_logistic_regression_tidiers.qmd) [glance.ml_model_logistic_regression()](ml_logistic_regression_tidiers.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Tidying methods for Spark ML Logistic Regression

[ml_metrics_binary()](ml_metrics_binary.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Extracts metrics from a fitted table

[ml_metrics_multiclass()](ml_metrics_multiclass.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Extracts metrics from a fitted table

[ml_metrics_regression()](ml_metrics_regression.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Extracts metrics from a fitted table

[ml_model_data()](ml_model_data.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Extracts data associated with a Spark ML model

[ml_multilayer_perceptron_classifier()](ml_multilayer_perceptron_classifier.qmd) [ml_multilayer_perceptron()](ml_multilayer_perceptron_classifier.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Spark ML - Multilayer Perceptron

[ml_multilayer_perceptron_tidiers()](ml_multilayer_perceptron_tidiers.qmd) [tidy.ml_model_multilayer_perceptron_classification()](ml_multilayer_perceptron_tidiers.qmd) [augment.ml_model_multilayer_perceptron_classification()](ml_multilayer_perceptron_tidiers.qmd) [glance.ml_model_multilayer_perceptron_classification()](ml_multilayer_perceptron_tidiers.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Tidying methods for Spark ML MLP

[ml_naive_bayes()](ml_naive_bayes.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Spark ML - Naive-Bayes

[ml_naive_bayes_tidiers()](ml_naive_bayes_tidiers.qmd) [tidy.ml_model_naive_bayes()](ml_naive_bayes_tidiers.qmd) [augment.ml_model_naive_bayes()](ml_naive_bayes_tidiers.qmd) [glance.ml_model_naive_bayes()](ml_naive_bayes_tidiers.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Tidying methods for Spark ML Naive Bayes

[ml_one_vs_rest()](ml_one_vs_rest.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Spark ML - OneVsRest

[ml_pca_tidiers()](ml_pca_tidiers.qmd) [tidy.ml_model_pca()](ml_pca_tidiers.qmd) [augment.ml_model_pca()](ml_pca_tidiers.qmd) [glance.ml_model_pca()](ml_pca_tidiers.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Tidying methods for Spark ML Principal Component Analysis

[ml_pipeline()](ml_pipeline.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Spark ML - Pipelines

[ml_power_iteration()](ml_power_iteration.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Spark ML - Power Iteration Clustering

[ml_prefixspan()](ml_prefixspan.qmd) [ml_freq_seq_patterns()](ml_prefixspan.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Frequent Pattern Mining - PrefixSpan

[ml_random_forest_classifier()](ml_random_forest.qmd) [ml_random_forest()](ml_random_forest.qmd) [ml_random_forest_regressor()](ml_random_forest.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Spark ML - Random Forest

[ml_stage()](ml_stage.qmd) [ml_stages()](ml_stage.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Spark ML - Pipeline stage extraction

[ml_summary()](ml_summary.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Spark ML - Extraction of summary metrics

[ml_survival_regression_tidiers()](ml_survival_regression_tidiers.qmd) [tidy.ml_model_aft_survival_regression()](ml_survival_regression_tidiers.qmd) [augment.ml_model_aft_survival_regression()](ml_survival_regression_tidiers.qmd) [glance.ml_model_aft_survival_regression()](ml_survival_regression_tidiers.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Tidying methods for Spark ML Survival Regression

[ml_tree_tidiers()](ml_tree_tidiers.qmd) [tidy.ml_model_decision_tree_classification()](ml_tree_tidiers.qmd) [tidy.ml_model_decision_tree_regression()](ml_tree_tidiers.qmd) [augment.ml_model_decision_tree_classification()](ml_tree_tidiers.qmd) [augment._ml_model_decision_tree_classification()](ml_tree_tidiers.qmd) [augment.ml_model_decision_tree_regression()](ml_tree_tidiers.qmd) [augment._ml_model_decision_tree_regression()](ml_tree_tidiers.qmd) [glance.ml_model_decision_tree_classification()](ml_tree_tidiers.qmd) [glance.ml_model_decision_tree_regression()](ml_tree_tidiers.qmd) [tidy.ml_model_random_forest_classification()](ml_tree_tidiers.qmd) [tidy.ml_model_random_forest_regression()](ml_tree_tidiers.qmd) [augment.ml_model_random_forest_classification()](ml_tree_tidiers.qmd) [augment._ml_model_random_forest_classification()](ml_tree_tidiers.qmd) [augment.ml_model_random_forest_regression()](ml_tree_tidiers.qmd) [augment._ml_model_random_forest_regression()](ml_tree_tidiers.qmd) [glance.ml_model_random_forest_classification()](ml_tree_tidiers.qmd) [glance.ml_model_random_forest_regression()](ml_tree_tidiers.qmd) [tidy.ml_model_gbt_classification()](ml_tree_tidiers.qmd) [tidy.ml_model_gbt_regression()](ml_tree_tidiers.qmd) [augment.ml_model_gbt_classification()](ml_tree_tidiers.qmd) [augment._ml_model_gbt_classification()](ml_tree_tidiers.qmd) [augment.ml_model_gbt_regression()](ml_tree_tidiers.qmd) [augment._ml_model_gbt_regression()](ml_tree_tidiers.qmd) [glance.ml_model_gbt_classification()](ml_tree_tidiers.qmd) [glance.ml_model_gbt_regression()](ml_tree_tidiers.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Tidying methods for Spark ML tree models

[ml_uid()](ml_uid.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Spark ML - UID

[ml_unsupervised_tidiers()](ml_unsupervised_tidiers.qmd) [tidy.ml_model_kmeans()](ml_unsupervised_tidiers.qmd) [augment.ml_model_kmeans()](ml_unsupervised_tidiers.qmd) [glance.ml_model_kmeans()](ml_unsupervised_tidiers.qmd) [tidy.ml_model_bisecting_kmeans()](ml_unsupervised_tidiers.qmd) [augment.ml_model_bisecting_kmeans()](ml_unsupervised_tidiers.qmd) [glance.ml_model_bisecting_kmeans()](ml_unsupervised_tidiers.qmd) [tidy.ml_model_gaussian_mixture()](ml_unsupervised_tidiers.qmd) [augment.ml_model_gaussian_mixture()](ml_unsupervised_tidiers.qmd) [glance.ml_model_gaussian_mixture()](ml_unsupervised_tidiers.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Tidying methods for Spark ML unsupervised models

[mutate()](mutate.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Mutate

[na.replace()](na.replace.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Replace Missing Values in Objects

[nest()](nest.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Nest

[pivot_longer()](pivot_longer.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Pivot longer

[pivot_wider()](pivot_wider.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Pivot wider

[random_string()](random_string.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Random string generation

[reactiveSpark()](reactiveSpark.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Reactive spark reader

[registerDoSpark()](registerDoSpark.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Register a Parallel Backend

[register_extension()](register_extension.qmd) [registered_extensions()](register_extension.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Register a Package that Implements a Spark Extension

[replace_na()](replace_na.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Replace NA

[right_join()](right_join.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Right join

[sdf-saveload()](sdf-saveload.qmd) [sdf_save_table()](sdf-saveload.qmd) [sdf_load_table()](sdf-saveload.qmd) [sdf_save_parquet()](sdf-saveload.qmd) [sdf_load_parquet()](sdf-saveload.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Save / Load a Spark DataFrame

[sdf-transform-methods()](sdf-transform-methods.qmd) [sdf_predict()](sdf-transform-methods.qmd) [sdf_transform()](sdf-transform-methods.qmd) [sdf_fit()](sdf-transform-methods.qmd) [sdf_fit_and_transform()](sdf-transform-methods.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Spark ML - Transform, fit, and predict methods (sdf_ interface)

[sdf_along()](sdf_along.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Create DataFrame for along Object

[sdf_bind()](sdf_bind.qmd) [sdf_bind_rows()](sdf_bind.qmd) [sdf_bind_cols()](sdf_bind.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Bind multiple Spark DataFrames by row and column

[sdf_broadcast()](sdf_broadcast.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Broadcast hint

[sdf_checkpoint()](sdf_checkpoint.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Checkpoint a Spark DataFrame

[sdf_coalesce()](sdf_coalesce.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Coalesces a Spark DataFrame

[sdf_collect()](sdf_collect.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Collect a Spark DataFrame into R.

[sdf_copy_to()](sdf_copy_to.qmd) [sdf_import()](sdf_copy_to.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Copy an Object into Spark

[sdf_crosstab()](sdf_crosstab.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Cross Tabulation

[sdf_debug_string()](sdf_debug_string.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Debug Info for Spark DataFrame

[sdf_describe()](sdf_describe.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Compute summary statistics for columns of a data frame

[sdf_dim()](sdf_dim.qmd) [sdf_nrow()](sdf_dim.qmd) [sdf_ncol()](sdf_dim.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Support for Dimension Operations

[sdf_distinct()](sdf_distinct.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Invoke distinct on a Spark DataFrame

[sdf_drop_duplicates()](sdf_drop_duplicates.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Remove duplicates from a Spark DataFrame

[sdf_expand_grid()](sdf_expand_grid.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Create a Spark dataframe containing all combinations of inputs

[sdf_from_avro()](sdf_from_avro.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Convert column(s) from avro format

[sdf_is_streaming()](sdf_is_streaming.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Spark DataFrame is Streaming

[sdf_last_index()](sdf_last_index.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns the last index of a Spark DataFrame

[sdf_len()](sdf_len.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Create DataFrame for Length

[sdf_num_partitions()](sdf_num_partitions.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Gets number of partitions of a Spark DataFrame

[sdf_partition_sizes()](sdf_partition_sizes.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Compute the number of records within each partition of a Spark DataFrame

[sdf_persist()](sdf_persist.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Persist a Spark DataFrame

[sdf_pivot()](sdf_pivot.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Pivot a Spark DataFrame

[sdf_project()](sdf_project.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Project features onto principal components

[sdf_quantile()](sdf_quantile.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Compute (Approximate) Quantiles with a Spark DataFrame

[sdf_random_split()](sdf_random_split.qmd) [sdf_partition()](sdf_random_split.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Partition a Spark Dataframe

[sdf_rbeta()](sdf_rbeta.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Generate random samples from a Beta distribution

[sdf_rbinom()](sdf_rbinom.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Generate random samples from a binomial distribution

[sdf_rcauchy()](sdf_rcauchy.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Generate random samples from a Cauchy distribution

[sdf_rchisq()](sdf_rchisq.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Generate random samples from a chi-squared distribution

[sdf_read_column()](sdf_read_column.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Read a Column from a Spark DataFrame

[sdf_register()](sdf_register.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Register a Spark DataFrame

[sdf_repartition()](sdf_repartition.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Repartition a Spark DataFrame

[sdf_residuals.ml_model_generalized_linear_regression()](sdf_residuals.qmd) [sdf_residuals.ml_model_linear_regression()](sdf_residuals.qmd) [sdf_residuals()](sdf_residuals.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Model Residuals

[sdf_rexp()](sdf_rexp.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Generate random samples from an exponential distribution

[sdf_rgamma()](sdf_rgamma.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Generate random samples from a Gamma distribution

[sdf_rgeom()](sdf_rgeom.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Generate random samples from a geometric distribution

[sdf_rhyper()](sdf_rhyper.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Generate random samples from a hypergeometric distribution

[sdf_rlnorm()](sdf_rlnorm.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Generate random samples from a log normal distribution

[sdf_rnorm()](sdf_rnorm.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Generate random samples from the standard normal distribution

[sdf_rpois()](sdf_rpois.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Generate random samples from a Poisson distribution

[sdf_rt()](sdf_rt.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Generate random samples from a t-distribution

[sdf_runif()](sdf_runif.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Generate random samples from the uniform distribution U(0, 1).

[sdf_rweibull()](sdf_rweibull.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Generate random samples from a Weibull distribution.

[sdf_sample()](sdf_sample.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Randomly Sample Rows from a Spark DataFrame

[sdf_schema()](sdf_schema.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Read the Schema of a Spark DataFrame

[sdf_separate_column()](sdf_separate_column.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Separate a Vector Column into Scalar Columns

[sdf_seq()](sdf_seq.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Create DataFrame for Range

[sdf_sort()](sdf_sort.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Sort a Spark DataFrame

[sdf_sql()](sdf_sql.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Spark DataFrame from SQL

[sdf_to_avro()](sdf_to_avro.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Convert column(s) to avro format

[sdf_unnest_longer()](sdf_unnest_longer.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Unnest longer

[sdf_unnest_wider()](sdf_unnest_wider.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Unnest wider

[sdf_weighted_sample()](sdf_weighted_sample.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Perform Weighted Random Sampling on a Spark DataFrame

[sdf_with_sequential_id()](sdf_with_sequential_id.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Add a Sequential ID Column to a Spark DataFrame

[sdf_with_unique_id()](sdf_with_unique_id.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Add a Unique ID Column to a Spark DataFrame

[select()](select.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Select

[separate()](separate.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Separate

[spark-api()](spark-api.qmd) [spark_context()](spark-api.qmd) [java_context()](spark-api.qmd) [hive_context()](spark-api.qmd) [spark_session()](spark-api.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Access the Spark API

[spark-connections()](spark-connections.qmd) [spark_connect()](spark-connections.qmd) [spark_connection_is_open()](spark-connections.qmd) [spark_disconnect()](spark-connections.qmd) [spark_disconnect_all()](spark-connections.qmd) [spark_submit()](spark-connections.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Manage Spark Connections

[spark_adaptive_query_execution()](spark_adaptive_query_execution.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Retrieves or sets status of Spark AQE

[spark_advisory_shuffle_partition_size()](spark_advisory_shuffle_partition_size.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Retrieves or sets advisory size of the shuffle partition

[spark_apply()](spark_apply.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Apply an R Function in Spark

[spark_apply_bundle()](spark_apply_bundle.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Create Bundle for Spark Apply

[spark_apply_log()](spark_apply_log.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Log Writer for Spark Apply

[spark_auto_broadcast_join_threshold()](spark_auto_broadcast_join_threshold.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Retrieves or sets the auto broadcast join threshold

[spark_coalesce_initial_num_partitions()](spark_coalesce_initial_num_partitions.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Retrieves or sets initial number of shuffle partitions before coalescing

[spark_coalesce_min_num_partitions()](spark_coalesce_min_num_partitions.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Retrieves or sets the minimum number of shuffle partitions after coalescing

[spark_coalesce_shuffle_partitions()](spark_coalesce_shuffle_partitions.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Retrieves or sets whether coalescing contiguous shuffle partitions is enabled

[spark_compilation_spec()](spark_compilation_spec.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Define a Spark Compilation Specification

[spark_config()](spark_config.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Read Spark Configuration

[spark_config_kubernetes()](spark_config_kubernetes.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Kubernetes Configuration

[spark_config_settings()](spark_config_settings.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Retrieve Available Settings

[spark_session_config()](spark_configuration.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Runtime configuration interface for the Spark Session

[spark_connect_method()](spark_connect_method.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Function that negotiates the connection with the Spark back-end

[spark_connection-class()](spark_connection-class.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;spark_connection class

[spark_connection()](spark_connection.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Retrieve the Spark Connection Associated with an R Object

[spark_connection_find()](spark_connection_find.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Find Spark Connection

[spark_context_config()](spark_context_config.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Runtime configuration interface for the Spark Context.

[spark_dataframe()](spark_dataframe.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Retrieve a Spark DataFrame

[spark_default_compilation_spec()](spark_default_compilation_spec.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default Compilation Specification for Spark Extensions

[spark_dependency()](spark_dependency.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Define a Spark dependency

[spark_dependency_fallback()](spark_dependency_fallback.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Fallback to Spark Dependency

[spark_extension()](spark_extension.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Create Spark Extension

[spark_home_set()](spark_home_set.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Set the SPARK_HOME environment variable

[spark_ide_connection_open()](spark_ide_connection_open.qmd) [spark_ide_connection_closed()](spark_ide_connection_open.qmd) [spark_ide_connection_updated()](spark_ide_connection_open.qmd) [spark_ide_connection_actions()](spark_ide_connection_open.qmd) [spark_ide_objects()](spark_ide_connection_open.qmd) [spark_ide_columns()](spark_ide_connection_open.qmd) [spark_ide_preview()](spark_ide_connection_open.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Set of functions to provide integration with the RStudio IDE

[spark_insert_table()](spark_insert_table.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Inserts a Spark DataFrame into a Spark table

[spark_install()](spark_install.qmd) [spark_uninstall()](spark_install.qmd) [spark_install_dir()](spark_install.qmd) [spark_install_tar()](spark_install.qmd) [spark_installed_versions()](spark_install.qmd) [spark_available_versions()](spark_install.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Download and install various versions of Spark

[spark_integ_test_skip()](spark_integ_test_skip.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;It lets the package know if it should test a particular functionality or not

[spark_jobj-class()](spark_jobj-class.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;spark_jobj class

[spark_jobj()](spark_jobj.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Retrieve a Spark JVM Object Reference

[spark_last_error()](spark_last_error.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Surfaces the last error from Spark captured by internal `spark_error` function

[spark_load_table()](spark_load_table.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Reads from a Spark Table into a Spark DataFrame.

[spark_log()](spark_log.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;View Entries in the Spark Log

[spark_read()](spark_read.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Read file(s) into a Spark DataFrame using a custom reader

[spark_read_avro()](spark_read_avro.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Read Apache Avro data into a Spark DataFrame.

[spark_read_binary()](spark_read_binary.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Read binary data into a Spark DataFrame.

[spark_read_csv()](spark_read_csv.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Read a CSV file into a Spark DataFrame

[spark_read_delta()](spark_read_delta.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Read from Delta Lake into a Spark DataFrame.

[spark_read_image()](spark_read_image.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Read image data into a Spark DataFrame.

[spark_read_jdbc()](spark_read_jdbc.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Read from JDBC connection into a Spark DataFrame.

[spark_read_json()](spark_read_json.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Read a JSON file into a Spark DataFrame

[spark_read_libsvm()](spark_read_libsvm.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Read libsvm file into a Spark DataFrame.

[spark_read_orc()](spark_read_orc.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Read a ORC file into a Spark DataFrame

[spark_read_parquet()](spark_read_parquet.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Read a Parquet file into a Spark DataFrame

[spark_read_source()](spark_read_source.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Read from a generic source into a Spark DataFrame.

[spark_read_table()](spark_read_table.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Reads from a Spark Table into a Spark DataFrame.

[spark_read_text()](spark_read_text.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Read a Text file into a Spark DataFrame

[spark_save_table()](spark_save_table.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Saves a Spark DataFrame as a Spark table

[spark_statistical_routines()](spark_statistical_routines.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Generate random samples from some distribution

[spark_table_name()](spark_table_name.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Generate a Table Name from Expression

[spark_version()](spark_version.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Get the Spark Version Associated with a Spark Connection

[spark_version_from_home()](spark_version_from_home.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Get the Spark Version Associated with a Spark Installation

[spark_web()](spark_web.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Open the Spark web interface

[spark_write()](spark_write.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Write Spark DataFrame to file using a custom writer

[spark_write_avro()](spark_write_avro.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Serialize a Spark DataFrame into Apache Avro format

[spark_write_csv()](spark_write_csv.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Write a Spark DataFrame to a CSV

[spark_write_delta()](spark_write_delta.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Writes a Spark DataFrame into Delta Lake

[spark_write_jdbc()](spark_write_jdbc.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Writes a Spark DataFrame into a JDBC table

[spark_write_json()](spark_write_json.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Write a Spark DataFrame to a JSON file

[spark_write_orc()](spark_write_orc.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Write a Spark DataFrame to a ORC file

[spark_write_parquet()](spark_write_parquet.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Write a Spark DataFrame to a Parquet file

[spark_write_rds()](spark_write_rds.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Write Spark DataFrame to RDS files

[spark_write_source()](spark_write_source.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Writes a Spark DataFrame into a generic source

[spark_write_table()](spark_write_table.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Writes a Spark DataFrame into a Spark table

[spark_write_text()](spark_write_text.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Write a Spark DataFrame to a Text file

[sparklyr_get_backend_port()](sparklyr_get_backend_port.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return the port number of a `sparklyr` backend.

[ft_sql_transformer()](sql-transformer.qmd) [ft_dplyr_transformer()](sql-transformer.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Feature Transformation - SQLTransformer

[src_databases()](src_databases.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Show database list

[stream_find()](stream_find.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Find Stream

[stream_generate_test()](stream_generate_test.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Generate Test Stream

[stream_id()](stream_id.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Spark Stream's Identifier

[stream_lag()](stream_lag.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Apply lag function to columns of a Spark Streaming DataFrame

[stream_name()](stream_name.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Spark Stream's Name

[stream_read_csv()](stream_read_csv.qmd) [stream_read_text()](stream_read_csv.qmd) [stream_read_json()](stream_read_csv.qmd) [stream_read_parquet()](stream_read_csv.qmd) [stream_read_orc()](stream_read_csv.qmd) [stream_read_kafka()](stream_read_csv.qmd) [stream_read_socket()](stream_read_csv.qmd) [stream_read_delta()](stream_read_csv.qmd) [stream_read_cloudfiles()](stream_read_csv.qmd) [stream_read_table()](stream_read_csv.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Read files created by the stream

[stream_render()](stream_render.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Render Stream

[stream_stats()](stream_stats.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Stream Statistics

[stream_stop()](stream_stop.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Stops a Spark Stream

[stream_trigger_continuous()](stream_trigger_continuous.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Spark Stream Continuous Trigger

[stream_trigger_interval()](stream_trigger_interval.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Spark Stream Interval Trigger

[stream_view()](stream_view.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;View Stream

[stream_watermark()](stream_watermark.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Watermark Stream

[stream_write_csv()](stream_write_csv.qmd) [stream_write_text()](stream_write_csv.qmd) [stream_write_json()](stream_write_csv.qmd) [stream_write_parquet()](stream_write_csv.qmd) [stream_write_orc()](stream_write_csv.qmd) [stream_write_kafka()](stream_write_csv.qmd) [stream_write_console()](stream_write_csv.qmd) [stream_write_delta()](stream_write_csv.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Write files to the stream

[stream_write_memory()](stream_write_memory.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Write Memory Stream

[stream_write_table()](stream_write_table.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Write Stream to Table

[[.tbl_spark()](sub-.tbl_spark.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Subsetting operator for Spark dataframe

[tbl_cache()](tbl_cache.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Cache a Spark Table

[tbl_change_db()](tbl_change_db.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Use specific database

[tbl_uncache()](tbl_uncache.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Uncache a Spark Table

[transform_sdf()](transform_sdf.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;transform a subset of column(s) in a Spark Dataframe

[unite()](unite.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Unite

[unnest()](unnest.qmd)


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Unnest

