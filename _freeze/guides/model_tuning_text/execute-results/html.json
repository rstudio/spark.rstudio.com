{
  "hash": "17c62408141b531fca95bb1527bf22aa",
  "result": {
    "markdown": "---\ntitle: \"Model Tuning - Part II\"\nexecute:\n  eval: true\n  freeze: true\neditor_options: \n  markdown: \n    wrap: 72\n---\n\n\n\n\n## Goals\n\nThe aim of this article is to build on the knowledge from [Model\nTuning](model_tuning.qmd){target=\"_blank\"} by covering the following:\n\n-   Show how to re-use the code of an existing ML Pipeline as the base\n    for the hyper-parameter tuning\n-   Show how tuning parameters are not limited to only model's\n    parameters. We will cover how to tune data transformation parameters\n\n## Recreating \"Tuning Text Analysis\"\n\nThe example in this article is based on the [Tuning Text\nAnalysis](https://tune.tidymodels.org/articles/extras/text_analysis.html){target=\"_blank\"}\narticle found in the `tidymodels`' `tune` website. In that article, they\nuse *Amazon's Fine Food Reviews* text data to perform hyper parameter\ntuning.\n\nAs its name suggest, Model Tuning has two main phases: the modeling, and\nthe tuning. In `tidymodels`, the modeling is done using the `recepies`\nand `parsnip` packages, while the tuning is done with `tune`. `tune` is\nable to modify the the `recipe` and model's arguments for each\nexperiment.\n\nIn Spark, the modeling is done with an ML Pipeline. In itself, preparing\nthe data, and setting up the model can be complex enough to merit its\nown walk-through. For the walk-through of the model used in this\narticle, please see [Text Modeling](textmodeling.qmd){target=\"_blank\"}.\n\nThe basics of the tuning part are covered in [Model\nTuning](model_tuning.qmd){target=\"_blank\"}. To avoid duplication, any\nfoundational explanation will be linked back to that article.\n\n## Setup\n\nFor this example, we will start a local Spark session, and then copy the\n*Fine Food Reviews* data to it.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(sparklyr)\nlibrary(modeldata)\n\ndata(\"small_fine_foods\")\n\nsc <- spark_connect(master = \"local\", version = \"3.3\")\n\nsff_training_data <- copy_to(sc, training_data)\nsff_testing_data <- copy_to(sc, testing_data)\n```\n:::\n\n\n## Pipeline\n\nThe data preparation and modeling in [Text\nModeling](textmodeling.qmd){target=\"_blank\"} was based on the [Tuning\nText\nAnalysis](https://tune.tidymodels.org/articles/extras/text_analysis.html){target=\"_blank\"}\narticle. The main steps from from the [Recipe and Model\nSpecification](https://tune.tidymodels.org/articles/extras/text_analysis.html#recipe-and-model-specifications-1){target=\"_blank\"}\nsection were recreated using Spark, via the `sparklyr` API. The `recipe`\nsteps were recreated with Feature Transformer functions, and the\n`parsnip` model was recreated using the equivalent\n`ml_logistic_regression()` model.\n\nDuring tuning, any parameter value used in the ML Pipeline will be\noverwritten with values from the [grid](#grid). This means that it\ndoesn't matter that we use the exact same code for developing, and\ntuning the pipeline. We can literally copy-paste, and run the resulting\npipeline code from [Text\nModeling](textmodeling.qmd#prepare-the-model-with-an-ml-pipeline).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsff_pipeline <- ml_pipeline(sc) %>% \n  ft_tokenizer(\n    input_col = \"review\",\n    output_col = \"word_list\"\n  ) %>% \n  ft_stop_words_remover(\n    input_col = \"word_list\", \n    output_col = \"wo_stop_words\"\n    ) %>% \n  ft_hashing_tf(\n    input_col = \"wo_stop_words\", \n    output_col = \"hashed_features\", \n    binary = TRUE, \n    num_features = 1024\n    ) %>%\n  ft_normalizer(\n    input_col = \"hashed_features\", \n    output_col = \"normal_features\"\n    ) %>% \n  ft_r_formula(score ~ normal_features) %>% \n  ml_logistic_regression()\n\nsff_pipeline\n#> Pipeline (Estimator) with 6 stages\n#> <pipeline__4ecbedbf_4b66_4aaf_8473_71a2439c9683> \n#>   Stages \n#>   |--1 Tokenizer (Transformer)\n#>   |    <tokenizer__44913373_2687_4fd0_a7f1_342d340255d6> \n#>   |     (Parameters -- Column Names)\n#>   |      input_col: review\n#>   |      output_col: word_list\n#>   |--2 StopWordsRemover (Transformer)\n#>   |    <stop_words_remover__1840232c_40f7_4822_8294_2c5f599d8046> \n#>   |     (Parameters -- Column Names)\n#>   |      input_col: word_list\n#>   |      output_col: wo_stop_words\n#>   |--3 HashingTF (Transformer)\n#>   |    <hashing_tf__c5b0cde0_0a9a_4277_aaf6_f975419eaed5> \n#>   |     (Parameters -- Column Names)\n#>   |      input_col: wo_stop_words\n#>   |      output_col: hashed_features\n#>   |--4 Normalizer (Transformer)\n#>   |    <normalizer__546b0428_e407_4f16_8063_98f618aef38b> \n#>   |     (Parameters -- Column Names)\n#>   |      input_col: hashed_features\n#>   |      output_col: normal_features\n#>   |--5 RFormula (Estimator)\n#>   |    <r_formula__72aea28c_723f_4701_989b_8c01d45a5624> \n#>   |     (Parameters -- Column Names)\n#>   |      features_col: features\n#>   |      label_col: label\n#>   |     (Parameters)\n#>   |      force_index_label: FALSE\n#>   |      formula: score ~ normal_features\n#>   |      handle_invalid: error\n#>   |      stringIndexerOrderType: frequencyDesc\n#>   |--6 LogisticRegression (Estimator)\n#>   |    <logistic_regression__d055e5bc_59de_48d2_98b2_2406471fbccb> \n#>   |     (Parameters -- Column Names)\n#>   |      features_col: features\n#>   |      label_col: label\n#>   |      prediction_col: prediction\n#>   |      probability_col: probability\n#>   |      raw_prediction_col: rawPrediction\n#>   |     (Parameters)\n#>   |      aggregation_depth: 2\n#>   |      elastic_net_param: 0\n#>   |      family: auto\n#>   |      fit_intercept: TRUE\n#>   |      max_iter: 100\n#>   |      maxBlockSizeInMB: 0\n#>   |      reg_param: 0\n#>   |      standardization: TRUE\n#>   |      threshold: 0.5\n#>   |      tol: 1e-06\n```\n:::\n\n\nIt is also worth pointing out that in a\"real life\" exercise,\n`sff_pipeline` would probably already be loaded into our environment.\nThat is because we just finished modeling and, decided to test to see if\nwe could tune the model. Spark can re-use the exact same ML Pipeline\nobject for the cross validation step.\n\n## Grid {#grid}\n\nThere is a big advantage to transforming, and modeling the data in a\nsingle ML Pipeline. It opens the door for Spark to also alter parameters\nused for data transformation, in addition to the model's parameters.\nThis means that we can include the parameters of the tokenization,\ncleaning, hashing, and normalization steps as possible candidate for the\nmodel tuning.\n\nThe *Text Analysis* article uses three tuning parameters. Two are in the\nmodel, and one is in the hashing step. Here are the parameters, and how\nthey map between `tidymodels` and `sparklyr`:\n\n| Parameter                             | `tidymodels` | `sparklyr`          |\n|---------------------------------------|--------------|---------------------|\n| Number of Terms to Hash               | `num_terms`  | `num_features`      |\n| Amount of regularization in the model | `penalty`    | `elastic_net_param` |\n| Proportion of pure vs ridge Lasso     | `mixture`    | `reg_param`         |\n\nThe values to tune with are taken from the [Grid\nSearch](https://tune.tidymodels.org/articles/extras/text_analysis.html#grid-search-1){target=\"_blank\"}\nsection in the *Text Analysis* article. All that is left to do is to\ncreate the grid itself. Just like we did in the first [Model\nTuning](model_tuning.html#grid){target=\"_blank\"} article, we use partial\nname matching to the steps we want to tune:\n\n-   `hashing_ft` will be the name of the list object containing the\n    `num_features` values\n\n-   `logistic_regression` will be the of the list object containing the\n    values of the other two parameters\n\nNotice that the R code of the values themselves are a direct copy of the\nones used in the *Text Analysis* article.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsff_grid <-  list(\n    hashing_tf = list(\n      num_features = 2^c(8, 10, 12)  \n    ),\n    logistic_regression = list(\n      elastic_net_param = 10^seq(-3, 0, length = 20), \n      reg_param = seq(0, 1, length = 5)    \n    )\n  )\n\nsff_grid\n#> $hashing_tf\n#> $hashing_tf$num_features\n#> [1]  256 1024 4096\n#> \n#> \n#> $logistic_regression\n#> $logistic_regression$elastic_net_param\n#>  [1] 0.001000000 0.001438450 0.002069138 0.002976351 0.004281332 0.006158482\n#>  [7] 0.008858668 0.012742750 0.018329807 0.026366509 0.037926902 0.054555948\n#> [13] 0.078475997 0.112883789 0.162377674 0.233572147 0.335981829 0.483293024\n#> [19] 0.695192796 1.000000000\n#> \n#> $logistic_regression$reg_param\n#> [1] 0.00 0.25 0.50 0.75 1.00\n```\n:::\n\n\n## Evaluator\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsff_evaluator <- ml_binary_classification_evaluator(sc)\n```\n:::\n\n\n## Model Tuning\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsff_cv <- ml_cross_validator(\n  x = sc,\n  estimator = sff_pipeline, \n  estimator_param_maps = sff_grid,\n  evaluator = sff_evaluator,\n  num_folds = 3,\n  parallelism = 4,\n  seed = 100\n)\n\nsff_cv\n#> CrossValidator (Estimator)\n#> <cross_validator__2817b96b_cfc1_489d_b267_b12b1fc11fe5> \n#>  (Parameters -- Tuning)\n#>   estimator: Pipeline\n#>              <pipeline__4ecbedbf_4b66_4aaf_8473_71a2439c9683> \n#>   evaluator: BinaryClassificationEvaluator\n#>              <binary_classification_evaluator__3a5c7cde_ced1_4037_bf28_4e973f158df2> \n#>     with metric areaUnderROC \n#>   num_folds: 3 \n#>   [Tuned over 300 hyperparameter sets]\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsff_model <- ml_fit(\n  x = sff_cv, \n  dataset = sff_training_data\n  )\n```\n:::\n\n\n## Validation metrics\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsff_metrics <- ml_validation_metrics(sff_model)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\n\nsff_metrics %>% \n  mutate(reg_param_1 = as.factor(reg_param_1)) %>% \n  ggplot(aes(\n    x = elastic_net_param_1, \n    y = areaUnderROC, \n    color = reg_param_1\n    )) +\n  geom_line() +\n  geom_point(size = 0.5) +\n  scale_x_continuous(trans = \"log10\") +\n  facet_wrap(~ num_features_2) +\n  theme_light(base_size = 9)\n```\n\n::: {.cell-output-display}\n![](model_tuning_text_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\n\nsff_metrics %>% \n  arrange(desc(areaUnderROC)) %>% \n  head()\n#>   areaUnderROC reg_param_1 elastic_net_param_1 num_features_2\n#> 1    0.7858727        0.25          0.05455595           4096\n#> 2    0.7847232        0.50          0.02636651           4096\n#> 3    0.7835850        0.75          0.01832981           4096\n#> 4    0.7830411        0.50          0.01832981           4096\n#> 5    0.7830230        0.25          0.03792690           4096\n#> 6    0.7828651        0.75          0.01274275           4096\n```\n:::\n\n\n## Model selection\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnew_sff_pipeline <- ml_pipeline(sc) %>% \n  ft_tokenizer(\n    input_col = \"review\",\n    output_col = \"word_list\"\n  ) %>% \n  ft_stop_words_remover(\n    input_col = \"word_list\", \n    output_col = \"wo_stop_words\"\n    ) %>% \n  ft_hashing_tf(\n    input_col = \"wo_stop_words\", \n    output_col = \"hashed_features\", \n    binary = TRUE, \n    num_features = 4096\n    ) %>%\n  ft_normalizer(\n    input_col = \"hashed_features\", \n    output_col = \"normal_features\"\n    ) %>% \n  ft_r_formula(score ~ normal_features) %>% \n  ml_logistic_regression(elastic_net_param = 0.05, reg_param = 0.25)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nnew_sff_fitted <- new_sff_pipeline %>% \n  ml_fit(sff_training_data)\n```\n:::\n\n\n## Test data metrics\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnew_sff_fitted %>% \n  ml_transform(sff_testing_data) %>% \n  ml_metrics_binary()\n#> # A tibble: 2 × 3\n#>   .metric .estimator .estimate\n#>   <chr>   <chr>          <dbl>\n#> 1 roc_auc binary         0.783\n#> 2 pr_auc  binary         0.653\n```\n:::\n\n\n",
    "supporting": [
      "model_tuning_text_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}