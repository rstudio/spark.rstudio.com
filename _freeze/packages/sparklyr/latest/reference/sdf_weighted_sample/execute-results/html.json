{
  "hash": "1e6b7184435ce39e06f57161874166b4",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Perform Weighted Random Sampling on a Spark DataFrame\"\nexecute:\n  freeze: true\n---\n\n\n\n*R/sdf_interface.R*\n\n## sdf_weighted_sample\n\n## Description\n Draw a random sample of rows (with or without replacement) from a Spark DataFrame If the sampling is done without replacement, then it will be conceptually equivalent to an iterative process such that in each step the probability of adding a row to the sample set is equal to its weight divided by summation of weights of all rows that are not in the sample set yet in that step. \n\n\n## Usage\n```r\n \nsdf_weighted_sample(x, weight_col, k, replacement = TRUE, seed = NULL) \n```\n\n## Arguments\n|Arguments|Description|\n|---|---|\n| x | An object coercable to a Spark DataFrame. |\n| weight_col | Name of the weight column |\n| k | Sample set size |\n| replacement | Whether to sample with replacement |\n| seed | An (optional) integer seed |\n\n\n\n\n\n\n## See Also\n Other Spark data frames:  `sdf_copy_to()`, `sdf_distinct()`, `sdf_random_split()`, `sdf_register()`, `sdf_sample()`, `sdf_sort()` \n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}