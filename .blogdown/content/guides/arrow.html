---
title: "Using Apache Arrow"
output: 
  html_document:
    toc_depth: 3
---



<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p><a href="https://arrow.apache.org/">Apache Arrow</a> is a cross-language development platform for in-memory data. Arrow is supported starting with <code>sparklyr 1.0.0</code> to improve performance when transferring data between Spark and R. You can find some performance benchmarks under:</p>
<ul>
<li><a href="https://blog.rstudio.com/2019/03/04/sparklyr-1-0/">sparklyr 1.0: Arrow, XGBoost, Broom and TFRecords</a>.</li>
<li><a href="https://arrow.apache.org/blog/2019/01/25/r-spark-improvements/">Speeding up R and Apache Spark using Apache Arrow</a>.</li>
</ul>
</div>
<div id="installation" class="section level2">
<h2>Installation</h2>
<p>Install the latest release of <code>arrow</code> from CRAN with</p>
<pre><code>install.packages(&quot;arrow&quot;)</code></pre>
<p>Please see <a href="https://arrow.apache.org/docs/r" class="uri">https://arrow.apache.org/docs/r</a> if you have any question about using <code>arrow</code> from R.</p>
</div>
<div id="use-cases" class="section level2">
<h2>Use Cases</h2>
<p>There are three main use cases for <code>arrow</code> in <code>sparklyr</code>:</p>
<ul>
<li><strong>Data Copying</strong>: When copying data with <code>copy_to()</code>, Arrow will be used.</li>
<li><strong>Data Collection</strong>: Also, when collecting either, implicitly by printing datasets or explicitly calling <code>collect</code>.</li>
<li><strong>R Transformations</strong>: When using <code>spark_apply()</code>, data will be transferred using Arrow when possible.</li>
</ul>
<p>To use <code>arrow</code> in <code>sparklyr</code> one simply needs to import this library:</p>
<pre class="r"><code>library(arrow)</code></pre>
<pre><code>Attaching package: ‘arrow’

The following object is masked from ‘package:utils’:

    timestamp

The following objects are masked from ‘package:base’:

    array, table</code></pre>
</div>
<div id="considerations" class="section level2">
<h2>Considerations</h2>
<div id="types" class="section level3">
<h3>Types</h3>
<p>Some data types are mapped to slightly different, one can argue more correct, types when using Arrow. For instance, consider collecting 64 bit integers in <code>sparklyr</code>:</p>
<pre class="r"><code>library(sparklyr)

sc &lt;- spark_connect(master = &quot;local&quot;)
integer64 &lt;- sdf_len(sc, 2, type = &quot;integer64&quot;)
integer64</code></pre>
<pre><code># Source: spark&lt;?&gt; [?? x 1]
     id
  &lt;dbl&gt;
1     1
2     2</code></pre>
<p>Notice that <code>sparklyr</code> collects 64 bit integers as <code>double</code>; however, using <code>arrow</code>:</p>
<pre class="r"><code>library(arrow)
integer64</code></pre>
<pre><code># Source: spark&lt;?&gt; [?? x 1]
  id             
  &lt;S3: integer64&gt;
1 1              
2 2 </code></pre>
<p>64 bit integers are now being collected as proper 64 bit integer using the <code>bit64</code> package.</p>
</div>
<div id="fallback" class="section level3">
<h3>Fallback</h3>
<p>The Arrow R package supports many data types; however, in cases where a type is unsupported, <code>sparklyr</code> will fallback to not using arrow and print a warning.</p>
<pre class="r"><code>library(sparklyr.nested)
library(sparklyr)
library(dplyr)
library(arrow)

sc &lt;- spark_connect(master = &quot;local&quot;)
cars &lt;- copy_to(sc, mtcars)

sdf_nest(cars, hp) %&gt;%
  group_by(cyl) %&gt;%
  summarize(data = collect_list(data))</code></pre>
<pre><code># Source: spark&lt;?&gt; [?? x 2]
    cyl data       
  &lt;dbl&gt; &lt;list&gt;     
1     6 &lt;list [7]&gt; 
2     4 &lt;list [11]&gt;
3     8 &lt;list [14]&gt;
Warning message:
In arrow_enabled_object.spark_jobj(sdf) :
  Arrow disabled due to columns: data</code></pre>
</div>
</div>
