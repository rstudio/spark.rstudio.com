{
  "hash": "6c693701609169805b0bcb2138c1c210",
  "result": {
    "markdown": "---\ntitle: \"Feature Transformation -- RFormula (Estimator)\"\nexecute:\n  freeze: true\n---\n\n\n\n\n*R/ml_feature_r_formula.R*\n\n## ft_r_formula\n\n## Description\nImplements the transforms required for fitting a dataset against an R model   formula. Currently we support a limited subset of the R operators,   including `~`, `.`, `:`, `+`, and `-`. Also see the R formula docs here:   [http://stat.ethz.ch/R-manual/R-patched/library/stats/html/formula.html](http://stat.ethz.ch/R-manual/R-patched/library/stats/html/formula.html)\n\n\n## Usage\n```r\nft_r_formula( \n  x, \n  formula = NULL, \n  features_col = \"features\", \n  label_col = \"label\", \n  force_index_label = FALSE, \n  uid = random_string(\"r_formula_\"), \n  ... \n) \n```\n\n## Arguments\n|Arguments|Description|\n|---|---|\n| x | A `spark_connection`, `ml_pipeline`, or a `tbl_spark`. |\n| formula | R formula as a character string or a formula. Formula objects are converted to character strings directly and the environment is not captured. |\n| features_col | Features column name, as a length-one character vector. The column should be single vector column of numeric values. Usually this column is output by `ft_r_formula`. |\n| label_col | Label column name. The column should be a numeric column. Usually this column is output by `ft_r_formula`. |\n| force_index_label | (Spark 2.1.0+) Force to index label whether it is numeric or string type. Usually we index label only when it is string type. If the formula was used by classification algorithms, we can force to index label even it is numeric type by setting this param with true. Default: `FALSE`. |\n| uid | A character string used to uniquely identify the feature transformer. |\n| ... | Optional arguments; currently unused. |\n\n## Details\n\nThe basic operators in the formula are: \n\n  \n\n    \n\n- ~ separate target and terms     \n\n- + concat terms, \"+ 0\" means removing intercept     \n\n- - remove a term, \"- 1\" means removing intercept     \n\n- : interaction (multiplication for numeric values, or binarized categorical values)     \n\n- . all columns except target   \n\n  Suppose a and b are double columns, we use the following simple examples to illustrate the   effect of RFormula: \n\n  \n\n    \n\n- `y ~ a + b` means model `y ~ w0 + w1 * a + w2 * b`\n\n      where `w0` is the intercept and `w1, w2` are coefficients.     \n\n- `y ~ a + b + a:b - 1` means model `y ~ w1 * a + w2 * b + w3 * a * b`\n\n      where `w1, w2, w3` are coefficients.   \n\n RFormula produces a vector column of features and a double or string column  of label. Like when formulas are used in R for linear regression, string  input columns will be one-hot encoded, and numeric columns will be cast to  doubles. If the label column is of type string, it will be first transformed  to double with StringIndexer. If the label column does not exist in the  DataFrame, the output label column will be created from the specified  response variable in the formula. \n\nIn the case where `x` is a `tbl_spark`, the estimator fits against `x`\n\n  to obtain a transformer, which is then immediately used to transform `x`, returning a `tbl_spark`. \n\n\n## Value\n\nThe object returned depends on the class of `x`. \n\n  \n\n- `spark_connection`: When `x` is a `spark_connection`, the function returns a `ml_transformer`,   a `ml_estimator`, or one of their subclasses. The object contains a pointer to   a Spark `Transformer` or `Estimator` object and can be used to compose   `Pipeline` objects. \n\n  \n\n- `ml_pipeline`: When `x` is a `ml_pipeline`, the function returns a `ml_pipeline` with   the transformer or estimator appended to the pipeline. \n\n  \n\n- `tbl_spark`: When `x` is a `tbl_spark`, a transformer is constructed then   immediately applied to the input `tbl_spark`, returning a `tbl_spark`\n\n\n\n## See Also\n\nSee [https://spark.apache.org/docs/latest/ml-features.html](https://spark.apache.org/docs/latest/ml-features.html) for   more information on the set of transformations available for DataFrame   columns in Spark. \n\nOther feature transformers:  `ft_binarizer()`, `ft_bucketizer()`, `ft_chisq_selector()`, `ft_count_vectorizer()`, `ft_dct()`, `ft_elementwise_product()`, `ft_feature_hasher()`, `ft_hashing_tf()`, `ft_idf()`, `ft_imputer()`, `ft_index_to_string()`, `ft_interaction()`, `ft_lsh`, `ft_max_abs_scaler()`, `ft_min_max_scaler()`, `ft_ngram()`, `ft_normalizer()`, `ft_one_hot_encoder_estimator()`, `ft_one_hot_encoder()`, `ft_pca()`, `ft_polynomial_expansion()`, `ft_quantile_discretizer()`, `ft_regex_tokenizer()`, `ft_robust_scaler()`, `ft_sql_transformer()`, `ft_standard_scaler()`, `ft_stop_words_remover()`, `ft_string_indexer()`, `ft_tokenizer()`, `ft_vector_assembler()`, `ft_vector_indexer()`, `ft_vector_slicer()`, `ft_word2vec()`\n\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}