{
  "hash": "87fcbe23f7bad8ce7139fa1aac2aa4f9",
  "result": {
    "markdown": "---\ntitle: \"Model Tuning - Part II\"\nexecute:\n  eval: false\n  freeze: true\neditor_options: \n  markdown: \n    wrap: 72\n---\n\n\n\n\n## Goals\n\nThe aim of this article is to build on the knowledge from [Model\nTuning](model_tuning.qmd){target=\"_blank\"} by covering the following:\n\n-   Show how to re-use the code of an existing ML Pipeline as the base\n    of the hyper-parameter tuning\n-   Show how tuning parameters are not limited to only model's\n    parameters. We will cover how to tune data transformation parameters\n\n## Recreating \"Tuning Text Analysis\"\n\nThe example in this article is based on the [Tuning Text\nAnalysis](https://tune.tidymodels.org/articles/extras/text_analysis.html){target=\"_blank\"}\narticle found in the `tidymodels`' `tune` website. In that article, they\nuse *Amazon's Fine Food Reviews* text data to perform hyper parameter\ntuning.\n\nAs its name suggest, Model Tuning has two main phases: the modeling, and\nthe tuning. In `tidymodels`, the modeling is done using the `recepies`\nand `parsnip` packages, while the tuning is done with `tune`. `tune` is\nable to modify the the `recipe` and model's arguments for each\nexperiment.\n\nIn Spark, the modeling is done with an ML Pipeline. In itself, preparing\nthe data, and setting up the model can be complex enough to merit its\nown walk-through. For the walk-through of the model used in this\narticle, please see [Text Modeling](textmodeling.qmd){target=\"_blank\"}.\n\nThe basics of the tuning part are covered in [Model\nTuning](model_tuning.qmd){target=\"_blank\"}. To avoid duplication, any\nfoundational explanation will be linked back to that article.\n\n## Setup\n\nFor this example, we will start a local Spark session, and then copy the\n*Fine Food Reviews* data to it.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(sparklyr)\nlibrary(modeldata)\n\ndata(\"small_fine_foods\")\n\nsc <- spark_connect(master = \"local\", version = \"3.3\")\n\nsff_training_data <- copy_to(sc, training_data)\nsff_testing_data <- copy_to(sc, testing_data)\n```\n:::\n\n\n## Pipeline\n\nWe literally copy-and-paste the ML Pipeline code from [Text\nModeling](textmodeling.qmd#prepare-the-model-with-an-ml-pipeline){target=\"_blank\"},\nand then run it as-is. The reason this works, is that model tuning in\nSpark allows us to include the processing steps along with the model.\n\nDuring tuning, any parameter value used in the ML Pipeline will be\noverwritten with values from the [grid](#grid). It doesn't matter that\nwe use the exact same pipeline code for development, and tuning.\n\nIt is also worth pointing out that if this was a \"real life\" exercise,\n`sff_pipeline` would probably already be loaded into our environment.\nThat is because we just finished modeling and, decided to test to see if\nwe could tune the model. Spark can re-use the exact same Ml Pipeline\nobject for the cross validation step.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsff_pipeline <- ml_pipeline(sc) %>% \n  ft_tokenizer(\n    input_col = \"review\",\n    output_col = \"word_list\"\n  ) %>% \n  ft_stop_words_remover(\n    input_col = \"word_list\", \n    output_col = \"wo_stop_words\"\n    ) %>% \n  ft_hashing_tf(\n    input_col = \"wo_stop_words\", \n    output_col = \"hashed_features\", \n    binary = TRUE, \n    num_features = 1024\n    ) %>%\n  ft_normalizer(\n    input_col = \"hashed_features\", \n    output_col = \"normal_features\"\n    ) %>% \n  ft_r_formula(score ~ normal_features) %>% \n  ml_logistic_regression()\n```\n:::\n\n\n## Grid {#grid}\n\nThis feature also makes it possible for the [tuning grid](#grid) to\ninclude parameters beyond just the ones for the model, we can also\nmodify parameters of the tokenization, cleaning, hashing and\nnormalization steps.\n\n[Grid\nSearch](https://tune.tidymodels.org/articles/extras/text_analysis.html#grid-search-1){target=\"_blank\"}\nsection in the `tidymodels` article.\n\npenalty = 10\\^seq(-3, 0, length = 20) mixture = seq(0, 1, length = 5)\nnum_terms = 2\\^c(8, 10, 12)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsff_grid <-  list(\n    hashing_tf = list(\n      num_features = 2^c(8, 10, 12)  \n    ),\n    logistic_regression = list(\n      elastic_net_param = 10^seq(-3, 0, length = 20), \n      reg_param = seq(0, 1, length = 5)    \n    )\n  )\n\nsff_grid\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsff_grid <-  list(\n    hashing_tf = list(\n      num_features = 2^c(12)  \n    ),\n    logistic_regression = list(\n      elastic_net_param = 10^seq(-3, 0, length = 5), \n      reg_param = seq(0, 1, length = 3)    \n    )\n  )\n\nsff_grid\n```\n:::\n\n\n## Evaluator\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsff_evaluator <- ml_binary_classification_evaluator(sc)\n```\n:::\n\n\n## Model Tuning\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsff_cv <- ml_cross_validator(\n  x = sc,\n  estimator = sff_pipeline, \n  estimator_param_maps = sff_grid,\n  evaluator = sff_evaluator,\n  num_folds = 3,\n  parallelism = 4\n)\n\nsff_cv\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsff_model <- ml_fit(\n  x = sff_cv, \n  dataset = sff_training_data\n  )\n```\n:::\n\n\n## Validation metrics\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsff_metrics <- ml_validation_metrics(sff_model)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\n\nsff_metrics %>% \n  mutate(reg_param_1 = as.factor(reg_param_1)) %>% \n  ggplot() +\n  geom_line(aes(\n    x = elastic_net_param_1, \n    y = areaUnderROC, \n    color = reg_param_1\n    )) +\n  facet_wrap(~ num_features_2) +\n  theme_light()\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\n\nsff_metrics %>% \n  arrange(desc(areaUnderROC)) %>% \n  head()\n```\n:::\n\n\n## Model selection\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnew_sff_pipeline <- ml_pipeline(sc) %>% \n  ft_tokenizer(\n    input_col = \"review\",\n    output_col = \"word_list\"\n  ) %>% \n  ft_stop_words_remover(\n    input_col = \"word_list\", \n    output_col = \"wo_stop_words\"\n    ) %>% \n  ft_hashing_tf(\n    input_col = \"wo_stop_words\", \n    output_col = \"hashed_features\", \n    binary = TRUE, \n    num_features = 4096\n    ) %>%\n  ft_normalizer(\n    input_col = \"hashed_features\", \n    output_col = \"normal_features\"\n    ) %>% \n  ft_r_formula(score ~ normal_features) %>% \n  ml_logistic_regression(elastic_net_param = 0.018, reg_param = 0.5)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nnew_sff_fitted <- new_sff_pipeline %>% \n  ml_fit(sff_training_data)\n```\n:::\n\n\n## Test data metrics\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnew_sff_fitted %>% \n  ml_transform(sff_testing_data) %>% \n  ml_metrics_binary()\n```\n:::\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}