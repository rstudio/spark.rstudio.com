{
  "hash": "ca34794ffd27e0ac6531a01689565f56",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Read a TFRecord File\"\nexecute:\n  freeze: true\n---\n\n\n\n*R/loader.R*\n\n## spark_read_tfrecord\n\n## Description\n Read a TFRecord file as a Spark DataFrame. \n\n\n## Usage\n```r\n \nspark_read_tfrecord(sc, name, path, schema = NULL, \n  record_type = c(\"Example\", \"SequenceExample\"), overwrite = TRUE) \n```\n\n## Arguments\n|Arguments|Description|\n|---|---|\n| sc | A spark conneciton. |\n| name | The name to assign to the newly generated table. |\n| path | The path to the file. Needs to be accessible from the cluster. Supports the \"hdfs://\", \"s3a://\" and \"file://\" protocols. |\n| schema | (Currently unsupported.) Schema of TensorFlow records.  If not provided, the schema is inferred from TensorFlow records. |\n| record_type | Input format of TensorFlow records. By default it is Example. |\n| overwrite | Boolean; overwrite the table with the given name if it already exists? |\n\n\n\n\n\n\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}