---
title: "Tune `tidymodels` remotely in Spark Connect"
execute:
  eval: true
  freeze: true
---

```{r}
#| include: false

run_r <- TRUE

```


```{r}
#| include: false

library(sparklyr)
library(tidymodels)
library(readmission)

if(FALSE) { # if (!interactive()) {
  pysparklyr::install_pyspark("4.1.0", python_version = "3.12")  
  reticulate::py_install("rpy2", envname = "r-sparklyr-pyspark-4.1")
}

# TODO: Remove before publishing
# readmission <- readmission[1:1000, ]
```

## Background

The ability of Spark to easily distribute tasks across multiple nodes (servers)
makes it a great target to run "embarrassing parallel" jobs, such as hyper-parameter
tuning. For R users, the challenge is to have to learn how to run experiments 
using the [Spark ML components](model_tuning.qmd). Ideally, we would like to use the already familiar
modeling R packages but have the computation happen somewhere else, faster,
and with little to no changes to our original code. 

**It is important to note
that we are not speaking of "big data", but rather of something more like 
"big processing"**.  What takes the job a long time to complete is the fact that
there are numerous tuning combination that need to be discretely processed 
(fit training data, predict on evaluation data, calculate metrics), and not that
we have to train on gigabytes and gigabytes of data. 

## The solution

Using `sparklyr`, it is now possible to use the exact same R objects created
to process the model tuning, but have the tuning itself occur in Spark. `sparklyr`
will upload the R objects to your Spark session automatically, and have all
of the parallel jobs run remotely. Everything made possible by running a
very similar function call. Instead of running `tune_grid()`, we would run
`tune_grid_spark()`, which has the extact same arguments as `tune_grid()`, with
a couple of additions, such as requiring a current Spark connection.


```{r}
#| eval: false

# TODO: Replace with actual installation instructions at release time

remotes::install_github("sparklyr/sparklyr", ref = "grid2")
remotes::install_github("tidymodels/tune", ref = "grid2")
remotes::install_github("mlverse/pysparklyr", ref = "grid2")
```

::: {#fig-cluster}
```{mermaid}
%%| fig-width: 6
flowchart RL
  subgraph sc [Spark Connect]
   p[Parallel processes]
  end
  r[local R]  -- Re-samples --> sc
  r -- Model --> sc
  r -- Pre-processor --> sc
  sc -.- rs[Results] -.-> r
  style sc fill:#F0B675,stroke:#666,color:#000;
  style p fill:#F8DDBF,stroke:#666,color:#000;
  style r fill:#75C7F0,stroke:#666,color:#000;
  style rs fill:#ddd,stroke:#ddd,color:#000;
  linkStyle default stroke:#666,color:#000
```

Model tuning in a Spark cluster
:::

## Prepare the workflow and re-samples locally

The standard framework for Machine Learning in R is 
[Tidymodels](https://www.tidymodels.org/). It is a collection of packages that
are designed to work together to provide everything from re-sampling, to 
pre-processing, to model tuning, to performance measurement. 

The following code prepares all the components needed to run hyper-parameter model
tuning in order to identify the best combination of parameters:


```{r}
#| eval: !expr 'run_r'

library(tidymodels)
library(readmission)

set.seed(1)

# Data set resampling 
readmission_splits <- initial_split(readmission, strata = readmitted)

readmission_folds <- vfold_cv(
  data = training(readmission_splits),
  strata = readmitted
  )

# Data pre-processing
recipe_basic <- recipe(readmitted ~ ., data = readmission) |>
  step_mutate(
    race = factor(case_when(
      !(race %in% c("Caucasian", "African American")) ~ "Other",
      .default = race
    ))
  ) |>
  step_unknown(all_nominal_predictors()) |>
  step_YeoJohnson(all_numeric_predictors()) |>
  step_normalize(all_numeric_predictors()) |>
  step_dummy(all_nominal_predictors())

# Model specification
spec_bt <- boost_tree(
  mode = "classification",
  mtry = tune(), # Part of the hyper-parameters to tune
  learn_rate = tune(), # Part of the hyper-parameters to tune
  trees = 10
  )
```

Typically, the next step would be to execute the hyper-parameter tuning by
calling `tune_grid()`. This is where we will diverge in order to use Spark,
instead of our laptop, to tune the model.

## Tune in Spark Connect

The feature of tuning remotely it is only available for Spark Connect connections,
and its vendor variants such as Databricks Connect. The variants will need to 
have R installed and available in their Spark nodes.  

```{r}
#| eval: false
library(sparklyr)
```


### Start Spark Connect locally

To show a full example throughout this article, we have included the steps to
start a local Spark Connect service. Please keep in mind that it is not necessary
to create anything local if you already have a Spark Connect service available
somewhere else, such as a vendor provided one. 

1. Install Spark locally if the version you wish to use is not available locally yet:
```{r}
#| eval: false
spark_install("4.1.0")
```

2. Start the Spark Connect service locally. Make sure to match the Spark version
you recently installed:

```{r}
#| eval: !expr 'run_r'
pysparklyr::spark_connect_service_start("4.1.0", python_version = "3.12")
```

### Tune the model

The first step is to connect to to the Spark Connect instance. 

```{r}
#| eval: !expr 'run_r'
sc <- spark_connect(
  "sc://localhost",
  method = "spark_connect",
  version = "4.1.0"
  )
```

Now, to start the model tuning, we call `tune_grid_spark()`. The minimal required
arguments are:

1. Spark connection
1. Model specification (`parsnip`)
1. Pre-processor (`recipe`)
1. Re-sampled data (`rsample`)

```{r}
#| eval: !expr 'run_r'
spark_results <- tune_grid_spark(sc, spec_bt, recipe_basic, readmission_folds)
```

As part of adding this feature, `sparklyr` imported a lot of the functionality
directly from the `tidymodels` packages in order to offer an equivalent experience,
as well as to perform the same checks. The resulting object will look 
indistinguishable from that created directly locally by `tidymodels`:

```{r}
#| eval: !expr 'run_r'
spark_results
```

The object can now be used to inspect and eventually finalize the model 
selection.

```{r}
#| eval: !expr 'run_r'
autoplot(spark_results)
```


## Compare with local results

The steps in this section would not be necessary in a 'real world' scenario. 
This is to show how the results returned by running `tune_grid()` compare to
those from `tune_grid_spark()`

```{r}
#| eval: !expr 'run_r'
results <- tune_grid(spec_bt, recipe_basic, readmission_folds)

# Use show_best() to compare the recommendations

show_best(results)
show_best(spark_results)
```

In this case, both calls returned the exact same results. This is because both
ran using the same exact versions R and R packages that our Positron or RStudio
would access. It is important to note that if the tuning would occur in a remote
Spark cluster, that has different Operating System, R version and/or R packages,
then the results would come back different. It is also important to differentiate 
between different results from local and not reproducible results. The results
will still be consistent if the job is run the exact same way, and the `seed` is
set during the local R session that calls the remote Spark jobs.  `sparklyr`
recreates how `tune` sets the R seed for each Spark task, so the jobs will remain
consistent after each repeated run.

## Spark parallelization

A lot of effort was made to make sure that tuning the model remotely in Spark was
as easy and automatic as possible. `sparklyr` copies the necessary R objects, and
uses the same defaults `tune_grid()` and Spark itself use in order to not have
to decide or setup more things than necessary. 

By default, Spark will run as many concurrent jobs as there are CPU cores 
made available by the cluster. 

However, there are a few ways to customize the tuning in Spark. They relate how
each hyper-parameter tuning task will be parallelized. The first way is to
control the number of discrete tasks that will be requested to Spark, and the
second how the hyper-parameter tuning combinations will be grouped.

## Retrieving predictions a.k.a `save_pred = TRUE`

`sparklyr` supports getting the out-of-sample predictions if they are saved. That
is done by using `control_grid()` when calling `tune_grid()`.

```{r}
#| eval: !expr 'run_r'
cntrl <- control_grid(save_pred = TRUE)

results <- tune_grid(spec_bt, recipe_basic, readmission_folds, control = cntrl)
```

There will be a second job that executes in Spark. This job does not really
process anything. The job just reads and download the predictions into the R 
session.

Once the tuning is completed, the predictions can be used in the R session
as if they were all processed locally.

```{r}
#| eval: !expr 'run_r'
collect_predictions(results)
```

```{r}
#| eval: !expr 'run_r'
#| include: false
pysparklyr::spark_connect_service_stop()
```
