{
  "hash": "b89ea6f2352f4e51a5b6557943a68461",
  "result": {
    "markdown": "---\ntitle: \"Feature Transformation -- Imputer (Estimator)\"\nexecute:\n  freeze: true\n---\n\n\n\n\n*R/ml_feature_imputer.R*\n\n## ft_imputer\n\n## Description\nImputation estimator for completing missing values, either using the mean or   the median of the columns in which the missing values are located. The input   columns should be of numeric type. This function requires Spark 2.2.0+. \n\n\n## Usage\n```r\nft_imputer( \n  x, \n  input_cols = NULL, \n  output_cols = NULL, \n  missing_value = NULL, \n  strategy = \"mean\", \n  uid = random_string(\"imputer_\"), \n  ... \n) \n```\n\n## Arguments\n|Arguments|Description|\n|---|---|\n| x | A `spark_connection`, `ml_pipeline`, or a `tbl_spark`. |\n| input_cols | The names of the input columns |\n| output_cols | The names of the output columns. |\n| missing_value | The placeholder for the missing values. All occurrences of `missing_value` will be imputed. Note that null values are always treated as missing. |\n| strategy | The imputation strategy. Currently only \"mean\" and \"median\" are supported. If \"mean\", then replace missing values using the mean value of the feature. If \"median\", then replace missing values using the approximate median value of the feature. Default: mean |\n| uid | A character string used to uniquely identify the feature transformer. |\n| ... | Optional arguments; currently unused. |\n\n## Details\n\nIn the case where `x` is a `tbl_spark`, the estimator fits against `x`\n\n  to obtain a transformer, which is then immediately used to transform `x`, returning a `tbl_spark`. \n\n\n## Value\n\nThe object returned depends on the class of `x`. \n\n  \n\n- `spark_connection`: When `x` is a `spark_connection`, the function returns a `ml_transformer`,   a `ml_estimator`, or one of their subclasses. The object contains a pointer to   a Spark `Transformer` or `Estimator` object and can be used to compose   `Pipeline` objects. \n\n  \n\n- `ml_pipeline`: When `x` is a `ml_pipeline`, the function returns a `ml_pipeline` with   the transformer or estimator appended to the pipeline. \n\n  \n\n- `tbl_spark`: When `x` is a `tbl_spark`, a transformer is constructed then   immediately applied to the input `tbl_spark`, returning a `tbl_spark`\n\n\n\n## See Also\n\nSee [https://spark.apache.org/docs/latest/ml-features.html](https://spark.apache.org/docs/latest/ml-features.html) for   more information on the set of transformations available for DataFrame   columns in Spark. \n\nOther feature transformers:  `ft_binarizer()`, `ft_bucketizer()`, `ft_chisq_selector()`, `ft_count_vectorizer()`, `ft_dct()`, `ft_elementwise_product()`, `ft_feature_hasher()`, `ft_hashing_tf()`, `ft_idf()`, `ft_index_to_string()`, `ft_interaction()`, `ft_lsh`, `ft_max_abs_scaler()`, `ft_min_max_scaler()`, `ft_ngram()`, `ft_normalizer()`, `ft_one_hot_encoder_estimator()`, `ft_one_hot_encoder()`, `ft_pca()`, `ft_polynomial_expansion()`, `ft_quantile_discretizer()`, `ft_r_formula()`, `ft_regex_tokenizer()`, `ft_robust_scaler()`, `ft_sql_transformer()`, `ft_standard_scaler()`, `ft_stop_words_remover()`, `ft_string_indexer()`, `ft_tokenizer()`, `ft_vector_assembler()`, `ft_vector_indexer()`, `ft_vector_slicer()`, `ft_word2vec()`\n\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}