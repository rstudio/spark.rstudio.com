{
  "hash": "6c15d5ec0118b915804caed1e6efcb34",
  "result": {
    "markdown": "---\ntitle: \"Repartition a Spark DataFrame\"\nexecute:\n  freeze: true\n---\n\n\n\n\n*R/sdf_interface.R*\n\n## sdf_repartition\n\n## Description\nRepartition a Spark DataFrame \n\n\n## Usage\n```r\nsdf_repartition(x, partitions = NULL, partition_by = NULL) \n```\n\n## Arguments\n|Arguments|Description|\n|---|---|\n| x | A `spark_connection`, `ml_pipeline`, or a `tbl_spark`. |\n| partitions | number of partitions |\n| partition_by | vector of column names used for partitioning, only supported for Spark 2.0+ |\n\n\n\n\n\n\n\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}