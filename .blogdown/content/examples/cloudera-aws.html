---
title: "Using sparklyr with an Apache Spark cluster"
output:
  html_document:
    toc: true
    toc_depth: 2
    toc_float:
      collapsed: false
params:
  width: 600
aliases:
  /articles/deployment-cdh.html
---



<div id="summary" class="section level1">
<h1>Summary</h1>
<p>This document demonstrates how to use <code>sparklyr</code> with an Cloudera Hadoop &amp; Spark cluster. Data are downloaded from the web and stored in Hive tables on HDFS across multiple worker nodes. RStudio Server is installed on the master node and orchestrates the analysis in spark.</p>
</div>
<div id="cloudera-cluster" class="section level1">
<h1>Cloudera Cluster</h1>
<p>This demonstration is focused on adding RStudio integration to an existing Cloudera cluster. The assumption will be made that there no aid is needed to setup and administer the cluster.</p>
<p>##CDH 5</p>
<p>We will start with a Cloudera cluster CDH version 5.8.2 (free version) with an underlaying Ubuntu Linux distribution.</p>
<p><img src="images/deployment/cdh/manager-landing-page.png" width=600/></p>
<p>##Spark 1.6</p>
<p>The default Spark 1.6.0 parcel is in installed and running</p>
<p><img src="images/deployment/cdh/spark-history-server-1.png" width=600/></p>
<div id="hive-data" class="section level2">
<h2>Hive data</h2>
<p>For this demo, we have created and populated 3 tables in Hive. The table names are: flights, airlines and airports. Using Hue, we can see the loaded tables. For the links to the data files and their Hive import scripts please see <em>Appendix A</em>.</p>
<p><img src="images/deployment/cdh/hue-metastore-1.png" width=600/></p>
</div>
</div>
<div id="install-rstudio" class="section level1">
<h1>Install RStudio</h1>
<p>The latest version of R is needed. In Ubuntu, the default core R is not the latest so we have to update the source list. We will also install a few other dependencies.</p>
<pre class="bash"><code>sudo sh -c &#39;echo &quot;deb http://cran.rstudio.com/bin/linux/ubuntu trusty/&quot; &gt;&gt; /etc/apt/sources.list&#39;
gpg --keyserver keyserver.ubuntu.com --recv-key 0x517166190x51716619e084dab9
gpg -a --export 0x517166190x51716619e084dab9 | sudo apt-key add -
sudo apt-get update
sudo apt-get install r-base
sudo apt-get install gdebi-core
sudo apt-get -y install libcurl4-gnutls-dev
sudo apt-get -y install libssl-dev</code></pre>
<p>We will install the preview version of RStudio Server</p>
<pre class="bash"><code>wget https://s3.amazonaws.com/rstudio-dailybuilds/rstudio-server-1.0.40-amd64.deb
sudo gdebi rstudio-server-1.0.49-amd64.deb</code></pre>
<div id="create-and-configure-a-user" class="section level3">
<h3>Create and configure a User</h3>
<p>Create a user called <code>rstudio</code> that will perform the data analysis.</p>
<pre class="bash"><code>sudo adduser rstudio</code></pre>
<p>To ease security restriction in this demo, we will add the new user to the default super group defined in the <strong>dfs.permissions.superusergroup</strong> setting in CDH</p>
<pre class="bash"><code>sudo groupadd supergroup
sudo usermod -a -G supergroup rstudio</code></pre>
</div>
</div>
<div id="connect-to-spark" class="section level1">
<h1>Connect to Spark</h1>
<p>Log in to RStudio Server by pointing a browser at your master node IP:8787.</p>
<p>
<img src="images/deployment/cdh/sign-in-1.png" width=600/>
</p>
<p>Set the environment variable <code>SPARK_HOME</code> and then run <code>spark_connect</code>. After connecting you will be able to browse the Hive metadata in the RStudio Server Spark pane.</p>
<pre class="r"><code>library(sparklyr)
library(dplyr)
library(ggplot2)

sc &lt;- spark_connect(master = &quot;yarn-client&quot;, version=&quot;1.6.0&quot;, spark_home = &#39;/opt/cloudera/parcels/CDH/lib/spark/&#39;)</code></pre>
<p>Once you are connected, you will see the Spark pane appear along with your hive tables.</p>
<p>
<img src="images/deployment/cdh/spark-pane-1.png" width=600/>
</p>
<p>You can inspect your tables by clicking on the data icon.</p>
<p>
<img src="images/deployment/cdh/tables-1.png" width=600/>
</p>
<p>This is what the tables look like loaded in Spark via the History Server Web UI (port 18088)</p>
<p>
<img src="images/deployment/cdh/spark-rdd-1.png" width=600/>
</p>
</div>
<div id="data-analysis" class="section level1">
<h1>Data analysis</h1>
<p>Is there evidence to suggest that some airline carriers make up time in flight? This analysis predicts time gained in flight by airline carrier.</p>
<p>
<img src="images/deployment/cdh/data-analysis-1.png" width=600/>
</p>
<div id="cache-the-tables-into-memory" class="section level2">
<h2>Cache the tables into memory</h2>
<p>Use <code>tbl_cache</code> to load the flights table into memory. Caching tables will make analysis much faster. Create a dplyr reference to the Spark DataFrame.</p>
<pre class="r"><code># Cache flights Hive table into Spark
tbl_cache(sc, &#39;flights&#39;)
flights_tbl &lt;- tbl(sc, &#39;flights&#39;)

# Cache airlines Hive table into Spark
tbl_cache(sc, &#39;airlines&#39;)
airlines_tbl &lt;- tbl(sc, &#39;airlines&#39;)

# Cache airports Hive table into Spark
tbl_cache(sc, &#39;airports&#39;)
airports_tbl &lt;- tbl(sc, &#39;airports&#39;)</code></pre>
</div>
<div id="create-a-model-data-set" class="section level2">
<h2>Create a model data set</h2>
<p>Filter the data to contain only the records to be used in the fitted model. Join carrier descriptions for reference. Create a new variable called <code>gain</code> which represents the amount of time gained (or lost) in flight.</p>
<pre class="r"><code># Filter records and create target variable &#39;gain&#39;
model_data &lt;- flights_tbl %&gt;%
  filter(!is.na(arrdelay) &amp; !is.na(depdelay) &amp; !is.na(distance)) %&gt;%
  filter(depdelay &gt; 15 &amp; depdelay &lt; 240) %&gt;%
  filter(arrdelay &gt; -60 &amp; arrdelay &lt; 360) %&gt;%
  filter(year &gt;= 2003 &amp; year &lt;= 2007) %&gt;%
  left_join(airlines_tbl, by = c(&quot;uniquecarrier&quot; = &quot;code&quot;)) %&gt;%
  mutate(gain = depdelay - arrdelay) %&gt;%
  select(year, month, arrdelay, depdelay, distance, uniquecarrier, description, gain)

# Summarize data by carrier
model_data %&gt;%
  group_by(uniquecarrier) %&gt;%
  summarize(description = min(description), gain=mean(gain), 
            distance=mean(distance), depdelay=mean(depdelay)) %&gt;%
  select(description, gain, distance, depdelay) %&gt;%
  arrange(gain)</code></pre>
<pre><code>Source:   query [?? x 4]
Database: spark connection master=yarn-client app=sparklyr local=FALSE

                    description       gain  distance depdelay
                          &lt;chr&gt;      &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
1        ATA Airlines d/b/a ATA -5.5679651 1240.7219 61.84391
2       Northwest Airlines Inc. -3.1134556  779.1926 48.84979
3                     Envoy Air -2.2056576  437.0883 54.54923
4             PSA Airlines Inc. -1.9267647  500.6955 55.60335
5  ExpressJet Airlines Inc. (1) -1.5886314  537.3077 61.58386
6               JetBlue Airways -1.3742524 1087.2337 59.80750
7         SkyWest Airlines Inc. -1.1265678  419.6489 54.04198
8          Delta Air Lines Inc. -0.9829374  956.9576 50.19338
9        American Airlines Inc. -0.9631200 1066.8396 56.78222
10  AirTran Airways Corporation -0.9411572  665.6574 53.38363
# ... with more rows</code></pre>
</div>
<div id="train-a-linear-model" class="section level2">
<h2>Train a linear model</h2>
<p>Predict time gained or lost in flight as a function of distance, departure delay, and airline carrier.</p>
<pre class="r"><code># Partition the data into training and validation sets
model_partition &lt;- model_data %&gt;% 
  sdf_partition(train = 0.8, valid = 0.2, seed = 5555)

# Fit a linear model
ml1 &lt;- model_partition$train %&gt;%
  ml_linear_regression(gain ~ distance + depdelay + uniquecarrier)

# Summarize the linear model
summary(ml1)</code></pre>
<pre><code>Call: ml_linear_regression(., gain ~ distance + depdelay + uniquecarrier)

Deviance Residuals: (approximate):
     Min       1Q   Median       3Q      Max 
-302.343   -5.669    2.714    9.832  104.130 

Coefficients:
                    Estimate  Std. Error  t value  Pr(&gt;|t|)    
(Intercept)      -1.26566581  0.10385870 -12.1864 &lt; 2.2e-16 ***
distance          0.00308711  0.00002404 128.4155 &lt; 2.2e-16 ***
depdelay         -0.01397013  0.00028816 -48.4812 &lt; 2.2e-16 ***
uniquecarrier_AA -2.18483090  0.10985406 -19.8885 &lt; 2.2e-16 ***
uniquecarrier_AQ  3.14330242  0.29114487  10.7964 &lt; 2.2e-16 ***
uniquecarrier_AS  0.09210380  0.12825003   0.7182 0.4726598    
uniquecarrier_B6 -2.66988794  0.12682192 -21.0523 &lt; 2.2e-16 ***
uniquecarrier_CO -1.11611186  0.11795564  -9.4621 &lt; 2.2e-16 ***
uniquecarrier_DL -1.95206198  0.11431110 -17.0767 &lt; 2.2e-16 ***
uniquecarrier_EV  1.70420830  0.11337215  15.0320 &lt; 2.2e-16 ***
uniquecarrier_F9 -1.03178176  0.15384863  -6.7065 1.994e-11 ***
uniquecarrier_FL -0.99574060  0.12034738  -8.2739 2.220e-16 ***
uniquecarrier_HA -1.16970713  0.34894788  -3.3521 0.0008020 ***
uniquecarrier_MQ -1.55569040  0.10975613 -14.1741 &lt; 2.2e-16 ***
uniquecarrier_NW -3.58502418  0.11534938 -31.0797 &lt; 2.2e-16 ***
uniquecarrier_OH -1.40654797  0.12034858 -11.6873 &lt; 2.2e-16 ***
uniquecarrier_OO -0.39069404  0.11132164  -3.5096 0.0004488 ***
uniquecarrier_TZ -7.26285217  0.34428509 -21.0955 &lt; 2.2e-16 ***
uniquecarrier_UA -0.56995737  0.11186757  -5.0949 3.489e-07 ***
uniquecarrier_US -0.52000028  0.11218498  -4.6352 3.566e-06 ***
uniquecarrier_WN  4.22838982  0.10629405  39.7801 &lt; 2.2e-16 ***
uniquecarrier_XE -1.13836940  0.11332176 -10.0455 &lt; 2.2e-16 ***
uniquecarrier_YV  3.17149538  0.11709253  27.0854 &lt; 2.2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

R-Squared: 0.02301
Root Mean Squared Error: 17.83</code></pre>
</div>
<div id="assess-model-performance" class="section level2">
<h2>Assess model performance</h2>
<p>Compare the model performance using the validation data.</p>
<pre class="r"><code># Calculate average gains by predicted decile
model_deciles &lt;- lapply(model_partition, function(x) {
  sdf_predict(ml1, x) %&gt;%
    mutate(decile = ntile(desc(prediction), 10)) %&gt;%
    group_by(decile) %&gt;%
    summarize(gain = mean(gain)) %&gt;%
    select(decile, gain) %&gt;%
    collect()
})

# Create a summary dataset for plotting
deciles &lt;- rbind(
  data.frame(data = &#39;train&#39;, model_deciles$train),
  data.frame(data = &#39;valid&#39;, model_deciles$valid),
  make.row.names = FALSE
)

# Plot average gains by predicted decile
deciles %&gt;%
  ggplot(aes(factor(decile), gain, fill = data)) +
  geom_bar(stat = &#39;identity&#39;, position = &#39;dodge&#39;) +
  labs(title = &#39;Average gain by predicted decile&#39;, x = &#39;Decile&#39;, y = &#39;Minutes&#39;)</code></pre>
<p>
<img src="images/deployment/cdh/performance-1.png" width=600/>
</p>
</div>
<div id="visualize-predictions" class="section level2">
<h2>Visualize predictions</h2>
<p>Compare actual gains to predicted gains for an out of time sample.</p>
<pre class="r"><code># Select data from an out of time sample
data_2008 &lt;- flights_tbl %&gt;%
  filter(!is.na(arrdelay) &amp; !is.na(depdelay) &amp; !is.na(distance)) %&gt;%
  filter(depdelay &gt; 15 &amp; depdelay &lt; 240) %&gt;%
  filter(arrdelay &gt; -60 &amp; arrdelay &lt; 360) %&gt;%
  filter(year == 2008) %&gt;%
  left_join(airlines_tbl, by = c(&quot;uniquecarrier&quot; = &quot;code&quot;)) %&gt;%
  mutate(gain = depdelay - arrdelay) %&gt;%
  select(year, month, arrdelay, depdelay, distance, uniquecarrier, description, gain, origin,dest)

# Summarize data by carrier
carrier &lt;- sdf_predict(ml1, data_2008) %&gt;%
  group_by(description) %&gt;%
  summarize(gain = mean(gain), prediction = mean(prediction), freq = n()) %&gt;%
  filter(freq &gt; 10000) %&gt;%
  collect

# Plot actual gains and predicted gains by airline carrier
ggplot(carrier, aes(gain, prediction)) + 
  geom_point(alpha = 0.75, color = &#39;red&#39;, shape = 3) +
  geom_abline(intercept = 0, slope = 1, alpha = 0.15, color = &#39;blue&#39;) +
  geom_text(aes(label = substr(description, 1, 20)), size = 3, alpha = 0.75, vjust = -1) +
  labs(title=&#39;Average Gains Forecast&#39;, x = &#39;Actual&#39;, y = &#39;Predicted&#39;)</code></pre>
<p>
<img src="images/deployment/cdh/forecast-1.png" width=600/>
</p>
<p>Some carriers make up more time than others in flight, but the differences are relatively small. The average time gains between the best and worst airlines is only six minutes. The best predictor of time gained is not carrier but flight distance. The biggest gains were associated with the longest flights.</p>
</div>
</div>
<div id="share-insights" class="section level1">
<h1>Share Insights</h1>
<p>This simple linear model contains a wealth of detailed information about carriers, distances traveled, and flight delays. These detailed insights can be conveyed to a non-technical audiance via an interactive <a href="http://rmarkdown.rstudio.com/flexdashboard/index.html">flexdashboard</a>.</p>
<div id="build-dashboard" class="section level2">
<h2>Build dashboard</h2>
<p>Aggregate the scored data by origin, destination, and airline. Save the aggregated data.</p>
<pre class="r"><code># Summarize by origin, destination, and carrier
summary_2008 &lt;- sdf_predict(ml1, data_2008) %&gt;%
  rename(carrier = uniquecarrier, airline = description) %&gt;%
  group_by(origin, dest, carrier, airline) %&gt;%
  summarize(
    flights = n(),
    distance = mean(distance),
    avg_dep_delay = mean(depdelay),
    avg_arr_delay = mean(arrdelay),
    avg_gain = mean(gain),
    pred_gain = mean(prediction)
    )

# Collect and save objects
pred_data &lt;- collect(summary_2008)
airports &lt;- collect(select(airports_tbl, name, faa, lat, lon))
ml1_summary &lt;- capture.output(summary(ml1))
save(pred_data, airports, ml1_summary, file = &#39;flights_pred_2008.RData&#39;)</code></pre>
</div>
<div id="publish-dashboard" class="section level2">
<h2>Publish dashboard</h2>
<p>Use the saved data to build an R Markdown <a href="http://rmarkdown.rstudio.com/flexdashboard/index.html">flexdashboard</a>. Publish the flexdashboard</p>
<p><img src="images/deployment/cdh/flex-1.png" width=600/></p>
<p>#Appendix</p>
<div id="appendix-a---data-files" class="section level3">
<h3>Appendix A - Data files</h3>
<p>Run the following script to download data from the web onto your master node. Download the yearly flight data and the airlines lookup table.</p>
<pre class="bash"><code># Make download directory
mkdir /tmp/flights

# Download flight data by year
for i in {2006..2008}
  do
    echo &quot;$(date) $i Download&quot;
    fnam=$i.csv.bz2
    wget -O /tmp/flights/$fnam http://stat-computing.org/dataexpo/2009/$fnam
    echo &quot;$(date) $i Unzip&quot;
    bunzip2 /tmp/flights/$fnam
  done

# Download airline carrier data
wget -O /tmp/airlines.csv http://www.transtats.bts.gov/Download_Lookup.asp?Lookup=L_UNIQUE_CARRIERS

# Download airports data
wget -O /tmp/airports.csv https://raw.githubusercontent.com/jpatokal/openflights/master/data/airports.dat</code></pre>
</div>
<div id="hive-tables" class="section level3">
<h3>Hive tables</h3>
<p>We used the Hue interface, logged in as ‘admin’ to load the data into HDFS and then into Hive.</p>
<pre class="sql"><code>CREATE EXTERNAL TABLE IF NOT EXISTS flights
(
year int,
month int,
dayofmonth int,
dayofweek int,
deptime int,
crsdeptime int,
arrtime int, 
crsarrtime int,
uniquecarrier string,
flightnum int,
tailnum string, 
actualelapsedtime int,
crselapsedtime int,
airtime string,
arrdelay int,
depdelay int, 
origin string,
dest string,
distance int,
taxiin string,
taxiout string,
cancelled int,
cancellationcode string,
diverted int,
carrierdelay string,
weatherdelay string,
nasdelay string,
securitydelay string,
lateaircraftdelay string
)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY &#39;,&#39;
LINES TERMINATED BY &#39;\n&#39;
TBLPROPERTIES(&quot;skip.header.line.count&quot;=&quot;1&quot;);</code></pre>
<pre class="sql"><code>LOAD DATA INPATH &#39;/user/admin/flights/2006.csv/&#39; INTO TABLE flights;
LOAD DATA INPATH &#39;/user/admin/flights/2007.csv/&#39; INTO TABLE flights;
LOAD DATA INPATH &#39;/user/admin/flights/2008.csv/&#39; INTO TABLE flights;</code></pre>
<pre class="sql"><code># Create metadata for airlines
CREATE EXTERNAL TABLE IF NOT EXISTS airlines
(
Code string,
Description string
)
ROW FORMAT SERDE &#39;org.apache.hadoop.hive.serde2.OpenCSVSerde&#39;
WITH SERDEPROPERTIES
(
&quot;separatorChar&quot; = &#39;\,&#39;,
&quot;quoteChar&quot;     = &#39;\&quot;&#39;
)
STORED AS TEXTFILE
tblproperties(&quot;skip.header.line.count&quot;=&quot;1&quot;);</code></pre>
<pre class="sql"><code>LOAD DATA INPATH &#39;/user/admin/L_UNIQUE_CARRIERS.csv&#39; INTO TABLE airlines;</code></pre>
<pre class="sql"><code>CREATE EXTERNAL TABLE IF NOT EXISTS airports
(
id string,
name string,
city string,
country string,
faa string,
icao string,
lat double,
lon double,
alt int,
tz_offset double,
dst string,
tz_name string
)
ROW FORMAT SERDE &#39;org.apache.hadoop.hive.serde2.OpenCSVSerde&#39;
WITH SERDEPROPERTIES
(
&quot;separatorChar&quot; = &#39;\,&#39;,
&quot;quoteChar&quot;     = &#39;\&quot;&#39;
)
STORED AS TEXTFILE;</code></pre>
<pre class="sql"><code>LOAD DATA INPATH &#39;/user/admin/airports.dat&#39; INTO TABLE airports;</code></pre>
</div>
</div>
</div>
