{
  "hash": "fa9fe8490b3f95ba3df06957b0b82a05",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Feature Transformation -- StandardScaler (Estimator)\"\nexecute:\n  freeze: true\n---\n\n\n\n*R/ml_feature_standard_scaler.R*\n\n## ft_standard_scaler\n\n## Description\n Standardizes features by removing the mean and scaling to unit variance using   column summary statistics on the samples in the training set. The \"unit std\"    is computed using the corrected sample standard deviation, which is computed    as the square root of the unbiased sample variance. \n\n\n## Usage\n```r\n \nft_standard_scaler( \n  x, \n  input_col = NULL, \n  output_col = NULL, \n  with_mean = FALSE, \n  with_std = TRUE, \n  uid = random_string(\"standard_scaler_\"), \n  ... \n) \n```\n\n## Arguments\n|Arguments|Description|\n|---|---|\n| x | A `spark_connection`, `ml_pipeline`, or a `tbl_spark`. |\n| input_col | The name of the input column. |\n| output_col | The name of the output column. |\n| with_mean | Whether to center the data with mean before scaling. It will build a dense output, so take care when applying to sparse input. Default: FALSE |\n| with_std | Whether to scale the data to unit standard deviation. Default: TRUE |\n| uid | A character string used to uniquely identify the feature transformer. |\n| ... | Optional arguments; currently unused. |\n\n## Details\n In the case where `x` is a `tbl_spark`, the estimator fits against `x` to obtain a transformer, returning a `tbl_spark`. \n\n\n## Value\n The object returned depends on the class of `x`. If it is a `spark_connection`, the function returns a `ml_estimator` or a `ml_estimator` object. If it is a `ml_pipeline`, it will return a pipeline with the transformer or estimator appended to it. If a `tbl_spark`, it will return a `tbl_spark` with the transformation  applied to it. \n\n\n## Examples\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(sparklyr)\n \nsc <- spark_connect(master = \"local\") \niris_tbl <- sdf_copy_to(sc, iris, name = \"iris_tbl\", overwrite = TRUE) \n \nfeatures <- c(\"Sepal_Length\", \"Sepal_Width\", \"Petal_Length\", \"Petal_Width\") \n \niris_tbl %>% \n  ft_vector_assembler( \n    input_col = features, \n    output_col = \"features_temp\" \n  ) %>% \n  ft_standard_scaler( \n    input_col = \"features_temp\", \n    output_col = \"features\", \n    with_mean = TRUE \n  ) \n \n \n```\n:::\n\n\n## See Also\n Other feature transformers:  `ft_binarizer()`, `ft_bucketizer()`, `ft_chisq_selector()`, `ft_count_vectorizer()`, `ft_dct()`, `ft_elementwise_product()`, `ft_feature_hasher()`, `ft_hashing_tf()`, `ft_idf()`, `ft_imputer()`, `ft_index_to_string()`, `ft_interaction()`, `ft_lsh`, `ft_max_abs_scaler()`, `ft_min_max_scaler()`, `ft_ngram()`, `ft_normalizer()`, `ft_one_hot_encoder()`, `ft_one_hot_encoder_estimator()`, `ft_pca()`, `ft_polynomial_expansion()`, `ft_quantile_discretizer()`, `ft_r_formula()`, `ft_regex_tokenizer()`, `ft_robust_scaler()`, `ft_sql_transformer()`, `ft_stop_words_remover()`, `ft_string_indexer()`, `ft_tokenizer()`, `ft_vector_assembler()`, `ft_vector_indexer()`, `ft_vector_slicer()`, `ft_word2vec()` \n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}