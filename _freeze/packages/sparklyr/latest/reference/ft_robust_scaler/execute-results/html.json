{
  "hash": "7f1018b825f12d96eb6c890f45132e22",
  "result": {
    "markdown": "---\ntitle: \"Feature Transformation -- RobustScaler (Estimator)\"\nexecute:\n  freeze: true\n---\n\n\n\n\n*R/ml_feature_robust_scaler.R*\n\n## ft_robust_scaler\n\n## Description\nRobustScaler removes the median and scales the data according to the quantile range. The quantile range is by default IQR (Interquartile Range, quantile range between the 1st quartile = 25th quantile and the 3rd quartile = 75th quantile) but can be configured. Centering and scaling happen independently on each feature by computing the relevant statistics on the samples in the training set. Median and quantile range are then stored to be used on later data using the transform method. Note that missing values are ignored in the computation of medians and ranges. \n\n\n## Usage\n```r\nft_robust_scaler( \n  x, \n  input_col = NULL, \n  output_col = NULL, \n  lower = 0.25, \n  upper = 0.75, \n  with_centering = TRUE, \n  with_scaling = TRUE, \n  relative_error = 0.001, \n  uid = random_string(\"ft_robust_scaler_\"), \n  ... \n) \n```\n\n## Arguments\n|Arguments|Description|\n|---|---|\n| x | A `spark_connection`, `ml_pipeline`, or a `tbl_spark`. |\n| input_col | The name of the input column. |\n| output_col | The name of the output column. |\n| lower | Lower quantile to calculate quantile range. |\n| upper | Upper quantile to calculate quantile range. |\n| with_centering | Whether to center data with median. |\n| with_scaling | Whether to scale the data to quantile range. |\n| relative_error | The target relative error for quantile computation. |\n| uid | A character string used to uniquely identify the feature transformer. |\n| ... | Optional arguments; currently unused. |\n\n## Details\n\nIn the case where `x` is a `tbl_spark`, the estimator fits against `x`\n\n  to obtain a transformer, which is then immediately used to transform `x`, returning a `tbl_spark`. \n\n\n## Value\n\nThe object returned depends on the class of `x`. \n\n  \n\n- `spark_connection`: When `x` is a `spark_connection`, the function returns a `ml_transformer`,   a `ml_estimator`, or one of their subclasses. The object contains a pointer to   a Spark `Transformer` or `Estimator` object and can be used to compose   `Pipeline` objects. \n\n  \n\n- `ml_pipeline`: When `x` is a `ml_pipeline`, the function returns a `ml_pipeline` with   the transformer or estimator appended to the pipeline. \n\n  \n\n- `tbl_spark`: When `x` is a `tbl_spark`, a transformer is constructed then   immediately applied to the input `tbl_spark`, returning a `tbl_spark`\n\n\n\n## See Also\n\nSee [https://spark.apache.org/docs/latest/ml-features.html](https://spark.apache.org/docs/latest/ml-features.html) for   more information on the set of transformations available for DataFrame   columns in Spark. \n\nOther feature transformers:  `ft_binarizer()`, `ft_bucketizer()`, `ft_chisq_selector()`, `ft_count_vectorizer()`, `ft_dct()`, `ft_elementwise_product()`, `ft_feature_hasher()`, `ft_hashing_tf()`, `ft_idf()`, `ft_imputer()`, `ft_index_to_string()`, `ft_interaction()`, `ft_lsh`, `ft_max_abs_scaler()`, `ft_min_max_scaler()`, `ft_ngram()`, `ft_normalizer()`, `ft_one_hot_encoder_estimator()`, `ft_one_hot_encoder()`, `ft_pca()`, `ft_polynomial_expansion()`, `ft_quantile_discretizer()`, `ft_r_formula()`, `ft_regex_tokenizer()`, `ft_sql_transformer()`, `ft_standard_scaler()`, `ft_stop_words_remover()`, `ft_string_indexer()`, `ft_tokenizer()`, `ft_vector_assembler()`, `ft_vector_indexer()`, `ft_vector_slicer()`, `ft_word2vec()`\n\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}