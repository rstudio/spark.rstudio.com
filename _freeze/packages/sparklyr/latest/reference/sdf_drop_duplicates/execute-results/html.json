{
  "hash": "307e5f4d504bed2de90383986627291a",
  "result": {
    "markdown": "---\ntitle: \"Remove duplicates from a Spark DataFrame\"\nexecute:\n  freeze: true\n---\n\n\n\n\n*R/sdf_interface.R*\n\n## sdf_drop_duplicates\n\n## Description\nRemove duplicates from a Spark DataFrame \n\n\n## Usage\n```r\nsdf_drop_duplicates(x, cols = NULL) \n```\n\n## Arguments\n|Arguments|Description|\n|---|---|\n| x | An object coercible to a Spark DataFrame |\n| cols | Subset of Columns to consider, given as a character vector |\n\n\n\n\n\n\n\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}