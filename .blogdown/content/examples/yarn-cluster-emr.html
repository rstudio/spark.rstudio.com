---
title: "Using sparklyr with an Apache Spark cluster"
output:
  html_document:
    toc: true
    toc_depth: 2
    toc_float:
      collapsed: false
params:
  width: 600
---



<p>This document demonstrates how to use <code>sparklyr</code> with an Apache Spark cluster. Data are downloaded from the web and stored in Hive tables on HDFS across multiple worker nodes. RStudio Server is installed on the master node and orchestrates the analysis in spark. Here is the basic workflow.</p>
<p><img src="images/deployment/amazon-emr/workflowShare.png" width=600/></p>
<div id="data-preparation" class="section level1">
<h1>Data preparation</h1>
<div id="set-up-the-cluster" class="section level2">
<h2>Set up the cluster</h2>
<p>This demonstration uses Amazon Web Services (AWS), but it could just as easily use Microsot, Google, or any other provider. We will use Elastic Map Reduce (EMR) to easily set up a cluster with two core nodes and one master node. Nodes use virtual servers from the Elastic Compute Cloud (EC2). <em>Note: There is no free tier for EMR, charges will apply.</em></p>
<p>Before beginning this setup we assume you have:</p>
<ul>
<li>Familiarity with and access to an AWS account</li>
<li>Familiarity with basic linux commands</li>
<li>Sudo privileges in order to install software from the command line</li>
</ul>
<p>
<img src="images/deployment/amazon-emr/emrArchitecture.png" width=600/>
</p>
<div id="build-an-emr-cluster" class="section level3">
<h3>Build an EMR cluster</h3>
<p>Before beginning the EMR wizard setup, make sure you create the following in AWS:</p>
<ul>
<li>An AWS key pair (.pem key) so you can SSH into the EC2 master node</li>
<li>A security group that gives you access to port 22 on your IP and port 8787 from anywhere</li>
</ul>
<p><img src="images/deployment/amazon-emr/awsNewSecurityGroup.png" width=600/></p>
<hr />
<div id="step-1-select-software" class="section level4">
<h4>Step 1: Select software</h4>
<p>Make sure to select Hive and Spark as part of the install. Note that by choosing Spark, R will also be installed on the master node as part of the distribution.</p>
<p><img src="images/deployment/amazon-emr/emrConfigStep1.png" width=600/></p>
<hr />
</div>
<div id="step-2-select-hardware" class="section level4">
<h4>Step 2: Select hardware</h4>
<p>Install 2 core nodes and one master node with m3.xlarge 80 GiB storage per node. You can easily increase the number of nodes later.</p>
<p><img src="images/deployment/amazon-emr/emrConfigStep2.png" width=600/></p>
<hr />
</div>
<div id="step-3-select-general-cluster-settings" class="section level4">
<h4>Step 3: Select general cluster settings</h4>
<p>Click next on the general cluster settings.</p>
<p><img src="images/deployment/amazon-emr/emrConfigStep3.png" width=600/></p>
<hr />
</div>
<div id="step-4-select-security" class="section level4">
<h4>Step 4: Select security</h4>
<p>Enter your EC2 key pair and security group. Make sure the security group has ports 22 and 8787 open.</p>
<p><img src="images/deployment/amazon-emr/emrConfigStep4.png" width=600/></p>
<hr />
</div>
</div>
<div id="connect-to-emr" class="section level3">
<h3>Connect to EMR</h3>
<p>The cluster page will give you details about your EMR cluster and instructions on connecting.</p>
<p><img src="images/deployment/amazon-emr/awsClusterConnect.png" width=600/></p>
<p>Connect to the master node via SSH using your key pair. Once you connect you will see the EMR welcome.</p>
<pre class="bash"><code># Log in to master node
ssh -i ~/spark-demo.pem hadoop@ec2-52-10-102-11.us-west-2.compute.amazonaws.com</code></pre>
<p><img src="images/deployment/amazon-emr/emrLogin.png" width=600/></p>
</div>
<div id="install-rstudio-server" class="section level3">
<h3>Install RStudio Server</h3>
<p>EMR uses Amazon Linux which is based on Centos. Update your master node and install dependencies that will be used by R packages.</p>
<pre class="bash"><code># Update
sudo yum update
sudo yum install libcurl-devel openssl-devel # used for devtools</code></pre>
<p>The installation of RStudio Server is easy. Download the <a href="https://www.rstudio.com/products/rstudio/download/preview/">preview version</a> of RStudio and install on the master node.</p>
<pre class="bash"><code># Install RStudio Server
wget -P /tmp https://s3.amazonaws.com/rstudio-dailybuilds/rstudio-server-rhel-0.99.1266-x86_64.rpm
sudo yum install --nogpgcheck /tmp/rstudio-server-rhel-0.99.1266-x86_64.rpm</code></pre>
</div>
<div id="create-a-user" class="section level3">
<h3>Create a User</h3>
<p>Create a user called <code>rstudio-user</code> that will perform the data analysis. Create a user directory for <code>rstudio-user</code> on HDFS with the <code>hadoop fs</code> command.</p>
<pre class="bash"><code># Make User
sudo useradd -m rstudio-user
sudo passwd rstudio-user

# Create new directory in hdfs
hadoop fs -mkdir /user/rstudio-user
hadoop fs -chmod 777 /user/rstudio-user</code></pre>
</div>
</div>
<div id="download-flights-data" class="section level2">
<h2>Download flights data</h2>
<p>The <a href="http://stat-computing.org/dataexpo/2009/the-data.html">flights</a> data is a well known data source representing 123 million flights over 22 years. It consumes roughly 12 GiB of storage in uncompressed CSV format in yearly files.</p>
<div id="switch-user" class="section level4">
<h4>Switch User</h4>
<p>For data loading and analysis, make sure you are logged in as regular user.</p>
<pre class="bash"><code># create directories on hdfs for new user
hadoop fs -mkdir /user/rstudio-user
hadoop fs -chmod 777 /user/rstudio-user

# switch user
su rstudio-user</code></pre>
</div>
<div id="download-data" class="section level3">
<h3>Download data</h3>
<p>Run the following script to download data from the web onto your master node. Download the yearly flight data and the airlines lookup table.</p>
<pre class="bash"><code># Make download directory
mkdir /tmp/flights

# Download flight data by year
for i in {1987..2008}
  do
    echo &quot;$(date) $i Download&quot;
    fnam=$i.csv.bz2
    wget -O /tmp/flights/$fnam http://stat-computing.org/dataexpo/2009/$fnam
    echo &quot;$(date) $i Unzip&quot;
    bunzip2 /tmp/flights/$fnam
  done

# Download airline carrier data
wget -O /tmp/airlines.csv http://www.transtats.bts.gov/Download_Lookup.asp?Lookup=L_UNIQUE_CARRIERS

# Download airports data
wget -O /tmp/airports.csv https://raw.githubusercontent.com/jpatokal/openflights/master/data/airports.dat</code></pre>
</div>
<div id="distribute-into-hdfs" class="section level3">
<h3>Distribute into HDFS</h3>
<p>Copy data into HDFS using the <code>hadoop fs</code> command.</p>
<pre class="bash"><code># Copy flight data to HDFS
hadoop fs -mkdir /user/rstudio-user/flights/
hadoop fs -put /tmp/flights /user/rstudio-user/

# Copy airline data to HDFS
hadoop fs -mkdir /user/rstudio-user/airlines/
hadoop fs -put /tmp/airlines.csv /user/rstudio-user/airlines

# Copy airport data to HDFS
hadoop fs -mkdir /user/rstudio-user/airports/
hadoop fs -put /tmp/airports.csv /user/rstudio-user/airports</code></pre>
</div>
</div>
<div id="create-hive-tables" class="section level2">
<h2>Create Hive tables</h2>
<p>Launch Hive from the command line.</p>
<pre class="bash"><code># Open Hive prompt
hive</code></pre>
<p>Create the metadata that will structure the flights table. Load data into the Hive table.</p>
<pre class="sql"><code># Create metadata for flights
CREATE EXTERNAL TABLE IF NOT EXISTS flights
(
year int,
month int,
dayofmonth int,
dayofweek int,
deptime int,
crsdeptime int,
arrtime int, 
crsarrtime int,
uniquecarrier string,
flightnum int,
tailnum string, 
actualelapsedtime int,
crselapsedtime int,
airtime string,
arrdelay int,
depdelay int, 
origin string,
dest string,
distance int,
taxiin string,
taxiout string,
cancelled int,
cancellationcode string,
diverted int,
carrierdelay string,
weatherdelay string,
nasdelay string,
securitydelay string,
lateaircraftdelay string
)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY &#39;,&#39;
LINES TERMINATED BY &#39;\n&#39;
TBLPROPERTIES(&quot;skip.header.line.count&quot;=&quot;1&quot;);

# Load data into table
LOAD DATA INPATH &#39;/user/rstudio-user/flights&#39; INTO TABLE flights;</code></pre>
<p>Create the metadata that will structure the airlines table. Load data into the Hive table.</p>
<pre class="sql"><code># Create metadata for airlines
CREATE EXTERNAL TABLE IF NOT EXISTS airlines
(
Code string,
Description string
)
ROW FORMAT SERDE &#39;org.apache.hadoop.hive.serde2.OpenCSVSerde&#39;
WITH SERDEPROPERTIES
(
&quot;separatorChar&quot; = &#39;\,&#39;,
&quot;quoteChar&quot;     = &#39;\&quot;&#39;
)
STORED AS TEXTFILE
tblproperties(&quot;skip.header.line.count&quot;=&quot;1&quot;);

# Load data into table
LOAD DATA INPATH &#39;/user/rstudio-user/airlines&#39; INTO TABLE airlines;</code></pre>
<p>Create the metadata that will structure the airports table. Load data into the Hive table.</p>
<pre class="sql"><code># Create metadata for airports
CREATE EXTERNAL TABLE IF NOT EXISTS airports
(
id string,
name string,
city string,
country string,
faa string,
icao string,
lat double,
lon double,
alt int,
tz_offset double,
dst string,
tz_name string
)
ROW FORMAT SERDE &#39;org.apache.hadoop.hive.serde2.OpenCSVSerde&#39;
WITH SERDEPROPERTIES
(
&quot;separatorChar&quot; = &#39;\,&#39;,
&quot;quoteChar&quot;     = &#39;\&quot;&#39;
)
STORED AS TEXTFILE;

# Load data into table
LOAD DATA INPATH &#39;/user/rstudio-user/airports&#39; INTO TABLE airports;</code></pre>
</div>
<div id="connect-to-spark" class="section level2">
<h2>Connect to Spark</h2>
<p>Log in to RStudio Server by pointing a browser at your master node IP:8787.</p>
<p>
<img src="images/deployment/amazon-emr/rstudioLogin.png" width=600/>
</p>
<p>Set the environment variable <code>SPARK_HOME</code> and then run <code>spark_connect</code>. After connecting you will be able to browse the Hive metadata in the RStudio Server Spark pane.</p>
<pre class="r"><code># Connect to Spark
library(sparklyr)
library(dplyr)
library(ggplot2)
Sys.setenv(SPARK_HOME=&quot;/usr/lib/spark&quot;)
config &lt;- spark_config()
sc &lt;- spark_connect(master = &quot;yarn-client&quot;, config = config, version = &#39;1.6.2&#39;)</code></pre>
<p>Once you are connected, you will see the Spark pane appear along with your hive tables.</p>
<p>
<img src="images/deployment/amazon-emr/rstudioSparkPane.png" width=600/>
</p>
<p>You can inspect your tables by clicking on the data icon.</p>
<p>
<img src="images/deployment/amazon-emr/rstudioData.png" width=600/>
</p>
</div>
</div>
<div id="data-analysis" class="section level1">
<h1>Data analysis</h1>
<p>Is there evidence to suggest that some airline carriers make up time in flight? This analysis predicts time gained in flight by airline carrier.</p>
<p>
<img src="images/deployment/amazon-emr/rstudio.png" width=600/>
</p>
<div id="cache-the-tables-into-memory" class="section level2">
<h2>Cache the tables into memory</h2>
<p>Use <code>tbl_cache</code> to load the flights table into memory. Caching tables will make analysis much faster. Create a dplyr reference to the Spark DataFrame.</p>
<pre class="r"><code># Cache flights Hive table into Spark
tbl_cache(sc, &#39;flights&#39;)
flights_tbl &lt;- tbl(sc, &#39;flights&#39;)

# Cache airlines Hive table into Spark
tbl_cache(sc, &#39;airlines&#39;)
airlines_tbl &lt;- tbl(sc, &#39;airlines&#39;)

# Cache airports Hive table into Spark
tbl_cache(sc, &#39;airports&#39;)
airports_tbl &lt;- tbl(sc, &#39;airports&#39;)</code></pre>
</div>
<div id="create-a-model-data-set" class="section level2">
<h2>Create a model data set</h2>
<p>Filter the data to contain only the records to be used in the fitted model. Join carrier descriptions for reference. Create a new variable called <code>gain</code> which represents the amount of time gained (or lost) in flight.</p>
<pre class="r"><code># Filter records and create target variable &#39;gain&#39;
model_data &lt;- flights_tbl %&gt;%
  filter(!is.na(arrdelay) &amp; !is.na(depdelay) &amp; !is.na(distance)) %&gt;%
  filter(depdelay &gt; 15 &amp; depdelay &lt; 240) %&gt;%
  filter(arrdelay &gt; -60 &amp; arrdelay &lt; 360) %&gt;%
  filter(year &gt;= 2003 &amp; year &lt;= 2007) %&gt;%
  left_join(airlines_tbl, by = c(&quot;uniquecarrier&quot; = &quot;code&quot;)) %&gt;%
  mutate(gain = depdelay - arrdelay) %&gt;%
  select(year, month, arrdelay, depdelay, distance, uniquecarrier, description, gain)

# Summarize data by carrier
model_data %&gt;%
  group_by(uniquecarrier) %&gt;%
  summarize(description = min(description), gain=mean(gain), 
            distance=mean(distance), depdelay=mean(depdelay)) %&gt;%
  select(description, gain, distance, depdelay) %&gt;%
  arrange(gain)</code></pre>
<pre><code>Source:   query [?? x 4]
Database: spark connection master=yarn-client app=sparklyr local=FALSE

                    description       gain  distance depdelay
                          &lt;chr&gt;      &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
1        ATA Airlines d/b/a ATA -3.3480120 1134.7084 56.06583
2  ExpressJet Airlines Inc. (1) -3.0326180  519.7125 59.41659
3                     Envoy Air -2.5434415  416.3716 53.12529
4       Northwest Airlines Inc. -2.2030586  779.2342 48.52828
5          Delta Air Lines Inc. -1.8248026  868.3997 50.77174
6   AirTran Airways Corporation -1.4331555  641.8318 54.96702
7    Continental Air Lines Inc. -0.9617003 1116.6668 57.00553
8        American Airlines Inc. -0.8860262 1074.4388 55.45045
9             Endeavor Air Inc. -0.6392733  467.1951 58.47395
10              JetBlue Airways -0.3262134 1139.0443 54.06156
# ... with more rows</code></pre>
</div>
<div id="train-a-linear-model" class="section level2">
<h2>Train a linear model</h2>
<p>Predict time gained or lost in flight as a function of distance, departure delay, and airline carrier.</p>
<pre class="r"><code># Partition the data into training and validation sets
model_partition &lt;- model_data %&gt;% 
  sdf_partition(train = 0.8, valid = 0.2, seed = 5555)

# Fit a linear model
ml1 &lt;- model_partition$train %&gt;%
  ml_linear_regression(gain ~ distance + depdelay + uniquecarrier)

# Summarize the linear model
summary(ml1)</code></pre>
<pre><code>Deviance Residuals: (approximate):
     Min       1Q   Median       3Q      Max 
-305.422   -5.593    2.699    9.750  147.871 

Coefficients:
                    Estimate  Std. Error  t value  Pr(&gt;|t|)    
(Intercept)      -1.24342576  0.10248281 -12.1330 &lt; 2.2e-16 ***
distance          0.00326600  0.00001670 195.5709 &lt; 2.2e-16 ***
depdelay         -0.01466233  0.00020337 -72.0977 &lt; 2.2e-16 ***
uniquecarrier_AA -2.32650517  0.10522524 -22.1098 &lt; 2.2e-16 ***
uniquecarrier_AQ  2.98773637  0.28798507  10.3746 &lt; 2.2e-16 ***
uniquecarrier_AS  0.92054894  0.11298561   8.1475 4.441e-16 ***
uniquecarrier_B6 -1.95784698  0.11728289 -16.6934 &lt; 2.2e-16 ***
uniquecarrier_CO -2.52618081  0.11006631 -22.9514 &lt; 2.2e-16 ***
uniquecarrier_DH  2.23287189  0.11608798  19.2343 &lt; 2.2e-16 ***
uniquecarrier_DL -2.68848119  0.10621977 -25.3106 &lt; 2.2e-16 ***
uniquecarrier_EV  1.93484736  0.10724290  18.0417 &lt; 2.2e-16 ***
uniquecarrier_F9 -0.89788137  0.14422281  -6.2257 4.796e-10 ***
uniquecarrier_FL -1.46706706  0.11085354 -13.2343 &lt; 2.2e-16 ***
uniquecarrier_HA -0.14506644  0.25031456  -0.5795    0.5622    
uniquecarrier_HP  2.09354855  0.12337515  16.9690 &lt; 2.2e-16 ***
uniquecarrier_MQ -1.88297535  0.10550507 -17.8473 &lt; 2.2e-16 ***
uniquecarrier_NW -2.79538927  0.10752182 -25.9983 &lt; 2.2e-16 ***
uniquecarrier_OH  0.83520117  0.11032997   7.5700 3.730e-14 ***
uniquecarrier_OO  0.61993842  0.10679884   5.8047 6.447e-09 ***
uniquecarrier_TZ -4.99830389  0.15912629 -31.4109 &lt; 2.2e-16 ***
uniquecarrier_UA -0.68294396  0.10638099  -6.4198 1.365e-10 ***
uniquecarrier_US -0.61589284  0.10669583  -5.7724 7.815e-09 ***
uniquecarrier_WN  3.86386059  0.10362275  37.2878 &lt; 2.2e-16 ***
uniquecarrier_XE -2.59658123  0.10775736 -24.0966 &lt; 2.2e-16 ***
uniquecarrier_YV  3.11113140  0.11659679  26.6828 &lt; 2.2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

R-Squared: 0.02385
Root Mean Squared Error: 17.74</code></pre>
</div>
<div id="assess-model-performance" class="section level2">
<h2>Assess model performance</h2>
<p>Compare the model performance using the validation data.</p>
<pre class="r"><code># Calculate average gains by predicted decile
model_deciles &lt;- lapply(model_partition, function(x) {
  sdf_predict(ml1, x) %&gt;%
    mutate(decile = ntile(desc(prediction), 10)) %&gt;%
    group_by(decile) %&gt;%
    summarize(gain = mean(gain)) %&gt;%
    select(decile, gain) %&gt;%
    collect()
})

# Create a summary dataset for plotting
deciles &lt;- rbind(
  data.frame(data = &#39;train&#39;, model_deciles$train),
  data.frame(data = &#39;valid&#39;, model_deciles$valid),
  make.row.names = FALSE
)

# Plot average gains by predicted decile
deciles %&gt;%
  ggplot(aes(factor(decile), gain, fill = data)) +
  geom_bar(stat = &#39;identity&#39;, position = &#39;dodge&#39;) +
  labs(title = &#39;Average gain by predicted decile&#39;, x = &#39;Decile&#39;, y = &#39;Minutes&#39;)</code></pre>
<p>
<img src="images/deployment/amazon-emr/performance-1.png" width=600/>
</p>
</div>
<div id="visualize-predictions" class="section level2">
<h2>Visualize predictions</h2>
<p>Compare actual gains to predicted gains for an out of time sample.</p>
<pre class="r"><code># Select data from an out of time sample
data_2008 &lt;- flights_tbl %&gt;%
  filter(!is.na(arrdelay) &amp; !is.na(depdelay) &amp; !is.na(distance)) %&gt;%
  filter(depdelay &gt; 15 &amp; depdelay &lt; 240) %&gt;%
  filter(arrdelay &gt; -60 &amp; arrdelay &lt; 360) %&gt;%
  filter(year == 2008) %&gt;%
  left_join(airlines_tbl, by = c(&quot;uniquecarrier&quot; = &quot;code&quot;)) %&gt;%
  mutate(gain = depdelay - arrdelay) %&gt;%
  select(year, month, arrdelay, depdelay, distance, uniquecarrier, description, gain, origin,dest)

# Summarize data by carrier
carrier &lt;- sdf_predict(ml1, data_2008) %&gt;%
  group_by(description) %&gt;%
  summarize(gain = mean(gain), prediction = mean(prediction), freq = n()) %&gt;%
  filter(freq &gt; 10000) %&gt;%
  collect

# Plot actual gains and predicted gains by airline carrier
ggplot(carrier, aes(gain, prediction)) + 
  geom_point(alpha = 0.75, color = &#39;red&#39;, shape = 3) +
  geom_abline(intercept = 0, slope = 1, alpha = 0.15, color = &#39;blue&#39;) +
  geom_text(aes(label = substr(description, 1, 20)), size = 3, alpha = 0.75, vjust = -1) +
  labs(title=&#39;Average Gains Forecast&#39;, x = &#39;Actual&#39;, y = &#39;Predicted&#39;)</code></pre>
<p>
<img src="images/deployment/amazon-emr/forecast-1.png" width=600/>
</p>
<p>Some carriers make up more time than others in flight, but the differences are relatively small. The average time gains between the best and worst airlines is only six minutes. The best predictor of time gained is not carrier but flight distance. The biggest gains were associated with the longest flights.</p>
</div>
</div>
<div id="share-insights" class="section level1">
<h1>Share Insights</h1>
<p>This simple linear model contains a wealth of detailed information about carriers, distances traveled, and flight delays. These detailed insights can be conveyed to a non-technical audiance via an interactive <a href="http://rmarkdown.rstudio.com/flexdashboard/index.html">flexdashboard</a>.</p>
<div id="build-dashboard" class="section level2">
<h2>Build dashboard</h2>
<p>Aggregate the scored data by origin, destination, and airline. Save the aggregated data.</p>
<pre class="r"><code># Summarize by origin, destination, and carrier
summary_2008 &lt;- sdf_predict(ml1, data_2008) %&gt;%
  rename(carrier = uniquecarrier, airline = description) %&gt;%
  group_by(origin, dest, carrier, airline) %&gt;%
  summarize(
    flights = n(),
    distance = mean(distance),
    avg_dep_delay = mean(depdelay),
    avg_arr_delay = mean(arrdelay),
    avg_gain = mean(gain),
    pred_gain = mean(prediction)
    )

# Collect and save objects
pred_data &lt;- collect(summary_2008)
airports &lt;- collect(select(airports_tbl, name, faa, lat, lon))
ml1_summary &lt;- capture.output(summary(ml1))
save(pred_data, airports, ml1_summary, file = &#39;flights_pred_2008.RData&#39;)</code></pre>
</div>
<div id="publish-dashboard" class="section level2">
<h2>Publish dashboard</h2>
Use the saved data to build an R Markdown <a href="http://rmarkdown.rstudio.com/flexdashboard/index.html">flexdashboard</a>. Publish the flexdashboard to <a href="https://www.rstudio.com/products/shiny-server-pro/">Shiny Server</a>, <a href="https://www.rstudio.com/products/shinyapps/">Shinyapps.io</a> or <a href="https://www.rstudio.com/products/connect/">RStudio Connect</a>.
<p>
<a href="https://beta.rstudioconnect.com/content/1439/">
<img src="images/deployment/amazon-emr/flightsDashboard.png" width=600/>
</a>
</p>
</div>
</div>
