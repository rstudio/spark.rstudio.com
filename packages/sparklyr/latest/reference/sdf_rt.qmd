---
title: "Generate random samples from a t-distribution"
execute:
  freeze: true
---

```{r, eval=ecodown::examples_not_run()}
#| include: false
options("pillar.width" = 60)
library(sparklyr) 
library(dplyr)
```

*R/sdf_stat.R*

## sdf_rt

## Description
 Generator method for creating a single-column Spark dataframes comprised of i.i.d. samples from a t-distribution. 


## Usage
```r
 
sdf_rt(sc, n, df, num_partitions = NULL, seed = NULL, output_col = "x") 
```

## Arguments
|Arguments|Description|
|---|---|
| sc | A Spark connection. |
| n | Sample Size (default: 1000). |
| df | Degrees of freedom (> 0, maybe non-integer). |
| num_partitions | Number of partitions in the resulting Spark dataframe (default: default parallelism of the Spark cluster). |
| seed | Random seed (default: a random long integer). |
| output_col | Name of the output column containing sample values (default: "x"). |






## See Also
 Other Spark statistical routines:  `sdf_rbeta()`, `sdf_rbinom()`, `sdf_rcauchy()`, `sdf_rchisq()`, `sdf_rexp()`, `sdf_rgamma()`, `sdf_rgeom()`, `sdf_rhyper()`, `sdf_rlnorm()`, `sdf_rnorm()`, `sdf_rpois()`, `sdf_runif()`, `sdf_rweibull()` 


```{r, eval=ecodown::examples_not_run()}
#| include: false
spark_disconnect_all()
```
