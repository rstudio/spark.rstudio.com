---
title: "Using sparklyr with Databricks"
output:
  html_document:
    toc: true
    toc_depth: 2
    toc_float:
      collapsed: false
params:
  width: 600
---



<div id="overview" class="section level2">
<h2>Overview</h2>
<p>This documentation demonstrates how to use <code>sparklyr</code> with RStudio Server Pro
and a Databricks cluster with Apache Spark.</p>
</div>
<div id="best-practices" class="section level2">
<h2>Best practices</h2>
<ul>
<li><strong>Remote connectivity</strong> - Install RStudio Server Pro outside of the
Databricks cluster and work with Spark remotely</li>
<li><strong>RStudio Team</strong> - Install RStudio Connect and RStudio Package Manager outside
of the Databricks cluster so that they are not limited to the resources or
ephemeral nature of a Databricks cluster</li>
<li><strong>Limit to interactive workloads</strong> - Perform interactive analyses with Spark,
then write the results to a database, file storage, or cloud storage for more
efficient retrival</li>
<li><strong>Efficiently loading results</strong> - Shiny apps that use Spark tend to have
performance issues, instead, consider reading the results from a database,
file storage, or cloud storage instead</li>
<li><strong>Persisent installation</strong> - If you cannot work with Spark remotely, you
should install RStudio Server Pro on the Driver node of a persistent
Databricks cluster as opposed to a Worker node or an ephemeral cluster</li>
</ul>
</div>
<div id="options-for-using-rstudio-with-databricks" class="section level2">
<h2>Options for using RStudio with Databricks</h2>
<p>There are two different options for using <code>sparklyr</code> with Databricks:</p>
<ul>
<li>Option 1 (Recommended option): <a href="#option-1---connecting-to-databricks-remotely">Connecting to Databricks remotely</a></li>
<li>Option 2 (Alternative option): <a href="#option-2---working-with-databricks-locally">Working with Databricks locally</a></li>
</ul>
<div id="option-1---connecting-to-databricks-remotely" class="section level3">
<h3>Option 1 - Connecting to Databricks remotely</h3>
<p>With this configuration, RStudio Server Pro is installed outside of the Spark
cluster and allows users to connect to Spark remotely using
<a href="https://docs.databricks.com/dev-tools/databricks-connect.html">Databricks Connect</a>.</p>
<p>This is the recommended configuration because it targets separate environments,
involves simpler configuration, avoids resource contention, and allows RStudio
Server Pro to connect to Databricks as well as other remote storage and compute
resources.</p>
<p><a href="/examples/databricks-cluster-remote">
<img src="/images/deployment/databricks/rstudio-databricks-remote.png" width='800px' align='center'/>
</a></p>
<a href="/examples/databricks-cluster-remote">
<h2>
View steps for connecting to Databricks remotely
</h2>
<p></a></p>
</div>
<div id="option-2---working-with-databricks-locally" class="section level3">
<h3>Option 2 - Working with Databricks locally</h3>
<p>With this configuration, RStudio Server Pro is installed on the Spark driver
node and allows users to work locally with Spark.</p>
<p>This configuration can result in more complex configuration, limited
connectivity to other storage and compute sources, resource contention between
RStudio Server Pro and Databricks, and maintenance concerns due to the ephemeral
nature of Databricks clusters.</p>
<p><a href="/examples/databricks-cluster-local">
<img src="/images/deployment/databricks/rstudio-databricks-local.png" width='800px' align='center'/>
</a></p>
<a href="/examples/databricks-cluster-local">
<h2>
View steps for working with Databricks locally
</h2>
<p></a></p>
</div>
</div>
