{
  "hash": "fa4e376f3e478de98dd8aae83c5588a6",
  "result": {
    "markdown": "---\ntitle: \"Save / Load a Spark DataFrame\"\nexecute:\n  freeze: true\n---\n\n\n\n\n*R/sdf_saveload.R*\n\n## sdf-saveload\n\n## Description\nRoutines for saving and loading Spark DataFrames. \n\n\n## Usage\n```r\nsdf_save_table(x, name, overwrite = FALSE, append = FALSE) \n\nsdf_load_table(sc, name) \n\nsdf_save_parquet(x, path, overwrite = FALSE, append = FALSE) \n\nsdf_load_parquet(sc, path) \n```\n\n## Arguments\n|Arguments|Description|\n|---|---|\n| x | A `spark_connection`, `ml_pipeline`, or a `tbl_spark`. |\n| name | The table name to assign to the saved Spark DataFrame. |\n| overwrite | Boolean; overwrite a pre-existing table of the same name? |\n| append | Boolean; append to a pre-existing table of the same name? |\n| sc | A `spark_connection` object. |\n| path | The path where the Spark DataFrame should be saved. |\n\n\n\n\n\n\n\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}