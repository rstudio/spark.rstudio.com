{
  "hash": "a52766ad5ee7b261615d640c3273e7e3",
  "result": {
    "markdown": "---\ntitle: \"Spark ML -- Tuning\"\nexecute:\n  freeze: true\n---\n\n\n*R/ml_tuning.R, R/ml_tuning_cross_validator.R,*\n\n## ml-tuning\n\n## Description\nPerform hyper-parameter tuning using either K-fold cross validation or train-validation split. \n\n\n## Usage\n```r\nml_sub_models(model) \n\nml_validation_metrics(model) \n\nml_cross_validator( \n  x, \n  estimator = NULL, \n  estimator_param_maps = NULL, \n  evaluator = NULL, \n  num_folds = 3, \n  collect_sub_models = FALSE, \n  parallelism = 1, \n  seed = NULL, \n  uid = random_string(\"cross_validator_\"), \n  ... \n) \n\nml_train_validation_split( \n  x, \n  estimator = NULL, \n  estimator_param_maps = NULL, \n  evaluator = NULL, \n  train_ratio = 0.75, \n  collect_sub_models = FALSE, \n  parallelism = 1, \n  seed = NULL, \n  uid = random_string(\"train_validation_split_\"), \n  ... \n) \n```\n\n## Arguments\n|Arguments|Description|\n|---|---|\n| model | A cross validation or train-validation-split model. |\n| x | A `spark_connection`, `ml_pipeline`, or a `tbl_spark`. |\n| estimator | A `ml_estimator` object. |\n| estimator_param_maps | A named list of stages and hyper-parameter sets to tune. See details. |\n| evaluator | A `ml_evaluator` object, see ml_evaluator. |\n| num_folds | Number of folds for cross validation. Must be >= 2. Default: 3 |\n| collect_sub_models | Whether to collect a list of sub-models trained during tuning. If set to `FALSE`, then only the single best sub-model will be available after fitting. If set to true, then all sub-models will be available. Warning: For large models, collecting all sub-models can cause OOMs on the Spark driver. |\n| parallelism | The number of threads to use when running parallel algorithms. Default is 1 for serial execution. |\n| seed | A random seed. Set this value if you need your results to be reproducible across repeated calls. |\n| uid | A character string used to uniquely identify the ML estimator. |\n| ... | Optional arguments; currently unused. |\n| train_ratio | Ratio between train and validation data. Must be between 0 and 1. Default: 0.75 |\n\n## Details\n`ml_cross_validator()` performs k-fold cross validation while `ml_train_validation_split()` performs tuning on one pair of train and validation datasets. \n\n\n## Value\n\nThe object returned depends on the class of `x`. \n\n  \n\n- `spark_connection`: When `x` is a `spark_connection`, the function returns an instance of a `ml_cross_validator` or `ml_traing_validation_split` object. \n\n  \n\n- `ml_pipeline`: When `x` is a `ml_pipeline`, the function returns a `ml_pipeline` with   the tuning estimator appended to the pipeline. \n\n  \n\n- `tbl_spark`: When `x` is a `tbl_spark`, a tuning estimator is constructed then   immediately fit with the input `tbl_spark`, returning a `ml_cross_validation_model` or a   `ml_train_validation_split_model` object. \n\nFor cross validation, `ml_sub_models()` returns a nested   list of models, where the first layer represents fold indices and the   second layer represents param maps. For train-validation split,   `ml_sub_models()` returns a list of models, corresponding to the   order of the estimator param maps. \n\n`ml_validation_metrics()` returns a data frame of performance   metrics and hyperparameter combinations. \n\n\n## Examples\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(sparklyr)\nsc <- spark_connect(master = \"local\") \niris_tbl <- sdf_copy_to(sc, iris, name = \"iris_tbl\", overwrite = TRUE) \n# Create a pipeline \npipeline <- ml_pipeline(sc) %>% \n  ft_r_formula(Species ~ .) %>% \n  ml_random_forest_classifier() \n# Specify hyperparameter grid \ngrid <- list( \n  random_forest = list( \n    num_trees = c(5, 10), \n    max_depth = c(5, 10), \n    impurity = c(\"entropy\", \"gini\") \n  ) \n) \n# Create the cross validator object \ncv <- ml_cross_validator( \n  sc, \n  estimator = pipeline, estimator_param_maps = grid, \n  evaluator = ml_multiclass_classification_evaluator(sc), \n  num_folds = 3, \n  parallelism = 4 \n) \n# Train the models \ncv_model <- ml_fit(cv, iris_tbl) \n# Print the metrics \nml_validation_metrics(cv_model) \n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}