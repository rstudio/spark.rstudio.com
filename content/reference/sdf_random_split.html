---
title: "Partition a Spark Dataframe"
aliases:
  - reference/sparklyr/latest/sdf_random_split.html
---

    <div>

    <div>
    <ul data-gumshoe>
    <li><a href="#arguments">Arguments</a></li>
    <li><a href="#value">Value</a></li>
    <li><a href="#details">Details</a></li>
    <li><a href="#transforming-spark-dataframes">Transforming Spark DataFrames</a></li>
    <li><a href="#see-also">See also</a></li>
    <li><a href="#examples">Examples</a></li>
    </ul>
    </div>

    <div>

    <p>Partition a Spark DataFrame into multiple groups. This routine is useful
for splitting a DataFrame into, for example, training and test datasets.</p>

    <div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class='fu'>sdf_random_split</span>(
  <span class='no'>x</span>,
  <span class='no'>...</span>,
  <span class='kw'>weights</span> <span class='kw'>=</span> <span class='kw'>NULL</span>,
  <span class='kw'>seed</span> <span class='kw'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/sample.html'>sample</a></span>(<span class='no'>.Machine</span>$<span class='no'>integer.max</span>, <span class='fl'>1</span>)
)

<span class='fu'>sdf_partition</span>(<span class='no'>x</span>, <span class='no'>...</span>, <span class='kw'>weights</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>seed</span> <span class='kw'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/sample.html'>sample</a></span>(<span class='no'>.Machine</span>$<span class='no'>integer.max</span>, <span class='fl'>1</span>))</code></pre></div>

    <h2 id="arguments">Arguments</h2>
    <table class="ref-arguments">

    <colgroup>
      <col class="name" />
      <col class="desc" />
    </colgroup>

    <tr>
      <td>x</td>
      <td><p>An object coercable to a Spark DataFrame.</p></td>
    </tr>
    <tr>
      <td>...</td>
      <td><p>Named parameters, mapping table names to weights. The weights
will be normalized such that they sum to 1.</p></td>
    </tr>
    <tr>
      <td>weights</td>
      <td><p>An alternate mechanism for supplying weights -- when
specified, this takes precedence over the <code>...</code> arguments.</p></td>
    </tr>
    <tr>
      <td>seed</td>
      <td><p>Random seed to use for randomly partitioning the dataset. Set
this if you want your partitioning to be reproducible on repeated runs.</p></td>
    </tr>
    </table>

    <h2 id="value">Value</h2>

    <p>An <span style="R">R</span> <code>list</code> of <code>tbl_spark</code>s.</p>
    <h2 id="details">Details</h2>

    <p>The sampling weights define the probability that a particular observation
will be assigned to a particular partition, not the resulting size of the
partition. This implies that partitioning a DataFrame with, for example,</p>
<p><code>sdf_random_split(x, training = 0.5, test = 0.5)</code></p>
<p>is not guaranteed to produce <code>training</code> and <code>test</code> partitions
of equal size.</p>
    <h2 id="transforming-spark-dataframes">Transforming Spark DataFrames</h2>

    


<p>The family of functions prefixed with <code>sdf_</code> generally access the Scala
Spark DataFrame API directly, as opposed to the <code>dplyr</code> interface which
uses Spark SQL. These functions will 'force' any pending SQL in a
<code>dplyr</code> pipeline, such that the resulting <code>tbl_spark</code> object
returned will no longer have the attached 'lazy' SQL operations. Note that
the underlying Spark DataFrame <em>does</em> execute its operations lazily, so
that even though the pending set of operations (currently) are not exposed at
the <span style="R">R</span> level, these operations will only be executed when you explicitly
<code><a href='collect.html'>collect()</a></code> the table.</p>
    <h2 id="see-also">See also</h2>

    <div class='dont-index'><p>Other Spark data frames: 
<code><a href='sdf_copy_to.html'>sdf_copy_to</a>()</code>,
<code><a href='sdf_register.html'>sdf_register</a>()</code>,
<code><a href='sdf_sample.html'>sdf_sample</a>()</code>,
<code><a href='sdf_sort.html'>sdf_sort</a>()</code>,
<code><a href='sdf_weighted_sample.html'>sdf_weighted_sample</a>()</code></p></div>

    <h2 id="examples">Examples</h2>
    <div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><div class='input'><span class='kw'>if</span> (<span class='fl'>FALSE</span>) {
<span class='co'># randomly partition data into a 'training' and 'test'</span>
<span class='co'># dataset, with 60% of the observations assigned to the</span>
<span class='co'># 'training' dataset, and 40% assigned to the 'test' dataset</span>
<span class='fu'><a href='https://rdrr.io/r/utils/data.html'>data</a></span>(<span class='no'>diamonds</span>, <span class='kw'>package</span> <span class='kw'>=</span> <span class='st'>"ggplot2"</span>)
<span class='no'>diamonds_tbl</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='copy_to.html'>copy_to</a></span>(<span class='no'>sc</span>, <span class='no'>diamonds</span>, <span class='st'>"diamonds"</span>)
<span class='no'>partitions</span> <span class='kw'>&lt;-</span> <span class='no'>diamonds_tbl</span> <span class='kw'>%&gt;%</span>
  <span class='fu'>sdf_random_split</span>(<span class='kw'>training</span> <span class='kw'>=</span> <span class='fl'>0.6</span>, <span class='kw'>test</span> <span class='kw'>=</span> <span class='fl'>0.4</span>)
<span class='fu'><a href='https://rdrr.io/r/base/print.html'>print</a></span>(<span class='no'>partitions</span>)

<span class='co'># alternate way of specifying weights</span>
<span class='no'>weights</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(<span class='kw'>training</span> <span class='kw'>=</span> <span class='fl'>0.6</span>, <span class='kw'>test</span> <span class='kw'>=</span> <span class='fl'>0.4</span>)
<span class='no'>diamonds_tbl</span> <span class='kw'>%&gt;%</span> <span class='fu'>sdf_random_split</span>(<span class='kw'>weights</span> <span class='kw'>=</span> <span class='no'>weights</span>)
}</div></code></pre></div>

    </div>

    </div>




