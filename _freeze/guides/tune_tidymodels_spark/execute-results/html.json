{
  "hash": "32e655941f80d19746fa966ee4022cc8",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Tune `tidymodels` remotely in Spark Connect\"\nexecute:\n  eval: true\n  freeze: true\n---\n\n\n\n\n\n\n## Background\n\nThe ability of Spark to easily distribute tasks across multiple nodes (servers)\nmakes it a great target to run \"embarrassing parallel\" jobs, such as hyper-parameter\ntuning. For R users, the challenge is to have to learn how to run experiments \nusing the [Spark ML components](model_tuning.qmd). Ideally, we would like to use the already familiar\nmodeling R packages but have the computation happen somewhere else, faster,\nand with little to no changes to our original code. \n\n**It is important to note\nthat we are not speaking of \"big data\", but rather of something more like \n\"big processing\"**.  What takes the job a long time to complete is the fact that\nthere are numerous tuning combination that need to be discretely processed \n(fit training data, predict on evaluation data, calculate metrics), and not that\nwe have to train on gigabytes and gigabytes of data. \n\n## The solution\n\nUsing `sparklyr`, it is now possible to use the exact same R objects created\nto process the model tuning, but have the tuning itself occur in Spark. `sparklyr`\nwill upload the R objects to your Spark session automatically, and have all\nof the parallel jobs run remotely. Everything made possible by running a\nvery similar function call. Instead of running `tune_grid()`, we would run\n`tune_grid_spark()`, which has the extact same arguments as `tune_grid()`, with\na couple of additions, such as requiring a current Spark connection.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# TODO: Replace with actual installation instructions at release time\n\nremotes::install_github(\"sparklyr/sparklyr\", ref = \"grid2\")\nremotes::install_github(\"tidymodels/tune\", ref = \"grid2\")\nremotes::install_github(\"mlverse/pysparklyr\", ref = \"grid2\")\n```\n:::\n\n\n::: {#fig-cluster}\n```{mermaid}\n%%| fig-width: 6\nflowchart RL\n  subgraph sc [Spark Connect]\n   p[Parallel processes]\n  end\n  r[local R]  -- Re-samples --> sc\n  sc -.- rs[Results] -.-> r\n  r -- Model --> sc\n  r -- Pre-processor --> sc\n  style sc fill:#F0B675,stroke:#666,color:#000;\n  style p fill:#F8DDBF,stroke:#666,color:#000;\n  style r fill:#75C7F0,stroke:#666,color:#000;\n  style rs fill:#333,stroke:#333,color:#fff;\n  linkStyle default stroke:#666,color:#000\n```\n\nModel tuning in a Spark cluster\n:::\n\n## Prepare the workflow and re-samples locally\n\nThe standard framework for Machine Learning in R is \n[Tidymodels](https://www.tidymodels.org/). It is a collection of packages that\nare designed to work together to provide everything from re-sampling, to \npre-processing, to model tuning, to performance measurement. \n\nThe following code prepares all the components needed to run hyper-parameter model\ntuning in order to identify the best combination of parameters:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidymodels)\nlibrary(readmission)\n\nset.seed(1)\n\n# Data set resampling \nreadmission_splits <- initial_split(readmission, strata = readmitted)\n\nreadmission_folds <- vfold_cv(\n  data = training(readmission_splits),\n  strata = readmitted\n  )\n\n# Data pre-processing\nrecipe_basic <- recipe(readmitted ~ ., data = readmission) |>\n  step_mutate(\n    race = factor(case_when(\n      !(race %in% c(\"Caucasian\", \"African American\")) ~ \"Other\",\n      .default = race\n    ))\n  ) |>\n  step_unknown(all_nominal_predictors()) |>\n  step_YeoJohnson(all_numeric_predictors()) |>\n  step_normalize(all_numeric_predictors()) |>\n  step_dummy(all_nominal_predictors())\n\n# Model specification\nspec_bt <- boost_tree(\n  mode = \"classification\",\n  mtry = tune(), # Part of the hyper-parameters to tune\n  learn_rate = tune(), # Part of the hyper-parameters to tune\n  trees = 10\n  )\n```\n:::\n\n\nTypically, the next step would be to execute the hyper-parameter tuning by\ncalling `tune_grid()`. This is where we will diverge in order to use Spark,\ninstead of our laptop, to tune the model.\n\n## Tune in Spark Connect\n\nThe feature of tuning remotely it is only available for Spark Connect connections,\nand its vendor variants such as Databricks Connect. The variants will need to \nhave R installed and available in their Spark nodes.  \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(sparklyr)\n```\n:::\n\n\n\n### Start Spark Connect locally\n\nTo show a full example throughout this article, we have included the steps to\nstart a local Spark Connect service. Please keep in mind that it is not necessary\nto create anything local if you already have a Spark Connect service available\nsomewhere else, such as a vendor provided one. \n\n1. Install Spark locally if the version you wish to use is not available locally yet:\n\n::: {.cell}\n\n```{.r .cell-code}\nspark_install(\"4.1.0\")\n```\n:::\n\n\n2. Start the Spark Connect service locally. Make sure to match the Spark version\nyou recently installed:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npysparklyr::spark_connect_service_start(\"4.1.0\", python_version = \"3.12\")\n#> Starting Spark Connect locally ...\n#> openjdk version \"17.0.14\" 2025-01-21\n#> OpenJDK Runtime Environment Homebrew (build 17.0.14+0)\n#> OpenJDK 64-Bit Server VM Homebrew (build 17.0.14+0, mixed mode, sharing)\n#> ℹ Attempting to load 'r-sparklyr-pyspark-4.1'\n#> ✔ Python environment: 'r-sparklyr-pyspark-4.1' [351ms]\n#> \n#>   org.apache.spark.sql.connect.service.SparkConnectServer running as process\n#>   34586.  Stop it first.\n```\n:::\n\n\n### Tune the model\n\nThe first step is to connect to to the Spark Connect instance. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nsc <- spark_connect(\n  \"sc://localhost\",\n  method = \"spark_connect\",\n  version = \"4.1.0\"\n  )\n#> ℹ Attempting to load 'r-sparklyr-pyspark-4.1'\n#> ✔ Python environment: 'r-sparklyr-pyspark-4.1' [6ms]\n#> \n```\n:::\n\n\nNow, to start the model tuning, we call `tune_grid_spark()`. The minimal required\narguments are:\n\n1. Spark connection\n1. Model specification (`parsnip`)\n1. Pre-processor (`recipe`)\n1. Re-sampled data (`rsample`)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nspark_results <- tune_grid_spark(sc, spec_bt, recipe_basic, readmission_folds)\n#> i Creating pre-processing data to finalize 1 unknown parameter: \"mtry\"\n```\n:::\n\n\nAs part of adding this feature, `sparklyr` imported a lot of the functionality\ndirectly from the `tidymodels` packages in order to offer an equivalent experience,\nas well as to perform the same checks. The resulting object will look \nindistinguishable from that created directly locally by `tidymodels`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nspark_results\n#> # Tuning results\n#> # 10-fold cross-validation using stratification \n#> # A tibble: 10 × 5\n#>    splits               id     .seeds    .metrics          .notes          \n#>    <list>               <chr>  <list>    <list>            <list>          \n#>  1 <split [48272/5364]> Fold01 <int [7]> <tibble [30 × 6]> <tibble [0 × 4]>\n#>  2 <split [48272/5364]> Fold02 <int [7]> <tibble [30 × 6]> <tibble [0 × 4]>\n#>  3 <split [48272/5364]> Fold03 <int [7]> <tibble [30 × 6]> <tibble [0 × 4]>\n#>  4 <split [48272/5364]> Fold04 <int [7]> <tibble [30 × 6]> <tibble [0 × 4]>\n#>  5 <split [48272/5364]> Fold05 <int [7]> <tibble [30 × 6]> <tibble [0 × 4]>\n#>  6 <split [48272/5364]> Fold06 <int [7]> <tibble [30 × 6]> <tibble [0 × 4]>\n#>  7 <split [48273/5363]> Fold07 <int [7]> <tibble [30 × 6]> <tibble [0 × 4]>\n#>  8 <split [48273/5363]> Fold08 <int [7]> <tibble [30 × 6]> <tibble [0 × 4]>\n#>  9 <split [48273/5363]> Fold09 <int [7]> <tibble [30 × 6]> <tibble [0 × 4]>\n#> 10 <split [48273/5363]> Fold10 <int [7]> <tibble [30 × 6]> <tibble [0 × 4]>\n```\n:::\n\n\nThe object can now be used to inspect and eventually finalize the model \nselection.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nautoplot(spark_results)\n```\n\n::: {.cell-output-display}\n![](tune_tidymodels_spark_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\n\n## Compare with local results\n\nThe steps in this section would not be necessary in a 'real world' scenario. \nThis is to show how the results returned by running `tune_grid()` compare to\nthose from `tune_grid_spark()`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresults <- tune_grid(spec_bt, recipe_basic, readmission_folds)\n#> i Creating pre-processing data to finalize 1 unknown parameter: \"mtry\"\n\n# Use show_best() to compare the recommendations\n\nshow_best(results)\n#> Warning in show_best(results): No value of `metric` was given; \"roc_auc\" will\n#> be used.\n#> # A tibble: 5 × 8\n#>    mtry learn_rate .metric .estimator  mean     n std_err .config         \n#>   <int>      <dbl> <chr>   <chr>      <dbl> <int>   <dbl> <chr>           \n#> 1     4     0.0880 roc_auc binary     0.600    10 0.00425 pre0_mod02_post0\n#> 2     7     0.001  roc_auc binary     0.600    10 0.00434 pre0_mod03_post0\n#> 3    10     0.0129 roc_auc binary     0.599    10 0.00467 pre0_mod04_post0\n#> 4    13     0.167  roc_auc binary     0.596    10 0.00391 pre0_mod05_post0\n#> 5    20     0.0245 roc_auc binary     0.596    10 0.00509 pre0_mod07_post0\nshow_best(spark_results)\n#> Warning in show_best(spark_results): No value of `metric` was given; \"roc_auc\"\n#> will be used.\n#> # A tibble: 5 × 8\n#>    mtry learn_rate .metric .estimator  mean     n std_err .config         \n#>   <int>      <dbl> <chr>   <chr>      <dbl> <int>   <dbl> <chr>           \n#> 1     4    0.0880  roc_auc binary     0.600    10 0.00425 pre0_mod02_post0\n#> 2     7    0.00100 roc_auc binary     0.600    10 0.00434 pre0_mod03_post0\n#> 3    10    0.0129  roc_auc binary     0.599    10 0.00467 pre0_mod04_post0\n#> 4    13    0.167   roc_auc binary     0.596    10 0.00391 pre0_mod05_post0\n#> 5    20    0.0245  roc_auc binary     0.596    10 0.00509 pre0_mod07_post0\n```\n:::\n\n\nIn this case, both calls returned the exact same results. This is because both\nran using the same exact versions R and R packages that our Positron or RStudio\nwould access. It is important to note that if the tuning would occur in a remote\nSpark cluster, that has different Operating System, R version and/or R packages,\nthen the results would come back different. It is also important to differentiate \nbetween different results from local and not reproducible results. The results\nwill still be consistent if the job is run the exact same way, and the `seed` is\nset during the local R session that calls the remote Spark jobs.  `sparklyr`\nrecreates how `tune` sets the R seed for each Spark task, so the jobs will remain\nconsistent after each repeated run.\n\n## Retrieving predictions a.k.a `save_pred = TRUE`\n\n`sparklyr` supports getting the out-of-sample predictions if they are saved. That\nis done by using `control_grid()` when calling `tune_grid()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncntrl <- control_grid(save_pred = TRUE)\n\nresults <- tune_grid(spec_bt, recipe_basic, readmission_folds, control = cntrl)\n#> i Creating pre-processing data to finalize 1 unknown parameter: \"mtry\"\n```\n:::\n\n\nThere will be a second job that executes in Spark. This job does not really\nprocess anything. The job just reads and download the predictions into the R \nsession.\n\nOnce the tuning is completed, the predictions can be used in the R session\nas if they were all processed locally.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncollect_predictions(results)\n#> # A tibble: 536,360 × 9\n#>    .pred_class .pred_Yes .pred_No id     readmitted  .row  mtry learn_rate\n#>    <fct>           <dbl>    <dbl> <chr>  <fct>      <int> <int>      <dbl>\n#>  1 No             0.0882    0.912 Fold01 No            10     1    0.00681\n#>  2 No             0.0889    0.911 Fold01 Yes           31     1    0.00681\n#>  3 No             0.0883    0.912 Fold01 No            51     1    0.00681\n#>  4 No             0.0879    0.912 Fold01 No            52     1    0.00681\n#>  5 No             0.0889    0.911 Fold01 No            62     1    0.00681\n#>  6 No             0.0879    0.912 Fold01 No            89     1    0.00681\n#>  7 No             0.0884    0.912 Fold01 Yes          102     1    0.00681\n#>  8 No             0.0878    0.912 Fold01 No           112     1    0.00681\n#>  9 No             0.0881    0.912 Fold01 No           146     1    0.00681\n#> 10 No             0.0879    0.912 Fold01 No           150     1    0.00681\n#> # ℹ 536,350 more rows\n#> # ℹ 1 more variable: .config <chr>\n```\n:::\n\n\n## Parallel processing in Spark\n\nIn Spark, the term **job** differs from the term **task**. A single job\ncontains multiple tasks that can run in parallel. Spark will run as many \n*concurrent tasks* as there are CPU cores that the cluster makes available to\nthat particular job. In the example on @fig-job-task, a single job is running\n4 tasks in parallel thanks to each running in a separate core.\n\n::: {#fig-job-task}\n```{mermaid}\n%%| fig-width: 6\nflowchart RL\n  subgraph j [<b>Job</b>]\n   t1[<b>Task 1</b> <br/> Core 1]\n   t2[<b>Task 2</b> <br/> Core 2]\n   t3[<b>Task 3</b> <br/> Core 3]\n   t4[<b>Task 4</b> <br/> Core 4]\n  end\n  style j fill:#fff,stroke:#666,color:#000;\n  linkStyle default stroke:#666,color:#000\n```\n\nJob vs. Task in Spark example\n:::\n\nHow this relates to `tune_grid_spark()` depends on how the parallel processing\nflag is set. As with `tune_grid()`, that is driven by setting a value for\n`parallel_over` in the control grid: \n\n\n::: {.cell}\n\n```{.r .cell-code}\ncntrl <- control_grid(parallel_over = \"resamples\")\n\nresults <- tune_grid(spec_bt, recipe_basic, readmission_folds, control = cntrl)\n```\n:::\n\n\nThere are two possible values to use in `parallel_over`: \n\n1. **resamples** *(default)* - The tuning is performed in parallel over the \nresamples alone. In the example, `readmission_folds` has 10 folds/resamples.\n\n1. **everything** - The tuning will be performed in parallel for each \nindividual permutation of resamples and tuning combinations.  In the example,\nthere are 10 tune combinations, which are then combined with the 10 \nfolds/resamples, giving us 100 permutations.  \n\n\nA lot of effort was made to make sure that tuning the model remotely in Spark was\nas easy and automatic as possible. `sparklyr` copies the necessary R objects, and\nuses the same defaults `tune_grid()` and Spark itself use in order to not have\nto decide or setup more things than absolutely necessary. \n\n\n\nHowever, there are a few ways to customize the tuning in Spark. They relate how\neach hyper-parameter tuning task will be parallelized. The first way is to\ncontrol the number of discrete tasks that will be requested to Spark, and the\nsecond how the hyper-parameter tuning combinations will be grouped.\n\n\n",
    "supporting": [
      "tune_tidymodels_spark_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}