{
  "hash": "1296dc31aa4707ae30a87a4f5b4d52b9",
  "result": {
    "markdown": "---\ntitle: \"Default Compilation Specification for Spark Extensions\"\nexecute:\n  freeze: true\n---\n\n\n\n\n*R/spark_compile.R*\n\n## spark_default_compilation_spec\n\n## Description\nThis is the default compilation specification used for Spark extensions, when used with `compile_package_jars`. \n\n\n## Usage\n```r\nspark_default_compilation_spec( \n  pkg = infer_active_package_name(), \n  locations = NULL \n) \n```\n\n## Arguments\n|Arguments|Description|\n|---|---|\n| pkg | The package containing Spark extensions to be compiled. |\n| locations | Additional locations to scan. By default, the directories `/opt/scala` and `/usr/local/scala` will be scanned. |\n\n\n\n\n\n\n\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}