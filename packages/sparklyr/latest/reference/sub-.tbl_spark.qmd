---
title: "Subsetting operator for Spark dataframe"
---

*R/sdf_interface.R*

## [.tbl_spark

## Description
Susetting operator for Spark dataframe allowing a subset of column(s) to be selected using syntaxes similar to those supported by R dataframes 


## Usage
```r
## S3 method for class 'tbl_spark'
[(x, i) 
```

## Arguments
|Arguments|Description|
|---|---|
| x | The Spark dataframe |
| i | Expression specifying subset of column(s) to include or exclude from the result (e.g., `["col1"]`, `[c("col1", "col2")]`, `[1:10]`, `[-1]`, `[NULL]`, or `[]`) |





## Examples
```{r, eval=ecodown::examples_not_run()}
library(sparklyr) 
sc <- spark_connect(master = "spark://HOST:PORT") 
example_sdf <- copy_to(sc, tibble::tibble(a = 1, b = 2)) 
example_sdf["a"] %>% print() 
```


