---
title: "Compute the number of records within each partition of a Spark DataFrame"
execute:
  freeze: true
---

```{r, eval=ecodown::examples_not_run()}
#| include: false
options("pillar.width" = 60)
library(sparklyr) 
library(dplyr)
```

*R/sdf_interface.R*

## sdf_partition_sizes

## Description
 Compute the number of records within each partition of a Spark DataFrame 


## Usage
```r
 
sdf_partition_sizes(x) 
```

## Arguments
|Arguments|Description|
|---|---|
| x | A `spark_connection`, `ml_pipeline`, or a `tbl_spark`. |





## Examples
```{r, eval=ecodown::examples_not_run()}
 
library(sparklyr) 
sc <- spark_connect(master = "spark://HOST:PORT") 
example_sdf <- sdf_len(sc, 100L, repartition = 10L) 
example_sdf %>% 
  sdf_partition_sizes() %>% 
  print() 
 
 
```



```{r, eval=ecodown::examples_not_run()}
#| include: false
spark_disconnect_all()
```
