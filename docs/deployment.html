<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-0.2.443">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>sparklyr - Deployment and Configuration</title>
<style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
<!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]--><script src="site_libs/quarto-nav/quarto-nav.js"></script><script src="site_libs/quarto-nav/headroom.min.js"></script><script src="site_libs/clipboard/clipboard.min.js"></script><meta name="quarto:offset" content="./">
<script src="site_libs/quarto-search/autocomplete.umd.js"></script><script src="site_libs/quarto-search/fuse.min.js"></script><script src="site_libs/quarto-search/quarto-search.js"></script><script src="site_libs/quarto-html/quarto.js"></script><script src="site_libs/quarto-html/popper.min.js"></script><script src="site_libs/quarto-html/tippy.umd.min.js"></script><script src="site_libs/quarto-html/anchor.min.js"></script><link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link class="quarto-color-scheme" href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet">
<link class="quarto-color-scheme quarto-color-alternate" rel="prefetch" href="site_libs/quarto-html/quarto-syntax-highlighting-dark.css">
<script src="site_libs/bootstrap/bootstrap.min.js"></script><link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link class="quarto-color-scheme" href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet">
<link class="quarto-color-scheme quarto-color-alternate" rel="prefetch" href="site_libs/bootstrap/bootstrap-dark.min.css">
<script id="quarto-search-options" type="application/json">{
    "location": "navbar",
    "copy-button": false,
    "collapse-after": 2,
    "panel-placement": "end",
    "type": "overlay",
    "limit": 20,
    "language": {
      "search-no-results-text": "No results",
      "search-matching-documents-text": "matching documents",
      "search-copy-link-title": "Copy link to search",
      "search-hide-matches-text": "Hide additional matches",
      "search-more-match-text": "more match in this document",
      "search-more-matches-text": "more matches in this document",
      "search-clear-button-title": "Clear",
      "search-detached-cancel-button-title": "Cancel",
      "search-submit-button-title": "Submit"
    }
  }</script><link rel="stylesheet" href="styles.css">
</head>
<body class="floating">
<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="navbar navbar-expand-lg navbar-dark "><div class="navbar-container container-fluid">
      <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">sparklyr</span>
  </a>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
<li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-guides" role="button" data-bs-toggle="dropdown" aria-expanded="false">Guides</a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-guides">
<li>
    <a class="dropdown-item" href="./guides/connections.html">Configuring connections</a>
  </li>  
        <li>
    <a class="dropdown-item" href="./troubleshooting.html">Troubleshooting</a>
  </li>  
        <li>
    <a class="dropdown-item" href="./dplyr.html">Manipulating data</a>
  </li>  
        <li>
    <a class="dropdown-item" href="./mlib.md">Machine Learning</a>
  </li>  
        <li>
    <a class="dropdown-item" href="./guides/caching.html">Understanding Caching</a>
  </li>  
        <li>
    <a class="dropdown-item" href="./deployment.html">Deployment Options</a>
  </li>  
        <li>
    <a class="dropdown-item" href="./guides/distributed-r.html">Distributed R</a>
  </li>  
        <li>
    <a class="dropdown-item" href="./guides/data-lakes.html">Data Lakes</a>
  </li>  
        <li>
    <a class="dropdown-item" href="./guides/pipelines.html">ML Pipelines</a>
  </li>  
        <li>
    <a class="dropdown-item" href="./guides/textmining.html">Text mining</a>
  </li>  
        <li>
    <a class="dropdown-item" href="./guides/streaming.html">Stream Analysis</a>
  </li>  
        <li>
    <a class="dropdown-item" href="./guides/arrow.html">Apache Arrow</a>
  </li>  
        <li>
    <a class="dropdown-item" href="./guides/aws-s3.html">AWS S3 buckets</a>
  </li>  
        <li>
    <a class="dropdown-item" href="./guides/h2o.html">Using H2O</a>
  </li>  
    </ul>
</li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-deployment-examples" role="button" data-bs-toggle="dropdown" aria-expanded="false">Deployment Examples</a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-deployment-examples">
<li>
    <a class="dropdown-item" href="./examples/stand-alone-aws.html">Standalone cluster</a>
  </li>  
        <li>
    <a class="dropdown-item" href="./examples/yarn-cluster-emr.html">YARN cluster</a>
  </li>  
        <li>
    <a class="dropdown-item" href="./examples/cloudera-aws.html">Cloudera cluster</a>
  </li>  
        <li>
    <a class="dropdown-item" href="./examples/databricks-cluster-local.html">Databricks cluster</a>
  </li>  
        <li>
    <a class="dropdown-item" href="./examples/qubole-overview.html">Qubole cluster</a>
  </li>  
    </ul>
</li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-packages" role="button" data-bs-toggle="dropdown" aria-expanded="false">Packages</a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-packages">
<li class="dropdown-header">sparklyr</li>
        <li>
    <a class="dropdown-item" href="./sparklyr/news.html">News</a>
  </li>  
        <li>
    <a class="dropdown-item" href="./sparklyr/reference">Reference</a>
  </li>  
        <li><hr class="dropdown-divider"></li>
        <li class="dropdown-header">MLeap</li>
        <li>
    <a class="dropdown-item" href="./mleap/index.html">About</a>
  </li>  
        <li>
    <a class="dropdown-item" href="./mleap/news.html">News</a>
  </li>  
        <li>
    <a class="dropdown-item" href="./mleap/reference">Reference</a>
  </li>  
        <li><hr class="dropdown-divider"></li>
        <li class="dropdown-header">XGBoost</li>
        <li>
    <a class="dropdown-item" href="./sparkxgb/index.html">About</a>
  </li>  
        <li>
    <a class="dropdown-item" href="./sparkxgb/news.html">News</a>
  </li>  
        <li>
    <a class="dropdown-item" href="./sparkxgb/reference">Reference</a>
  </li>  
        <li><hr class="dropdown-divider"></li>
        <li class="dropdown-header">Spark TF</li>
        <li>
    <a class="dropdown-item" href="./sparktf/index.html">About</a>
  </li>  
        <li>
    <a class="dropdown-item" href="./sparktf/news.html">News</a>
  </li>  
        <li>
    <a class="dropdown-item" href="./sparktf/reference">Reference</a>
  </li>  
    </ul>
</li>
</ul>
<div class="quarto-toggle-container">
                  <a href="" class="quarto-color-scheme-toggle nav-link" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
              </div>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav><nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }"><div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title">Deployment and Configuration</h1>
      <button type="button" class="quarto-btn-toggle btn">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto"><div class="sidebar-menu-container"> 
  <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <a href="./guides/connections.html" class="">Configuring connections</a>
</li>
      <li class="sidebar-item">
  <a href="./troubleshooting.html" class="">Troubleshooting</a>
</li>
      <li class="sidebar-item">
  <a href="./dplyr.html" class="">Manipulating data</a>
</li>
      <li class="sidebar-item">
  <a href="./mlib.md" class="">Machine Learning</a>
</li>
      <li class="sidebar-item">
  <a href="./guides/caching.html" class="">Understanding Caching</a>
</li>
      <li class="sidebar-item">
  <a href="./deployment.html" class="active">Deployment Options</a>
</li>
      <li class="sidebar-item">
  <a href="./guides/distributed-r.html" class="">Distributed R</a>
</li>
      <li class="sidebar-item">
  <a href="./guides/data-lakes.html" class="">Data Lakes</a>
</li>
      <li class="sidebar-item">
  <a href="./guides/pipelines.html" class="">ML Pipelines</a>
</li>
      <li class="sidebar-item">
  <a href="./guides/textmining.html" class="">Text mining</a>
</li>
      <li class="sidebar-item">
  <a href="./guides/streaming.html" class="">Stream Analysis</a>
</li>
      <li class="sidebar-item">
  <a href="./guides/arrow.html" class="">Apache Arrow</a>
</li>
      <li class="sidebar-item">
  <a href="./guides/aws-s3.html" class="">AWS S3 buckets</a>
</li>
      <li class="sidebar-item">
  <a href="./guides/h2o.html" class="">Using H2O</a>
</li>
  </ul>
</div>
</nav><!-- margin-sidebar --><div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
      <nav id="TOC" role="doc-toc"><h2 id="toc-title">On this page</h2>
<ul>
<li>
<a href="#deployment" class="nav-link active" data-scroll-target="#deployment">Deployment</a>
<ul class="collapse">
<li><a href="#local-deployment" class="nav-link" data-scroll-target="#local-deployment">Local Deployment</a></li>
<li><a href="#cluster-deployment" class="nav-link" data-scroll-target="#cluster-deployment">Cluster Deployment</a></li>
<li><a href="#livy-connections" class="nav-link" data-scroll-target="#livy-connections">Livy Connections</a></li>
<li><a href="#connection-tools" class="nav-link" data-scroll-target="#connection-tools">Connection Tools</a></li>
<li><a href="#collect" class="nav-link" data-scroll-target="#collect">Collect</a></li>
</ul>
</li>
<li>
<a href="#configuration" class="nav-link" data-scroll-target="#configuration">Configuration</a>
<ul class="collapse">
<li><a href="#config-files" class="nav-link" data-scroll-target="#config-files">Config Files</a></li>
<li><a href="#package-options" class="nav-link" data-scroll-target="#package-options">Package Options</a></li>
<li><a href="#spark-options" class="nav-link" data-scroll-target="#spark-options">Spark Options</a></li>
<li><a href="#user-options" class="nav-link" data-scroll-target="#user-options">User Options</a></li>
<li><a href="#multiple-profiles" class="nav-link" data-scroll-target="#multiple-profiles">Multiple Profiles</a></li>
<li><a href="#tuning" class="nav-link" data-scroll-target="#tuning">Tuning</a></li>
</ul>
</li>
<li>
<a href="#rstudio-server" class="nav-link" data-scroll-target="#rstudio-server">RStudio Server</a>
<ul class="collapse">
<li><a href="#connection-options" class="nav-link" data-scroll-target="#connection-options">Connection Options</a></li>
<li><a href="#spark-installations" class="nav-link" data-scroll-target="#spark-installations">Spark Installations</a></li>
</ul>
</li>
</ul></nav>
</div>
<!-- main -->
<main class="content"><header id="title-block-header"><h1 class="title d-none d-lg-block display-7">Deployment and Configuration</h1>
</header><section id="deployment" class="level2"><h2 class="anchored" data-anchor-id="deployment">Deployment</h2>
<p>There are two well supported deployment modes for <strong>sparklyr</strong>:</p>
<ul>
<li>Local — Working on a local desktop typically with smaller/sampled datasets</li>
<li>Cluster — Working directly within or alongside a Spark cluster (<a href="http://spark.apache.org/docs/latest/spark-standalone.html">standalone</a>, <a href="http://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/index.html">YARN</a>, <a href="http://mesos.apache.org/">Mesos</a>, etc.)</li>
</ul>
<section id="local-deployment" class="level3"><h3 class="anchored" data-anchor-id="local-deployment">Local Deployment</h3>
<p>Local mode is an excellent way to learn and experiment with Spark. Local mode also provides a convenient development environment for analyses, reports, and applications that you plan to eventually deploy to a multi-node Spark cluster.</p>
<p>To work in local mode you should first install a version of Spark for local use. You can do this using the <a href="./reference/spark_install">spark_install</a> function, for example:</p>
<div class="cell">
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">sparklyr</span><span class="fu">::</span><span class="fu"><a href="https://edgararuiz.github.io/spark.rstudio.com/sparklyr/reference/spark_install.html">spark_install</a></span><span class="op">(</span>version <span class="op">=</span> <span class="st">"2.1.0"</span><span class="op">)</span></code></pre></div>
</div>
<p>To connect to the local Spark instance you pass “local” as the value of the Spark master node to <a href="./reference/spark-connections/">spark_connect</a>:</p>
<div class="cell">
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://spark.rstudio.com/">sparklyr</a></span><span class="op">)</span>
<span class="va">sc</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://edgararuiz.github.io/spark.rstudio.com/sparklyr/reference/spark-connections.html">spark_connect</a></span><span class="op">(</span>master <span class="op">=</span> <span class="st">"local"</span><span class="op">)</span></code></pre></div>
</div>
<p>For the local development scenario, see the <a href="#configuration">Configuration</a> section below for details on how to have the same code work seamlessly in both development and production environments.</p>
</section><section id="cluster-deployment" class="level3"><h3 class="anchored" data-anchor-id="cluster-deployment">Cluster Deployment</h3>
<p>A common deployment strategy is to submit your application from a gateway machine that is physically co-located with your worker machines (e.g. Master node in a standalone EC2 cluster). In this setup, client mode is appropriate. In client mode, the driver is launched directly within the spark-submit process which acts as a client to the cluster. The input and output of the application is attached to the console. Thus, this mode is especially suitable for applications that involve the REPL (e.g. Spark shell). For more information see <a href="http://spark.apache.org/docs/latest/submitting-applications.html">Submitting Applications</a>.</p>
<p>To use spaklyr with a Spark cluster you should locate your R session on a machine that is either directly on one of the cluster nodes or is close to the cluster (for networking performance). In the case where R is not running directly on the cluster you should also ensure that the machine has a Spark version and configuration <strong>identical</strong> to that of the cluster nodes.</p>
<p>The most straightforward way to run R within or near to the cluster is either a remote SSH session or via <a href="https://www.rstudio.com/products/rstudio/">RStudio Server</a>.</p>
<p>In cluster mode you use the version of Spark already deployed on the cluster node. This version is located via the <code>SPARK_HOME</code> environment variable, so you should be sure that this variable is correctly defined on your server before attempting a connection. This would typically be done within the <a href="https://stat.ethz.ch/R-manual/R-devel/library/base/html/Startup.html">Renviron.site</a> configuration file. For example:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode sh code-with-copy"><code class="sourceCode bash"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="va">SPARK_HOME</span><span class="op">=</span>/opt/spark/spark-2.0.0-bin-hadoop2.6</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>To connect, pass the address of the master node to <a href="./reference/spark-connections/">spark_connect</a>, for example:</p>
<div class="cell">
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://spark.rstudio.com/">sparklyr</a></span><span class="op">)</span>
<span class="va">sc</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://edgararuiz.github.io/spark.rstudio.com/sparklyr/reference/spark-connections.html">spark_connect</a></span><span class="op">(</span>master <span class="op">=</span> <span class="st">"spark://local:7077"</span><span class="op">)</span></code></pre></div>
</div>
<p>For a <a href="http://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/index.html">Hadoop YARN</a> cluster, you can connect using the YARN master, for example:</p>
<div class="cell">
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://spark.rstudio.com/">sparklyr</a></span><span class="op">)</span>
<span class="va">sc</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://edgararuiz.github.io/spark.rstudio.com/sparklyr/reference/spark-connections.html">spark_connect</a></span><span class="op">(</span>master <span class="op">=</span> <span class="st">"yarn-client"</span><span class="op">)</span></code></pre></div>
</div>
<p>If you are running on EC2 using the Spark <a href="http://spark.apache.org/docs/latest/ec2-scripts.html">EC2 deployment scripts</a> then you can read the master from <code>/root/spark-ec2/cluster-url</code>, for example:</p>
<div class="cell">
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://spark.rstudio.com/">sparklyr</a></span><span class="op">)</span>
<span class="va">cluster_url</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/system.html">system</a></span><span class="op">(</span><span class="st">'cat /root/spark-ec2/cluster-url'</span>, intern<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span>
<span class="va">sc</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://edgararuiz.github.io/spark.rstudio.com/sparklyr/reference/spark-connections.html">spark_connect</a></span><span class="op">(</span>master <span class="op">=</span> <span class="va">cluster_url</span><span class="op">)</span></code></pre></div>
</div>
</section><section id="livy-connections" class="level3"><h3 class="anchored" data-anchor-id="livy-connections">Livy Connections</h3>
<p><a href="http://livy.io/">Livy</a>, <em>“An Open Source REST Service for Apache Spark (Apache License)”</em> , is available starting in <code>sparklyr 0.5</code> as an <strong>experimental</strong> feature. Among many scenarios, this enables connections from the RStudio desktop to Apache Spark when Livy is available and correctly configured in the remote cluster.</p>
<p>To work with Livy locally, <code>sparklyr</code> supports <code><a href="https://edgararuiz.github.io/spark.rstudio.com/sparklyr/reference/livy_install.html">livy_install()</a></code> which installs Livy in your local environment, this is similar to <code><a href="https://edgararuiz.github.io/spark.rstudio.com/sparklyr/reference/spark_install.html">spark_install()</a></code>. Since Livy is a service to enable remote connections into Apache Spark, the service needs to be started with <code><a href="https://edgararuiz.github.io/spark.rstudio.com/sparklyr/reference/livy_service.html">livy_service_start()</a></code>. Once the service is running, <code><a href="https://edgararuiz.github.io/spark.rstudio.com/sparklyr/reference/spark-connections.html">spark_connect()</a></code> needs to reference the running service and use <code>method = "Livy"</code>, then <code>sparklyr</code> can be used as usual. A short example follows:</p>
<div class="cell">
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://edgararuiz.github.io/spark.rstudio.com/sparklyr/reference/livy_install.html">livy_install</a></span><span class="op">(</span><span class="op">)</span>
<span class="fu"><a href="https://edgararuiz.github.io/spark.rstudio.com/sparklyr/reference/livy_service.html">livy_service_start</a></span><span class="op">(</span><span class="op">)</span>

<span class="va">sc</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://edgararuiz.github.io/spark.rstudio.com/sparklyr/reference/spark-connections.html">spark_connect</a></span><span class="op">(</span>master <span class="op">=</span> <span class="st">"http://localhost:8998"</span>, method <span class="op">=</span> <span class="st">"livy"</span><span class="op">)</span>
<span class="fu"><a href="https://edgararuiz.github.io/spark.rstudio.com/sparklyr/reference/copy_to.html">copy_to</a></span><span class="op">(</span><span class="va">sc</span>, <span class="va">iris</span><span class="op">)</span>

<span class="fu"><a href="https://edgararuiz.github.io/spark.rstudio.com/sparklyr/reference/spark-connections.html">spark_disconnect</a></span><span class="op">(</span><span class="va">sc</span><span class="op">)</span>
<span class="fu"><a href="https://edgararuiz.github.io/spark.rstudio.com/sparklyr/reference/livy_service.html">livy_service_stop</a></span><span class="op">(</span><span class="op">)</span></code></pre></div>
</div>
</section><section id="connection-tools" class="level3"><h3 class="anchored" data-anchor-id="connection-tools">Connection Tools</h3>
<p>You can view the Spark web UI via the <a href="./reference/spark_web">spark_web</a> function, and view the Spark log via the <a href="./reference/spark_log">spark_log</a> function:</p>
<div class="cell">
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://edgararuiz.github.io/spark.rstudio.com/sparklyr/reference/spark_web.html">spark_web</a></span><span class="op">(</span><span class="va">sc</span><span class="op">)</span>
<span class="fu"><a href="https://edgararuiz.github.io/spark.rstudio.com/sparklyr/reference/spark_log.html">spark_log</a></span><span class="op">(</span><span class="va">sc</span><span class="op">)</span></code></pre></div>
</div>
<p>You can disconnect from Spark using the <a href="./reference/spark-connections/">spark_disconnect</a> function:</p>
<div class="cell">
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://edgararuiz.github.io/spark.rstudio.com/sparklyr/reference/spark-connections.html">spark_disconnect</a></span><span class="op">(</span><span class="va">sc</span><span class="op">)</span></code></pre></div>
</div>
</section><section id="collect" class="level3"><h3 class="anchored" data-anchor-id="collect">Collect</h3>
<p>The <code>collect</code> function transfers data from Spark into R. The data are collected from a cluster environment and transfered into local R memory. In the process, all data is first transfered from executor nodes to the driver node. Therefore, the driver node must have enough memory to collect all the data.</p>
<p>Collecting data on the driver node is relatively slow. The process also inflates the data as it moves from the executor nodes to the driver node. Caution should be used when collecting large data.</p>
<p>The following parameters could be adjusted to avoid OutOfMemory and Timeout errors:</p>
<ul>
<li>spark.executor.heartbeatInterval</li>
<li>spark.network.timeout</li>
<li>spark.driver.extraJavaOptions</li>
<li>spark.driver.memory</li>
<li>spark.yarn.driver.memoryOverhead</li>
<li>spark.driver.maxResultSize</li>
</ul></section></section><section id="configuration" class="level2"><h2 class="anchored" data-anchor-id="configuration">Configuration</h2>
<p>This section describes the various options available for configuring both the behavior of the <strong>sparklyr</strong> package as well as the underlying Spark cluster. Creating multiple configuration profiles (e.g. development, test, production) is also covered.</p>
<section id="config-files" class="level3"><h3 class="anchored" data-anchor-id="config-files">Config Files</h3>
<p>The configuration for a Spark connection is specified via the <code>config</code> parameter of the <a href="./reference/spark-connections/">spark_connect</a> function. By default the configuration is established by calling the <a href="./reference/spark_config/">spark_config</a> function. This code represents the default behavior:</p>
<div class="cell">
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://edgararuiz.github.io/spark.rstudio.com/sparklyr/reference/spark-connections.html">spark_connect</a></span><span class="op">(</span>master <span class="op">=</span> <span class="st">"local"</span>, config <span class="op">=</span> <span class="fu"><a href="https://edgararuiz.github.io/spark.rstudio.com/sparklyr/reference/spark_config.html">spark_config</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span></code></pre></div>
</div>
<p>By default the <a href="reference/sparklyr/latest/spark_config.html">spark_config</a> function reads configuration data from a file named <code>config.yml</code> located in the current working directory (or in parent directories if not located in the working directory). This file is not required and only need be provided for overriding default behavior. You can also specify an alternate config file name and/or location.</p>
<p>The <code>config.yml</code> file is in turn processed using the <a href="https://github.com/rstudio/config">config</a> package, which enables support for multiple named configuration profiles.</p>
</section><section id="package-options" class="level3"><h3 class="anchored" data-anchor-id="package-options">Package Options</h3>
<p>There are a number of options available to configure the behavior of the sparklyr package:</p>
<p>For example, this configuration file sets the number of local cores to 4 and the amount of memory allocated for the Spark driver to 4G:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode yaml code-with-copy"><code class="sourceCode yaml"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">default</span><span class="kw">:</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">sparklyr.cores.local</span><span class="kw">:</span><span class="at"> </span><span class="dv">4</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">sparklyr.shell.driver-memory</span><span class="kw">:</span><span class="at"> 4G</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Note that the use of <code>default</code> will be explained below in <a href="#multiple-profiles">Multiple Profiles</a>.</p>
<section id="spark" class="level4"><h4 class="anchored" data-anchor-id="spark">Spark</h4>
<table class="table">
<colgroup>
<col style="width: 38%">
<col style="width: 61%">
</colgroup>
<thead><tr class="header">
<th>Option</th>
<th>Description</th>
</tr></thead>
<tbody><tr class="odd">
<td><code>sparklyr.shell.*</code></td>
<td>Command line parameters to pass to <code>spark-submit</code>. For example, <code>sparklyr.shell.executor-memory: 20G</code> configures <code>--executor-memory 20G</code> (see the <a href="https://spark.apache.org/docs/latest/submitting-applications.html">Spark documentation</a> for details on supported options).</td>
</tr></tbody>
</table></section><section id="runtime" class="level4"><h4 class="anchored" data-anchor-id="runtime">Runtime</h4>
<table class="table">
<colgroup>
<col style="width: 38%">
<col style="width: 61%">
</colgroup>
<thead><tr class="header">
<th>Option</th>
<th>Description</th>
</tr></thead>
<tbody>
<tr class="odd">
<td><code>sparklyr.cores.local</code></td>
<td>Number of cores to use when running in local mode (defaults to <code><a href="https://rdrr.io/r/parallel/detectCores.html">parallel::detectCores</a></code>).</td>
</tr>
<tr class="even">
<td><code>sparklyr.sparkui.url</code></td>
<td>Configures the url to the Spark UI web interface when calling spark_web.</td>
</tr>
<tr class="odd">
<td><code>sparklyr.defaultPackages</code></td>
<td>List of default Spark packages to install in the cluster (defaults to “com.databricks:spark-csv_2.11:1.3.0” and “com.amazonaws:aws-java-sdk-pom:1.10.34”).</td>
</tr>
<tr class="even">
<td><code>sparklyr.sanitize.column.names</code></td>
<td>Allows Spark to automatically rename column names to conform to Spark naming restrictions.</td>
</tr>
</tbody>
</table></section><section id="diagnostics" class="level4"><h4 class="anchored" data-anchor-id="diagnostics">Diagnostics</h4>
<table class="table">
<colgroup>
<col style="width: 38%">
<col style="width: 61%">
</colgroup>
<thead><tr class="header">
<th>Option</th>
<th>Description</th>
</tr></thead>
<tbody>
<tr class="odd">
<td><code>sparklyr.backend.threads</code></td>
<td>Number of threads to use in the sparklyr backend to process incoming connections form the sparklyr client.</td>
</tr>
<tr class="even">
<td><code>sparklyr.app.jar</code></td>
<td>The application jar to be submitted in Spark submit.</td>
</tr>
<tr class="odd">
<td><code>sparklyr.ports.file</code></td>
<td>Path to the ports file used to share connection information to the sparklyr backend.</td>
</tr>
<tr class="even">
<td><code>sparklyr.ports.wait.seconds</code></td>
<td>Number of seconds to wait while for the Spark connection to initialize.</td>
</tr>
<tr class="odd">
<td><code>sparklyr.verbose</code></td>
<td>Provide additional feedback while performing operations. Currently used to communicate which column names are being sanitized in sparklyr.sanitize.column.names.</td>
</tr>
</tbody>
</table></section></section><section id="spark-options" class="level3"><h3 class="anchored" data-anchor-id="spark-options">Spark Options</h3>
<p>You can also use <code>config.yml</code> to specify arbitrary Spark configuration properties:</p>
<table class="table">
<colgroup>
<col style="width: 20%">
<col style="width: 79%">
</colgroup>
<thead><tr class="header">
<th>Option</th>
<th>Description</th>
</tr></thead>
<tbody>
<tr class="odd">
<td><code>spark.*</code></td>
<td>Configuration settings for the Spark context (applied by creating a <code>SparkConf</code> containing the specified properties). For example, <code>spark.executor.memory: 1g</code> configures the memory available in each executor (see <a href="http://spark.apache.org/docs/latest/configuration.html#application-properties">Spark Configuration</a> for additional options.)</td>
</tr>
<tr class="even">
<td><code>spark.sql.*</code></td>
<td>Configuration settings for the Spark SQL context (applied using SET). For instance, <code>spark.sql.shuffle.partitions</code> configures number of partitions to use while shuffling (see <a href="http://spark.apache.org/docs/latest/sql-programming-guide.html#other-configuration-options">SQL Programming Guide</a> for additional options).</td>
</tr>
</tbody>
</table>
<p>For example, this configuration file sets a custom scratch directory for Spark and specifies 100 as the number of partitions to use when shuffling data for joins or aggregations:</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode yaml code-with-copy"><code class="sourceCode yaml"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="fu">default</span><span class="kw">:</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">spark.local.dir</span><span class="kw">:</span><span class="at"> /tmp/spark-scratch</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">spark.sql.shuffle.partitions</span><span class="kw">:</span><span class="at"> </span><span class="dv">100</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section><section id="user-options" class="level3"><h3 class="anchored" data-anchor-id="user-options">User Options</h3>
<p>You can also include arbitrary custom user options within the <code>config.yml</code> file. These can be named anything you like so long as they <em>do not</em> use either <code>spark</code> or <code>sparklyr</code> as a prefix. For example, this configuration file defines <code>dataset</code> and <code>sample-size</code> options:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode yaml code-with-copy"><code class="sourceCode yaml"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="fu">default</span><span class="kw">:</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">dataset</span><span class="kw">:</span><span class="at"> </span><span class="st">"observations.parquet"</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">sample-size</span><span class="kw">:</span><span class="at"> </span><span class="dv">10000</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section><section id="multiple-profiles" class="level3"><h3 class="anchored" data-anchor-id="multiple-profiles">Multiple Profiles</h3>
<p>The <a href="https://github.com/rstudio/config">config</a> package enables the definition of multiple named configuration profiles for different environments (e.g. default, test, production). All environments automatically inherit from the <code>default</code> environment and can optionally also inherit from each other.</p>
<p>For example, you might want to use a distinct datasets for development and testing or might want to use custom Spark configuration properties that are only applied when running on a production cluster. Here’s how that would be expressed in <code>config.yml</code>:</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode yaml code-with-copy"><code class="sourceCode yaml"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="fu">default</span><span class="kw">:</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">dataset</span><span class="kw">:</span><span class="at"> </span><span class="st">"observations-dev.parquet"</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">sample-size</span><span class="kw">:</span><span class="at"> </span><span class="dv">10000</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="fu">production</span><span class="kw">:</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">spark.memory.fraction</span><span class="kw">:</span><span class="at"> </span><span class="fl">0.9</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">spark.rdd.compress</span><span class="kw">:</span><span class="at"> </span><span class="ch">true</span></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">dataset</span><span class="kw">:</span><span class="at"> </span><span class="st">"observations.parquet"</span></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">sample-size</span><span class="kw">:</span><span class="at"> </span><span class="ch">null</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>You can also use this feature to specify distinct Spark master nodes for different environments, for example:</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode yaml code-with-copy"><code class="sourceCode yaml"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="fu">default</span><span class="kw">:</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">spark.master</span><span class="kw">:</span><span class="at"> </span><span class="st">"local"</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="fu">production</span><span class="kw">:</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">spark.master</span><span class="kw">:</span><span class="at"> </span><span class="st">"spark://local:7077"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>With this configuration, you can omit the <code>master</code> argument entirely from the call to <a href="./reference/spark-connections/">spark_connect</a>:</p>
<div class="cell">
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">sc</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://edgararuiz.github.io/spark.rstudio.com/sparklyr/reference/spark-connections.html">spark_connect</a></span><span class="op">(</span><span class="op">)</span></code></pre></div>
</div>
<p>Note that the currently active configuration is determined via the value of <code>R_CONFIG_ACTIVE</code> environment variable. See the <a href="https://github.com/rstudio/config">config package documentation</a> for additional details.</p>
</section><section id="tuning" class="level3"><h3 class="anchored" data-anchor-id="tuning">Tuning</h3>
<p>In general, you will need to tune a Spark cluster for it to perform well. Spark applications tend to consume a lot of resources. There are many knobs to control the performance of Yarn and executor (i.e. worker) nodes in a cluster. Some of the parameters to pay attention to are as follows:</p>
<ul>
<li>spark.executor.heartbeatInterval</li>
<li>spark.network.timeout</li>
<li>spark.executor.extraJavaOptions</li>
<li>spark.executor.memory</li>
<li>spark.yarn.executor.memoryOverhead</li>
<li>spark.executor.cores</li>
<li>spark.executor.instances (if is not enabled)</li>
</ul>
<section id="example-config" class="level4"><h4 class="anchored" data-anchor-id="example-config">Example Config</h4>
<p>Here is an example spark configuration for an EMR cluster on AWS with 1 master and 2 worker nodes. Eache node has 8 vCPU and 61 GiB of memory.</p>
<table class="table">
<thead><tr class="header">
<th>Parameter</th>
<th>Value</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>spark.driver.extraJavaOptions</td>
<td>
<em>append</em> -XX:MaxPermSize=30G</td>
</tr>
<tr class="even">
<td>spark.driver.maxResultSize</td>
<td>0</td>
</tr>
<tr class="odd">
<td>spark.driver.memory</td>
<td>30G</td>
</tr>
<tr class="even">
<td>spark.yarn.driver.memoryOverhead</td>
<td>4096</td>
</tr>
<tr class="odd">
<td>spark.yarn.executor.memoryOverhead</td>
<td>4096</td>
</tr>
<tr class="even">
<td>spark.executor.memory</td>
<td>4G</td>
</tr>
<tr class="odd">
<td>spark.executor.cores</td>
<td>2</td>
</tr>
<tr class="even">
<td>spark.dynamicAllocation.maxExecutors</td>
<td>15</td>
</tr>
</tbody>
</table>
<p>Configuration parameters can be set in the config R object or can be set in the <code>config.yml</code>. Alternatively, they can be set in the <code>spark-defaults.conf</code>.</p>
<section id="configuration-in-r-script" class="level5"><h5 class="anchored" data-anchor-id="configuration-in-r-script">Configuration in R script</h5>
<div class="cell">
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">config</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://edgararuiz.github.io/spark.rstudio.com/sparklyr/reference/spark_config.html">spark_config</a></span><span class="op">(</span><span class="op">)</span>
<span class="va">config</span><span class="op">$</span><span class="va">spark.executor.cores</span> <span class="op">&lt;-</span> <span class="fl">2</span>
<span class="va">config</span><span class="op">$</span><span class="va">spark.executor.memory</span> <span class="op">&lt;-</span> <span class="st">"4G"</span>
<span class="va">sc</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://edgararuiz.github.io/spark.rstudio.com/sparklyr/reference/spark-connections.html">spark_connect</a></span><span class="op">(</span>master <span class="op">=</span> <span class="st">"yarn-client"</span>, config <span class="op">=</span> <span class="va">config</span>, version <span class="op">=</span> <span class="st">'2.0.0'</span><span class="op">)</span></code></pre></div>
</div>
</section><section id="configuration-in-yaml-script" class="level5"><h5 class="anchored" data-anchor-id="configuration-in-yaml-script">Configuration in YAML script</h5>
<div class="sourceCode" id="cb18"><pre class="sourceCode yaml code-with-copy"><code class="sourceCode yaml"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="fu">default</span><span class="kw">:</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">spark.executor.cores</span><span class="kw">:</span><span class="at"> </span><span class="dv">2</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">spark.executor.memory</span><span class="kw">:</span><span class="at"> 4G</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section></section></section></section><section id="rstudio-server" class="level2"><h2 class="anchored" data-anchor-id="rstudio-server">RStudio Server</h2>
<p>RStudio Server provides a web-based IDE interface to a remote R session, making it ideal for use as a front-end to a Spark cluster. This section covers some additional configuration options that are useful for RStudio Server.</p>
<section id="connection-options" class="level3"><h3 class="anchored" data-anchor-id="connection-options">Connection Options</h3>
<p>The RStudio IDE Spark pane provides a <strong>New Connection</strong> dialog to assist in connecting with both local instances of Spark and Spark clusters:</p>
<p><img src="./images/deployment/overview/connect-to-spark.png" width="486"></p>
<p>You can configure which connection choices are presented using the <code>rstudio.spark.connections</code> option. By default, users are presented with possibility of both local and cluster connections, however, you can modify this behavior to present only one of these, or even a specific Spark master URL. Some commonly used combinations of connection choices include:</p>
<table class="table">
<colgroup>
<col style="width: 38%">
<col style="width: 61%">
</colgroup>
<thead><tr class="header">
<th>Value</th>
<th>Description</th>
</tr></thead>
<tbody>
<tr class="odd">
<td><code>c("local", "cluster")</code></td>
<td>Default. Present connections to both local and cluster Spark instances.</td>
</tr>
<tr class="even">
<td><code>"local"</code></td>
<td>Present only connections to local Spark instances.</td>
</tr>
<tr class="odd">
<td><code>"spark://local:7077"</code></td>
<td>Present only a connection to a specific Spark cluster.</td>
</tr>
<tr class="even">
<td><code>c("spark://local:7077", "cluster")</code></td>
<td>Present a connection to a specific Spark cluster and other clusters.</td>
</tr>
</tbody>
</table>
<p>This option should generally be set within <a href="https://stat.ethz.ch/R-manual/R-devel/library/base/html/Startup.html">Rprofile.site</a>. For example:</p>
<div class="cell">
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/options.html">options</a></span><span class="op">(</span>rstudio.spark.connections <span class="op">=</span> <span class="st">"spark://local:7077"</span><span class="op">)</span></code></pre></div>
</div>
</section><section id="spark-installations" class="level3"><h3 class="anchored" data-anchor-id="spark-installations">Spark Installations</h3>
<p>If you are running within local mode (as opposed to cluster mode) you may want to provide pre-installed Spark version(s) to be shared by all users of the server. You can do this by installing Spark versions within a shared directory (e.g. <code>/opt/spark</code>) then designating it as the Spark installation directory.</p>
<p>For example, after installing one or more versions of Spark to <code>/opt/spark</code> you would add the following to <a href="https://stat.ethz.ch/R-manual/R-devel/library/base/html/Startup.html">Rprofile.site</a>:</p>
<div class="cell">
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/options.html">options</a></span><span class="op">(</span>spark.install.dir <span class="op">=</span> <span class="st">"/opt/spark"</span><span class="op">)</span></code></pre></div>
</div>
<p>If this directory is read-only for ordinary users then RStudio will not offer installation of additional versions, which will help guide users to a version that is known to be compatible with versions of Spark deployed on clusters in the same organization.</p>


</section></section></main><!-- /main --><script type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
    } else {
      disableStylesheet(alternateStylesheets);
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      return window.localStorage.getItem("quarto-color-scheme");
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = null;
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.id = "quarto-color-scheme-toggle";
    a.classList.add('top-right');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } 
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    setTimeout(function() {
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      let href = ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
  </div>
  <div class="nav-page nav-page-next">
  </div>
</nav>
</div> <!-- /content -->


</body>
</html>
