{
  "hash": "83f41fcd1fbe87c2fa69536811492f37",
  "result": {
    "markdown": "---\ntitle: Run R inside Databricks Connect\nformat:\n  html:\n    theme: default\n    toc: true\nexecute:\n    eval: true\n    freeze: true\neditor: \n  markdown: \n    wrap: 72\n---\n\n\n\n\n*Last updated: Sun Feb  4 15:01:56 2024*\n\n## Background\n\nSupport for `spark_apply()` is currently available in the development\nversions of `sparklyr`, and `pysparklyr`. To install, run the following:\n\n``` r\nremotes::install_github(\"sparklyr/sparklyr\")\nremotes::install_github(\"mlverse/pysparklyr\")\n```\n\nDatabricks Connect is now able to run regular Python code inside Spark.\n`sparklyr` takes advantage of this capability by having Python transport\nand run the R code. It does this via the `rpy2` Python library. Using\nthis library guarantees Arrow suport.\n\n::: {#fig-connect}\n\n```{mermaid}\n%%| fig-width: 10\n%%| eval: true\nflowchart LR\n  subgraph lp[test]\n    subgraph r[R]\n      sr[sparklyr]\n      rt[reticulate]\n    end\n    subgraph ps[Python]\n      dc[Databricks Connect]\n      g1[gRPC]\n    end\n  end   \n  subgraph db[Databricks]\n    sp[Spark]   \n  end\n  sr <--> rt\n  rt <--> dc\n  g1 <-- Internet<br>Connection --> sp\n  dc <--> g1\n  \n  style r   fill:#fff,stroke:#666,color:#000\n  style sr  fill:#fff,stroke:#666,color:#000\n  style rt  fill:#fff,stroke:#666,color:#000\n  style ps  fill:#fff,stroke:#666,color:#000\n  style lp  fill:#fff,stroke:#666,color:#fff\n  style db  fill:#fff,stroke:#666,color:#000\n  style sp  fill:#fff,stroke:#666,color:#000\n  style g1  fill:#fff,stroke:#666,color:#000\n  style dc  fill:#fff,stroke:#666,color:#000\n```\n\n\nHow `sparklyr` communicates with Databricks Connect\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}