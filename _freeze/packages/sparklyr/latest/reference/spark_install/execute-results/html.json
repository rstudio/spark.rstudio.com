{
  "hash": "a56a115b100da67ecd265a775b75b53e",
  "result": {
    "markdown": "---\ntitle: \"Download and install various versions of Spark\"\nexecute:\n  freeze: true\n---\n\n\n\n\n*R/install_spark.R, R/install_spark_versions.R*\n\n## spark_install\n\n## Description\nInstall versions of Spark for use with local Spark connections   (i.e. `spark_connect(master = \"local\"`) \n\n\n## Usage\n```r\nspark_install( \n  version = NULL, \n  hadoop_version = NULL, \n  reset = TRUE, \n  logging = \"INFO\", \n  verbose = interactive() \n) \n\nspark_uninstall(version, hadoop_version) \n\nspark_install_dir() \n\nspark_install_tar(tarfile) \n\nspark_installed_versions() \n\nspark_available_versions( \n  show_hadoop = FALSE, \n  show_minor = FALSE, \n  show_future = FALSE \n) \n```\n\n## Arguments\n|Arguments|Description|\n|---|---|\n| version | Version of Spark to install. See `spark_available_versions` for a list of supported versions |\n| hadoop_version | Version of Hadoop to install. See `spark_available_versions` for a list of supported versions |\n| reset | Attempts to reset settings to defaults. |\n| logging | Logging level to configure install. Supported options: \"WARN\", \"INFO\" |\n| verbose | Report information as Spark is downloaded / installed |\n| tarfile | Path to TAR file conforming to the pattern spark-###-bin-(hadoop)?### where ### reference spark and hadoop versions respectively. |\n| show_hadoop | Show Hadoop distributions? |\n| show_minor | Show minor Spark versions? |\n| show_future | Should future versions which have not been released be shown? |\n\n\n\n## Value\nList with information about the installed version. \n\n\n\n\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}