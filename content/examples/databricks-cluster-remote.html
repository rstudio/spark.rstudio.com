---
title: "Option 1 - Connecting to Databricks remotely"
output:
  html_document:
    toc: true
    toc_depth: 2
    toc_float:
      collapsed: false
params:
  width: 600
---



<div id="overview" class="section level2">
<h2>Overview</h2>
<p>With this configuration, RStudio Server Pro is installed outside of the Spark
cluster and allows users to connect to Spark remotely using
<a href="https://docs.databricks.com/dev-tools/databricks-connect.html">Databricks Connect</a>.</p>
<p><img src="/images/deployment/databricks/rstudio-databricks-remote.png" width='800px' align='center'/></p>
<p>This is the recommended configuration because it targets separate environments,
involves simpler configuration, avoids resource contention, and allows RStudio
Server Pro to connect to Databricks as well as other remote storage and compute
resources.</p>
</div>
<div id="advantages-and-limitations" class="section level2">
<h2>Advantages and limitations</h2>
<p>Advantages:</p>
<ul>
<li>RStudio Server Pro will remain functional if Databricks clusters are
terminated</li>
<li>Provides the ability to comminicate with one or more Databricks clusters as a
remote compute resource</li>
<li>Avoids resource contention between RStudio Server Pro and Databricks</li>
</ul>
<p>Limitations:</p>
<ul>
<li>Databricks Connect does not support structured streaming</li>
<li>Databricks Connect does not support running arbitrary code that is not a part
of a Spark job on the remote cluster</li>
<li>Databricks Connect does not support Scala, Python, and R APIs for Delta table
operations.</li>
<li>Databricks Connect does not support most utilities in Databricks Utilities.
However, <code>dbutils.fs</code> and <code>dbutils.secrets</code> are supported.</li>
</ul>
</div>
<div id="requirements" class="section level2">
<h2>Requirements</h2>
<ul>
<li>RStudio Server Pro</li>
<li>Java 8 installed on the server with RStudio Server Pro</li>
<li>Active Databricks cluster with a runtime version 5.5 and above</li>
</ul>
</div>
<div id="install-python" class="section level2">
<h2>Install Python</h2>
<p>The Databricks Connect client is provided as a Python library.</p>
<p>Follow the steps to install Python on the server with RStudio Server Pro:</p>
<p><a href="https://docs.rstudio.com/resources/install-python/" class="uri">https://docs.rstudio.com/resources/install-python/</a></p>
<p>Note that you can either install Python for all users in a global location or
for an individual user in your home directory.</p>
</div>
<div id="install-databricks-connect" class="section level2">
<h2>Install Databricks Connect</h2>
<p>Run the following command to install Databricks Connect on the server with
RStudio Server Pro:</p>
<pre><code>pip install -U databricks-connect==6.3.*  # or a different version to match your Databricks cluster</code></pre>
<p>Note that you can either install this library for all users in a global Python
environment or for an individual user in their Python environment (e.g., using
the <code>pip --user</code> option or installing into a conda environment or virtual
environment).</p>
</div>
<div id="configure-databricks-connect" class="section level2">
<h2>Configure Databricks Connect</h2>
<p>To configure the Databricks Connect client, you can run the following command in
a terminal when logged in as a user in RStudio Server Pro:</p>
<pre><code>databricks-connect configure</code></pre>
<p>In the prompts that follow, enter the following information:</p>
<table>
<colgroup>
<col width="14%" />
<col width="39%" />
<col width="46%" />
</colgroup>
<thead>
<tr class="header">
<th>Item</th>
<th>Description</th>
<th>Example Value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Databricks Host</td>
<td>Base address of your Databricks console URL</td>
<td><code>https://dbc-01234567-89ab.cloud.databricks.com</code></td>
</tr>
<tr class="even">
<td>Databricks Token</td>
<td>User token generated from the Databricks Console under your “User Settings”</td>
<td><code>dapi24g06bdd96f2700b09dd336d5444c1yz</code></td>
</tr>
<tr class="odd">
<td>Cluster ID</td>
<td>Cluster ID in the Databricks console under Advanced Options &gt; Tags &gt; <code>ClusterId</code></td>
<td><code>0308-033548-colt989</code></td>
</tr>
<tr class="even">
<td>Org ID</td>
<td>Found in the <code>?o=orgId</code> portion of your Databricks Console URL</td>
<td><code>8498623428173033</code></td>
</tr>
<tr class="odd">
<td>Port</td>
<td>The port that Databricks Connect connects to</td>
<td><code>15001</code></td>
</tr>
</tbody>
</table>
<p>After you’ve completed the configuration process for Databricks Connect, you can
run the following command in a terminal to test the connectivity of Databricks
Connect to your Databricks cluster:</p>
<pre><code>databricks-connect test</code></pre>
</div>
<div id="install-sparklyr" class="section level2">
<h2>Install <code>sparklyr</code></h2>
<p>The integration of <code>sparklyr</code> with Databricks Connect is currently being added
to the development version of <code>sparklyr</code>. To use this functionality now, you’ll
need to install the development version of <code>sparklyr</code>, by running the following
command in an R console:</p>
<pre><code>devtools::install_github(&quot;sparklyr/sparklyr&quot;)</code></pre>
</div>
<div id="install-spark" class="section level2">
<h2>Install Spark</h2>
<p>To work with a remote Databricks cluster, you need to have a local installation
of Spark that matches the version of Spark on the Databricks Cluster.</p>
<p>You can install Spark by running the following command in an R console:</p>
<pre><code>library(sparklyr)
sparklyr::spark_install()</code></pre>
<p>You can specify the version of Spark to install along with other options. Refer
to the
<a href="https://spark.rstudio.com/reference/spark_install/"><code>spark_install()</code> options in the <code>sparklyr</code> reference documentation</a>
for more information.</p>
</div>
<div id="use-sparklyr" class="section level2">
<h2>Use <code>sparklyr</code></h2>
<p>The <code>SPARK_HOME</code> environment variable must be set to the output of the
<code>databricks-connect get-spark-home</code> command.</p>
<p>You can set the <code>SPARK_HOME</code> environment variable and connect to the Databricks
cluster by running the following R code:</p>
<pre><code>databricks_connect_spark_home &lt;- system(&quot;databricks-connect get-spark-home&quot;, intern = TRUE)

library(sparklyr)
Sys.setenv(SPARK_HOME=databricks_connect_spark_home)
sc &lt;- spark_connect(master = &quot;local&quot;, method = &quot;databricks&quot;)</code></pre>
</div>
<div id="additional-information" class="section level2">
<h2>Additional information</h2>
<p>For more information on the setup, configuration, and limitations of Databricks
Connect, refer to the
<a href="https://docs.databricks.com/dev-tools/databricks-connect.html">Databricks Connect page in the Databricks documentation</a>.</p>
</div>
