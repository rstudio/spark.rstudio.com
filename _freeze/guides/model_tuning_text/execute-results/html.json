{
  "hash": "e94555bbcc68b2cc83427db60062ed82",
  "result": {
    "markdown": "---\ntitle: \"Model Tuning - Part II\"\nexecute:\n  eval: true\n  freeze: true\n---\n\n\n\n\n## Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(sparklyr)\n\nsc <- spark_connect(master = \"local\", version = \"3.3\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(modeldata)\n\ndata(\"small_fine_foods\")\n\nsff_training_data <- copy_to(sc, training_data)\n\nsff_testing_data <- copy_to(sc, testing_data)\n```\n:::\n\n\n## Pipeline\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsff_pipeline <- ml_pipeline(sc) %>% \n  ft_tokenizer(\n    input_col = \"review\",\n    output_col = \"word_list\"\n  ) %>% \n  ft_stop_words_remover(\n    input_col = \"word_list\", \n    output_col = \"wo_stop_words\"\n    ) %>% \n  ft_hashing_tf(\n    input_col = \"wo_stop_words\", \n    output_col = \"hashed_features\", \n    binary = TRUE, \n    num_features = 1024\n    ) %>%\n  ft_normalizer(\n    input_col = \"hashed_features\", \n    output_col = \"normal_features\"\n    ) %>% \n  ft_r_formula(score ~ normal_features) %>% \n  ml_logistic_regression()\n```\n:::\n\n\n## Grid\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsff_grid <-  list(\n    hashing_tf = list(\n      num_features = 2^c(8, 10, 12)  \n    ),\n    logistic_regression = list(\n      elastic_net_param = 10^seq(-3, 0, length = 20), # penalty\n      reg_param = seq(0, 1, length = 5) # mixture      \n    )\n  )\n\nsff_grid\n#> $hashing_tf\n#> $hashing_tf$num_features\n#> [1]  256 1024 4096\n#> \n#> \n#> $logistic_regression\n#> $logistic_regression$elastic_net_param\n#>  [1] 0.001000000 0.001438450 0.002069138 0.002976351 0.004281332 0.006158482\n#>  [7] 0.008858668 0.012742750 0.018329807 0.026366509 0.037926902 0.054555948\n#> [13] 0.078475997 0.112883789 0.162377674 0.233572147 0.335981829 0.483293024\n#> [19] 0.695192796 1.000000000\n#> \n#> $logistic_regression$reg_param\n#> [1] 0.00 0.25 0.50 0.75 1.00\n```\n:::\n\n\n## Evaluator\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsff_evaluator <- ml_binary_classification_evaluator(x = sc)\n```\n:::\n\n\n## Model Tuning\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsff_cv <- ml_cross_validator(\n  x = sc,\n  estimator = sff_pipeline, \n  estimator_param_maps = sff_grid,\n  evaluator = sff_evaluator,\n  num_folds = 3,\n  parallelism = 4\n)\n\nsff_cv\n#> CrossValidator (Estimator)\n#> <cross_validator__72727901_e018_42db_9c46_45b6b964c626> \n#>  (Parameters -- Tuning)\n#>   estimator: Pipeline\n#>              <pipeline__371cd9cf_0349_4b5e_9de0_9cdb55621ec7> \n#>   evaluator: BinaryClassificationEvaluator\n#>              <binary_classification_evaluator__5020c112_5304_4734_b07e_58a8c25301fc> \n#>     with metric areaUnderROC \n#>   num_folds: 3 \n#>   [Tuned over 300 hyperparameter sets]\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsff_model <- ml_fit(\n  x = sff_cv, \n  dataset = sff_training_data\n  )\n```\n:::\n\n\n## Validation metrics\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsff_metrics <- ml_validation_metrics(sff_model)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\n\nsff_metrics %>% \n  mutate(reg_param_1 = as.factor(reg_param_1)) %>% \n  ggplot() +\n  geom_line(aes(elastic_net_param_1, areaUnderROC, color = reg_param_1)) +\n  facet_wrap(~ num_features_2) +\n  theme_light()\n```\n\n::: {.cell-output-display}\n![](model_tuning_text_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\n\nsff_metrics %>% \n  arrange(desc(areaUnderROC)) %>% \n  head()\n#>   areaUnderROC elastic_net_param_1 reg_param_1 num_features_2\n#> 1    0.7777806         0.012742750        0.75           4096\n#> 2    0.7775263         0.018329807        0.50           4096\n#> 3    0.7772891         0.012742750        1.00           4096\n#> 4    0.7769841         0.026366509        0.50           4096\n#> 5    0.7766766         0.018329807        0.75           4096\n#> 6    0.7766600         0.008858668        1.00           4096\n```\n:::\n\n\n## Model selection\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnew_sff_pipeline <- ml_pipeline(sc) %>% \n  ft_tokenizer(\n    input_col = \"review\",\n    output_col = \"word_list\"\n  ) %>% \n  ft_stop_words_remover(\n    input_col = \"word_list\", \n    output_col = \"wo_stop_words\"\n    ) %>% \n  ft_hashing_tf(\n    input_col = \"wo_stop_words\", \n    output_col = \"hashed_features\", \n    binary = TRUE, \n    num_features = 4096\n    ) %>%\n  ft_normalizer(\n    input_col = \"hashed_features\", \n    output_col = \"normal_features\"\n    ) %>% \n  ft_r_formula(score ~ normal_features) %>% \n  ml_logistic_regression(elastic_net_param = 0.018, reg_param = 0.5)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nnew_sff_fitted <- new_sff_pipeline %>% \n  ml_fit(sff_training_data)\n```\n:::\n\n\n## Test data metrics\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnew_sff_fitted %>% \n  ml_transform(sff_testing_data) %>% \n  ml_metrics_binary()\n#> # A tibble: 2 Ã— 3\n#>   .metric .estimator .estimate\n#>   <chr>   <chr>          <dbl>\n#> 1 roc_auc binary         0.789\n#> 2 pr_auc  binary         0.662\n```\n:::\n\n\n",
    "supporting": [
      "model_tuning_text_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}